{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics \n",
    "\n",
    "This notebook holds Assignment 2.1 for Module 2 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In the previous assignment you pulled lyrics data on two artists. In this assignment we explore this data set and a pull from the now-defunct Twitter API for the artists Cher and Robyn.  If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Canvas. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e16354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"/users/chandler/dropbox/teaching/repos/ads-tm-api-scrape/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3071a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens=5):\n",
    "    \"\"\"\n",
    "    Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "    number of characters, lexical diversity, and num_tokens most common tokens. \n",
    "    Return a list with the number of tokens, number of unique tokens, lexical \n",
    "    diversity, and number of characters. \n",
    "    \"\"\"\n",
    "\n",
    "    # Compute number of tokens\n",
    "    num_tokens = len(tokens)\n",
    "\n",
    "    # Compute number of unique tokens\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "\n",
    "    # Compute number of characters\n",
    "    num_characters = sum(len(token) for token in tokens)\n",
    "\n",
    "    # Compute lexical diversity\n",
    "    if num_tokens > 0:\n",
    "        lexical_diversity = num_unique_tokens / num_tokens\n",
    "    else:\n",
    "        lexical_diversity = 0.0\n",
    "\n",
    "    print(f\"There are {num_tokens} tokens in the data.\")\n",
    "    print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "    print(f\"There are {num_characters} characters in the data.\")\n",
    "    print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "\n",
    "    # Print the num_tokens most common tokens\n",
    "    if num_tokens > 0:\n",
    "        common_tokens = Counter(tokens).most_common(num_tokens)\n",
    "        print(f\"The {num_tokens} most common tokens are:\")\n",
    "        for token, count in common_tokens:\n",
    "            print(f\"{token}: {count} occurrences\")\n",
    "    else:\n",
    "        print(\"No tokens to display.\")\n",
    "\n",
    "    return [num_tokens, num_unique_tokens, lexical_diversity, num_characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee2caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_descriptive_statistics(text):\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Calculate word count\n",
    "    word_count = len(tokens)\n",
    "    \n",
    "    # Calculate average word length\n",
    "    avg_word_length = sum(len(word) for word in tokens) / len(tokens)\n",
    "    \n",
    "    # Calculate vocabulary size\n",
    "    vocabulary_size = len(set(tokens))\n",
    "    \n",
    "    # Return the descriptive statistics\n",
    "    return {\n",
    "        'word_count': word_count,\n",
    "        'avg_word_length': avg_word_length,\n",
    "        'vocabulary_size': vocabulary_size\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8cea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def descriptive_stats(tokens, num_tokens=5, verbose=True):\n",
    "    \"\"\"\n",
    "    Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "    number of characters, lexical diversity, and num_tokens most common tokens. \n",
    "    Return a list with the number of tokens, number of unique tokens, \n",
    "    lexical diversity, and number of characters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the number of tokens\n",
    "    num_tokens = len(tokens)\n",
    "    \n",
    "    # Calculate the number of unique tokens\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    \n",
    "    # Calculate the number of characters\n",
    "    num_characters = sum(len(token) for token in tokens)\n",
    "    \n",
    "    # Calculate the lexical diversity\n",
    "    lexical_diversity = num_unique_tokens / num_tokens if num_tokens > 0 else 0.0\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # Print the num_tokens most common tokens\n",
    "        most_common_tokens = Counter(tokens).most_common(num_tokens)\n",
    "        print(f\"The {num_tokens} most common tokens are:\")\n",
    "        for token, frequency in most_common_tokens:\n",
    "            print(f\"{token}: {frequency}\")\n",
    "    \n",
    "    return [num_tokens, num_unique_tokens, lexical_diversity, num_characters]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dcf058",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"here is some example text with other example text here in this text\"\"\".split()\n",
    "stats = descriptive_stats(text, verbose=False)  # Call the function once and store the returned values\n",
    "\n",
    "assert stats[0] == 13\n",
    "assert stats[1] == 9\n",
    "assert abs(stats[2] - 0.69) < 0.02\n",
    "assert stats[3] == 55\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7e1a2",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "A: It is beneficial to use assertion statements in your code is to identify logical errors and any invalid assumptions. Assertion statements help catch bugs early in the development process. They also document the code and help handle unexpected errors. They act as quality points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37d70801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory exists: C:\\Users\\keevi\\OneDrive\\Documents\\SDU\\ADS-509\\Week 2\\M1 Results\n",
      "Lyrics directories: ['cher', 'robyn']\n",
      "Lyrics DataFrame:\n",
      "                                              lyrics\n",
      "0  \"88 Degrees\"\\n\\n\\n\\nStuck in L.A., ain't got n...\n",
      "1  \"A Different Kind Of Love Song\"\\n\\n\\n\\nWhat if...\n",
      "2  \"After All\"\\n\\n\\n\\nWell, here we are again\\nI ...\n",
      "3  \"Again\"\\n\\n\\n\\nAgain evening finds me at your ...\n",
      "4  \"Alfie\"\\n\\n\\n\\nWhat's it all about, Alfie?\\nIs...\n"
     ]
    }
   ],
   "source": [
    "# Read in the lyrics data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the data locations with raw strings to handle backslashes properly\n",
    "data_location = r\"C:\\Users\\keevi\\OneDrive\\Documents\\SDU\\ADS-509\\Week 2\\M1 Results\"\n",
    "lyrics_folder = \"lyrics/\"\n",
    "\n",
    "# Check if base directory exists\n",
    "if not os.path.exists(data_location):\n",
    "    print(f\"Base directory does not exist: {data_location}\")\n",
    "else:\n",
    "    print(f\"Base directory exists: {data_location}\")\n",
    "\n",
    "# List directories in the lyrics folder\n",
    "lyrics_path = os.path.join(data_location, lyrics_folder)\n",
    "if not os.path.exists(lyrics_path):\n",
    "    print(f\"Lyrics directory does not exist: {lyrics_path}\")\n",
    "else:\n",
    "    lyrics_dirs = os.listdir(lyrics_path)\n",
    "    print(\"Lyrics directories:\", lyrics_dirs)\n",
    "\n",
    "# Read all lyrics files from each subdirectory\n",
    "all_lyrics = []\n",
    "\n",
    "for lyrics_dir in lyrics_dirs:\n",
    "    dir_path = os.path.join(lyrics_path, lyrics_dir)\n",
    "    if os.path.isdir(dir_path):\n",
    "        files = os.listdir(dir_path)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(dir_path, file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    lyrics_data = f.read()\n",
    "                    all_lyrics.append(lyrics_data)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Error: {e}\")\n",
    "            except PermissionError as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "# Create a DataFrame for the lyrics data\n",
    "lyrics_df = pd.DataFrame(all_lyrics, columns=['lyrics'])\n",
    "print(\"Lyrics DataFrame:\")\n",
    "print(lyrics_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debcac5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory exists: C:\\Users\\keevi\\OneDrive\\Documents\\SDU\\ADS-509\\Week 2\\M1 Results\n",
      "Twitter files: ['.DS_Store', 'cher_followers.txt', 'cher_followers_data.txt', 'robynkonichiwa_followers.txt', 'robynkonichiwa_followers_data.txt']\n",
      "\n",
      "Twitter DataFrame:\n",
      "                   tweet\n",
      "0                   id\\n\n",
      "1             35152213\\n\n",
      "2   742153090850164742\\n\n",
      "3  1496463006451974150\\n\n",
      "4           3366479914\\n\n"
     ]
    }
   ],
   "source": [
    "# Read in the twitter data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the data locations with raw strings to handle backslashes properly\n",
    "data_location = r\"C:\\Users\\keevi\\OneDrive\\Documents\\SDU\\ADS-509\\Week 2\\M1 Results\"\n",
    "twitter_folder = \"twitter/\"\n",
    "\n",
    "# Check if base directory exists\n",
    "if not os.path.exists(data_location):\n",
    "    print(f\"Base directory does not exist: {data_location}\")\n",
    "else:\n",
    "    print(f\"Base directory exists: {data_location}\")\n",
    "\n",
    "# List files in the twitter directory\n",
    "twitter_path = os.path.join(data_location, twitter_folder)\n",
    "if not os.path.exists(twitter_path):\n",
    "    print(f\"Twitter directory does not exist: {twitter_path}\")\n",
    "else:\n",
    "    twitter_files = os.listdir(twitter_path)\n",
    "    print(\"Twitter files:\", twitter_files)\n",
    "\n",
    "# Filter out non-text files from Twitter directory\n",
    "twitter_files = [file for file in twitter_files if file.endswith('.txt')]\n",
    "\n",
    "if twitter_files:\n",
    "    twitter_file = os.path.join(twitter_path, twitter_files[0])\n",
    "\n",
    "    # Read the Twitter data\n",
    "    try:\n",
    "        with open(twitter_file, 'r', encoding='utf-8') as f:\n",
    "            twitter_data = f.readlines()\n",
    "\n",
    "        # Create a DataFrame for the Twitter data\n",
    "        twitter_df = pd.DataFrame(twitter_data, columns=['tweet'])\n",
    "        print(\"\\nTwitter DataFrame:\")\n",
    "        print(twitter_df.head())\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except PermissionError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "else:\n",
    "    print(\"No text files found in the Twitter directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c73d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cba1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c29f59bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics DataFrame:\n",
      "                                              lyrics  \\\n",
      "0  \"88 Degrees\"\\n\\n\\n\\nStuck in L.A., ain't got n...   \n",
      "1  \"A Different Kind Of Love Song\"\\n\\n\\n\\nWhat if...   \n",
      "2  \"After All\"\\n\\n\\n\\nWell, here we are again\\nI ...   \n",
      "3  \"Again\"\\n\\n\\n\\nAgain evening finds me at your ...   \n",
      "4  \"Alfie\"\\n\\n\\n\\nWhat's it all about, Alfie?\\nIs...   \n",
      "\n",
      "                                      cleaned_lyrics  \n",
      "0  [88, degrees, stuck, la, aint, got, friends, h...  \n",
      "1  [different, kind, love, song, world, crazy, sa...  \n",
      "2  [well, guess, must, fate, weve, tried, deep, i...  \n",
      "3  [evening, finds, door, ask, could, try, dont, ...  \n",
      "4  [alfie, whats, alfie, moment, live, whats, sor...  \n"
     ]
    }
   ],
   "source": [
    "def clean_and_tokenize(text):\n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in punctuation])\n",
    "    # Split on whitespace and convert to lowercase\n",
    "    tokens = text.lower().split()\n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in sw]\n",
    "    return tokens\n",
    "\n",
    "# Lyrics Data Cleaning and Tokenization\n",
    "\n",
    "# List directories in the lyrics folder\n",
    "lyrics_path = os.path.join(data_location, lyrics_folder)\n",
    "if os.path.exists(lyrics_path):\n",
    "    lyrics_dirs = os.listdir(lyrics_path)\n",
    "\n",
    "    # Read and clean lyrics data\n",
    "    all_lyrics = []\n",
    "    for lyrics_dir in lyrics_dirs:\n",
    "        dir_path = os.path.join(lyrics_path, lyrics_dir)\n",
    "        if os.path.isdir(dir_path):\n",
    "            files = os.listdir(dir_path)\n",
    "            for file in files:\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        lyrics_data = f.read()\n",
    "                        cleaned_data = clean_and_tokenize(lyrics_data)\n",
    "                        all_lyrics.append({\n",
    "                            'lyrics': lyrics_data,\n",
    "                            'cleaned_lyrics': cleaned_data\n",
    "                        })\n",
    "                except FileNotFoundError as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                except PermissionError as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "    # Create a DataFrame for the lyrics data\n",
    "    lyrics_df = pd.DataFrame(all_lyrics)\n",
    "    print(\"Lyrics DataFrame:\")\n",
    "    print(lyrics_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b327033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter DataFrame:\n",
      "                 tweet          cleaned_tweet\n",
      "0                   id                   [id]\n",
      "1             35152213             [35152213]\n",
      "2   742153090850164742   [742153090850164742]\n",
      "3  1496463006451974150  [1496463006451974150]\n",
      "4           3366479914           [3366479914]\n"
     ]
    }
   ],
   "source": [
    "# Twitter Data Cleaning and Tokenization\n",
    "\n",
    "# List files in the twitter directory\n",
    "twitter_path = os.path.join(data_location, twitter_folder)\n",
    "if os.path.exists(twitter_path):\n",
    "    twitter_files = os.listdir(twitter_path)\n",
    "    twitter_files = [file for file in twitter_files if file.endswith('.txt')]\n",
    "\n",
    "    all_tweets = []\n",
    "    if twitter_files:\n",
    "        for file in twitter_files:\n",
    "            file_path = os.path.join(twitter_path, file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    twitter_data = f.readlines()\n",
    "                    for tweet in twitter_data:\n",
    "                        cleaned_tweet = clean_and_tokenize(tweet)\n",
    "                        all_tweets.append({\n",
    "                            'tweet': tweet.strip(),\n",
    "                            'cleaned_tweet': cleaned_tweet\n",
    "                        })\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Error: {e}\")\n",
    "            except PermissionError as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    # Create a DataFrame for the Twitter data\n",
    "    twitter_df = pd.DataFrame(all_tweets)\n",
    "    print(\"\\nTwitter DataFrame:\")\n",
    "    print(twitter_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd0179",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both your lyrics data and your twitter data and for both artists (four total calls). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70ba2d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics DataFrame:\n",
      "  artist                                             lyrics  \\\n",
      "0   cher  \"88 Degrees\"\\n\\n\\n\\nStuck in L.A., ain't got n...   \n",
      "1   cher  \"A Different Kind Of Love Song\"\\n\\n\\n\\nWhat if...   \n",
      "2   cher  \"After All\"\\n\\n\\n\\nWell, here we are again\\nI ...   \n",
      "3   cher  \"Again\"\\n\\n\\n\\nAgain evening finds me at your ...   \n",
      "4   cher  \"Alfie\"\\n\\n\\n\\nWhat's it all about, Alfie?\\nIs...   \n",
      "\n",
      "                                      cleaned_lyrics  \n",
      "0  [88, degrees, stuck, la, aint, got, friends, h...  \n",
      "1  [different, kind, love, song, world, crazy, sa...  \n",
      "2  [well, guess, must, fate, weve, tried, deep, i...  \n",
      "3  [evening, finds, door, ask, could, try, dont, ...  \n",
      "4  [alfie, whats, alfie, moment, live, whats, sor...  \n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 182 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 831 characters in the data.\n",
      "The lexical diversity is 0.451 in the data.\n",
      "The 5 most common tokens are:\n",
      "cause: 9\n",
      "hot: 8\n",
      "im: 8\n",
      "yeah: 8\n",
      "88: 6\n",
      "[182, 82, 0.45054945054945056, 831]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 691 characters in the data.\n",
      "The lexical diversity is 0.299 in the data.\n",
      "The 5 most common tokens are:\n",
      "kind: 17\n",
      "different: 16\n",
      "love: 16\n",
      "song: 16\n",
      "ooh: 14\n",
      "[137, 41, 0.29927007299270075, 691]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 120 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 603 characters in the data.\n",
      "The lexical diversity is 0.492 in the data.\n",
      "The 5 most common tokens are:\n",
      "two: 8\n",
      "weve: 6\n",
      "back: 6\n",
      "guess: 5\n",
      "stops: 4\n",
      "[120, 59, 0.49166666666666664, 603]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 34 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 143 characters in the data.\n",
      "The lexical diversity is 0.824 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 3\n",
      "door: 2\n",
      "know: 2\n",
      "never: 2\n",
      "see: 2\n",
      "[34, 28, 0.8235294117647058, 143]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 67 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 339 characters in the data.\n",
      "The lexical diversity is 0.687 in the data.\n",
      "The 5 most common tokens are:\n",
      "alfie: 11\n",
      "love: 4\n",
      "believe: 3\n",
      "whats: 2\n",
      "meant: 2\n",
      "[67, 46, 0.6865671641791045, 339]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 104 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 491 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "The 5 most common tokens are:\n",
      "need: 7\n",
      "wanna: 6\n",
      "like: 5\n",
      "alive: 3\n",
      "rain: 3\n",
      "[104, 72, 0.6923076923076923, 491]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 94 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 461 characters in the data.\n",
      "The lexical diversity is 0.574 in the data.\n",
      "The 5 most common tokens are:\n",
      "heart: 6\n",
      "feel: 6\n",
      "cant: 5\n",
      "way: 5\n",
      "wants: 5\n",
      "[94, 54, 0.574468085106383, 461]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 83 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 462 characters in the data.\n",
      "The lexical diversity is 0.578 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 10\n",
      "friends: 10\n",
      "want: 8\n",
      "really: 6\n",
      "aint: 3\n",
      "[83, 48, 0.5783132530120482, 462]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 663 characters in the data.\n",
      "The lexical diversity is 0.321 in the data.\n",
      "The 5 most common tokens are:\n",
      "nothing: 11\n",
      "youre: 11\n",
      "baby: 10\n",
      "dont: 8\n",
      "wanna: 8\n",
      "[134, 43, 0.3208955223880597, 663]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 68 tokens in the data.\n",
      "There are 29 unique tokens in the data.\n",
      "There are 241 characters in the data.\n",
      "The lexical diversity is 0.426 in the data.\n",
      "The 5 most common tokens are:\n",
      "blue: 9\n",
      "im: 8\n",
      "one: 6\n",
      "hes: 5\n",
      "time: 4\n",
      "[68, 29, 0.4264705882352941, 241]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 490 characters in the data.\n",
      "The lexical diversity is 0.564 in the data.\n",
      "The 5 most common tokens are:\n",
      "thing: 8\n",
      "know: 5\n",
      "bad: 5\n",
      "let: 4\n",
      "go: 4\n",
      "[101, 57, 0.5643564356435643, 490]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 642 characters in the data.\n",
      "The lexical diversity is 0.540 in the data.\n",
      "The 5 most common tokens are:\n",
      "apples: 7\n",
      "dont: 7\n",
      "fall: 7\n",
      "far: 7\n",
      "tree: 7\n",
      "[137, 74, 0.5401459854014599, 642]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 490 characters in the data.\n",
      "The lexical diversity is 0.509 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 12\n",
      "cant: 7\n",
      "one: 5\n",
      "way: 4\n",
      "spend: 4\n",
      "[110, 56, 0.509090909090909, 490]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 390 characters in the data.\n",
      "The lexical diversity is 0.452 in the data.\n",
      "The 5 most common tokens are:\n",
      "without: 11\n",
      "world: 8\n",
      "heroes: 7\n",
      "dont: 6\n",
      "know: 6\n",
      "[73, 33, 0.4520547945205479, 390]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 123 tokens in the data.\n",
      "There are 93 unique tokens in the data.\n",
      "There are 667 characters in the data.\n",
      "The lexical diversity is 0.756 in the data.\n",
      "The 5 most common tokens are:\n",
      "young: 7\n",
      "girl: 6\n",
      "left: 4\n",
      "love: 4\n",
      "made: 2\n",
      "[123, 93, 0.7560975609756098, 667]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 498 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 13\n",
      "im: 12\n",
      "street: 7\n",
      "feet: 6\n",
      "get: 3\n",
      "[110, 55, 0.5, 498]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 174 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 752 characters in the data.\n",
      "The lexical diversity is 0.408 in the data.\n",
      "The 5 most common tokens are:\n",
      "bang: 62\n",
      "shot: 10\n",
      "baby: 9\n",
      "ground: 6\n",
      "hit: 4\n",
      "[174, 71, 0.40804597701149425, 752]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 100 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 445 characters in the data.\n",
      "The lexical diversity is 0.530 in the data.\n",
      "The 5 most common tokens are:\n",
      "bang: 26\n",
      "shot: 6\n",
      "baby: 3\n",
      "hit: 3\n",
      "ground: 3\n",
      "[100, 53, 0.53, 445]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 488 characters in the data.\n",
      "The lexical diversity is 0.581 in the data.\n",
      "The 5 most common tokens are:\n",
      "every: 9\n",
      "behind: 4\n",
      "door: 4\n",
      "asking: 4\n",
      "house: 3\n",
      "[93, 54, 0.5806451612903226, 488]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 177 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 885 characters in the data.\n",
      "The lexical diversity is 0.294 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 12\n",
      "love: 11\n",
      "believe: 10\n",
      "youre: 10\n",
      "strong: 10\n",
      "[177, 52, 0.2937853107344633, 885]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 156 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 665 characters in the data.\n",
      "The lexical diversity is 0.359 in the data.\n",
      "The 5 most common tokens are:\n",
      "want: 16\n",
      "dont: 12\n",
      "fade: 9\n",
      "away: 9\n",
      "wanna: 6\n",
      "[156, 56, 0.358974358974359, 665]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 96 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 449 characters in the data.\n",
      "The lexical diversity is 0.490 in the data.\n",
      "The 5 most common tokens are:\n",
      "many: 10\n",
      "blowin: 7\n",
      "wind: 7\n",
      "yes: 7\n",
      "answer: 6\n",
      "[96, 47, 0.4895833333333333, 449]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 526 characters in the data.\n",
      "The lexical diversity is 0.389 in the data.\n",
      "The 5 most common tokens are:\n",
      "body: 26\n",
      "heart: 19\n",
      "im: 4\n",
      "eyes: 3\n",
      "feeling: 3\n",
      "[113, 44, 0.3893805309734513, 526]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 84 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 439 characters in the data.\n",
      "The lexical diversity is 0.655 in the data.\n",
      "The 5 most common tokens are:\n",
      "hunger: 11\n",
      "born: 7\n",
      "never: 5\n",
      "youre: 4\n",
      "dies: 4\n",
      "[84, 55, 0.6547619047619048, 439]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 155 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 783 characters in the data.\n",
      "The lexical diversity is 0.342 in the data.\n",
      "The 5 most common tokens are:\n",
      "borrowed: 10\n",
      "time: 10\n",
      "living: 8\n",
      "love: 8\n",
      "another: 8\n",
      "[155, 53, 0.3419354838709677, 783]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 185 tokens in the data.\n",
      "There are 106 unique tokens in the data.\n",
      "There are 880 characters in the data.\n",
      "The lexical diversity is 0.573 in the data.\n",
      "The 5 most common tokens are:\n",
      "boys: 6\n",
      "go: 6\n",
      "girls: 5\n",
      "cant: 5\n",
      "shine: 4\n",
      "[185, 106, 0.572972972972973, 880]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 80 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 403 characters in the data.\n",
      "The lexical diversity is 0.650 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 6\n",
      "cant: 4\n",
      "morei: 4\n",
      "stop: 4\n",
      "know: 3\n",
      "[80, 52, 0.65, 403]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 31 unique tokens in the data.\n",
      "There are 411 characters in the data.\n",
      "The lexical diversity is 0.304 in the data.\n",
      "The 5 most common tokens are:\n",
      "gotta: 13\n",
      "go: 10\n",
      "im: 9\n",
      "way: 6\n",
      "end: 5\n",
      "[102, 31, 0.30392156862745096, 411]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 115 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 496 characters in the data.\n",
      "The lexical diversity is 0.539 in the data.\n",
      "The 5 most common tokens are:\n",
      "ya: 8\n",
      "fool: 6\n",
      "cant: 6\n",
      "cher: 5\n",
      "greg: 4\n",
      "[115, 62, 0.5391304347826087, 496]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 45 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 200 characters in the data.\n",
      "The lexical diversity is 0.622 in the data.\n",
      "The 5 most common tokens are:\n",
      "carnival: 4\n",
      "ill: 4\n",
      "sing: 3\n",
      "time: 3\n",
      "sun: 2\n",
      "[45, 28, 0.6222222222222222, 200]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 758 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 15\n",
      "carousel: 14\n",
      "around: 10\n",
      "know: 5\n",
      "going: 5\n",
      "[146, 73, 0.5, 758]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 79 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 352 characters in the data.\n",
      "The lexical diversity is 0.671 in the data.\n",
      "The 5 most common tokens are:\n",
      "catch: 5\n",
      "wind: 5\n",
      "ah: 4\n",
      "may: 4\n",
      "well: 4\n",
      "[79, 53, 0.6708860759493671, 352]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 124 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 592 characters in the data.\n",
      "The lexical diversity is 0.379 in the data.\n",
      "The 5 most common tokens are:\n",
      "good: 14\n",
      "times: 8\n",
      "long: 7\n",
      "life: 6\n",
      "gonna: 4\n",
      "[124, 47, 0.3790322580645161, 592]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 99 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 455 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "The 5 most common tokens are:\n",
      "sun: 4\n",
      "chastity: 3\n",
      "one: 3\n",
      "make: 3\n",
      "hate: 3\n",
      "[99, 66, 0.6666666666666666, 455]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 136 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 688 characters in the data.\n",
      "The lexical diversity is 0.493 in the data.\n",
      "The 5 most common tokens are:\n",
      "chiquitita: 13\n",
      "sing: 7\n",
      "like: 6\n",
      "new: 5\n",
      "song: 5\n",
      "[136, 67, 0.49264705882352944, 688]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 183 tokens in the data.\n",
      "There are 85 unique tokens in the data.\n",
      "There are 959 characters in the data.\n",
      "The lexical diversity is 0.464 in the data.\n",
      "The 5 most common tokens are:\n",
      "chiquitita: 14\n",
      "tu: 9\n",
      "que: 8\n",
      "quiero: 7\n",
      "compartir: 6\n",
      "[183, 85, 0.4644808743169399, 959]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 311 characters in the data.\n",
      "The lexical diversity is 0.685 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 7\n",
      "time: 6\n",
      "one: 4\n",
      "wish: 3\n",
      "know: 2\n",
      "[73, 50, 0.684931506849315, 311]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 22 tokens in the data.\n",
      "There are 10 unique tokens in the data.\n",
      "There are 145 characters in the data.\n",
      "The lexical diversity is 0.455 in the data.\n",
      "The 5 most common tokens are:\n",
      "nguqo: 4\n",
      "ngqothwane: 4\n",
      "igqira: 2\n",
      "lendlela: 2\n",
      "sebeqabele: 2\n",
      "[22, 10, 0.45454545454545453, 145]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 342 characters in the data.\n",
      "The lexical diversity is 0.603 in the data.\n",
      "The 5 most common tokens are:\n",
      "ill: 8\n",
      "stay: 7\n",
      "come: 5\n",
      "youll: 5\n",
      "true: 4\n",
      "[78, 47, 0.6025641025641025, 342]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 124 tokens in the data.\n",
      "There are 87 unique tokens in the data.\n",
      "There are 577 characters in the data.\n",
      "The lexical diversity is 0.702 in the data.\n",
      "The 5 most common tokens are:\n",
      "come: 7\n",
      "window: 4\n",
      "dont: 4\n",
      "let: 4\n",
      "im: 3\n",
      "[124, 87, 0.7016129032258065, 577]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 143 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 716 characters in the data.\n",
      "The lexical diversity is 0.434 in the data.\n",
      "The 5 most common tokens are:\n",
      "couldve: 19\n",
      "baby: 13\n",
      "see: 7\n",
      "say: 5\n",
      "standing: 5\n",
      "[143, 62, 0.43356643356643354, 716]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 430 characters in the data.\n",
      "The lexical diversity is 0.376 in the data.\n",
      "The 5 most common tokens are:\n",
      "cry: 11\n",
      "like: 10\n",
      "baby: 10\n",
      "think: 5\n",
      "love: 5\n",
      "[93, 35, 0.3763440860215054, 430]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 62 tokens in the data.\n",
      "There are 23 unique tokens in the data.\n",
      "There are 273 characters in the data.\n",
      "The lexical diversity is 0.371 in the data.\n",
      "The 5 most common tokens are:\n",
      "cry: 11\n",
      "sleep: 8\n",
      "hes: 5\n",
      "gone: 5\n",
      "still: 4\n",
      "[62, 23, 0.3709677419354839, 273]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 116 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 589 characters in the data.\n",
      "The lexical diversity is 0.483 in the data.\n",
      "The 5 most common tokens are:\n",
      "dancing: 10\n",
      "queen: 10\n",
      "dance: 5\n",
      "digging: 5\n",
      "youre: 4\n",
      "[116, 56, 0.4827586206896552, 589]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 92 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 497 characters in the data.\n",
      "The lexical diversity is 0.620 in the data.\n",
      "The 5 most common tokens are:\n",
      "dangerous: 6\n",
      "times: 6\n",
      "would: 6\n",
      "keep: 4\n",
      "know: 3\n",
      "[92, 57, 0.6195652173913043, 497]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 80 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 358 characters in the data.\n",
      "The lexical diversity is 0.650 in the data.\n",
      "The 5 most common tokens are:\n",
      "danny: 4\n",
      "boy: 4\n",
      "come: 4\n",
      "oh: 3\n",
      "find: 3\n",
      "[80, 52, 0.65, 358]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 131 tokens in the data.\n",
      "There are 101 unique tokens in the data.\n",
      "There are 655 characters in the data.\n",
      "The lexical diversity is 0.771 in the data.\n",
      "The 5 most common tokens are:\n",
      "dark: 4\n",
      "lady: 4\n",
      "said: 4\n",
      "black: 3\n",
      "chorus: 3\n",
      "[131, 101, 0.7709923664122137, 655]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 94 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 462 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "could: 12\n",
      "start: 6\n",
      "singing: 6\n",
      "song: 5\n",
      "finish: 4\n",
      "[94, 47, 0.5, 462]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 195 tokens in the data.\n",
      "There are 116 unique tokens in the data.\n",
      "There are 964 characters in the data.\n",
      "The lexical diversity is 0.595 in the data.\n",
      "The 5 most common tokens are:\n",
      "youre: 14\n",
      "disaster: 7\n",
      "read: 7\n",
      "lips: 7\n",
      "cake: 5\n",
      "[195, 116, 0.5948717948717949, 964]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 104 tokens in the data.\n",
      "There are 87 unique tokens in the data.\n",
      "There are 521 characters in the data.\n",
      "The lexical diversity is 0.837 in the data.\n",
      "The 5 most common tokens are:\n",
      "dixie: 4\n",
      "wanna: 3\n",
      "like: 3\n",
      "land: 2\n",
      "cotton: 2\n",
      "[104, 87, 0.8365384615384616, 521]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 145 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 744 characters in the data.\n",
      "The lexical diversity is 0.572 in the data.\n",
      "The 5 most common tokens are:\n",
      "dixie: 7\n",
      "girl: 6\n",
      "small: 6\n",
      "day: 4\n",
      "waiting: 3\n",
      "[145, 83, 0.5724137931034483, 744]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 207 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 1028 characters in the data.\n",
      "The lexical diversity is 0.343 in the data.\n",
      "The 5 most common tokens are:\n",
      "anybody: 16\n",
      "really: 16\n",
      "know: 15\n",
      "love: 13\n",
      "somebody: 12\n",
      "[207, 71, 0.34299516908212563, 1028]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 75 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 399 characters in the data.\n",
      "The lexical diversity is 0.373 in the data.\n",
      "The 5 most common tokens are:\n",
      "ever: 16\n",
      "cross: 8\n",
      "mind: 8\n",
      "darling: 7\n",
      "time: 4\n",
      "[75, 28, 0.37333333333333335, 399]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 81 unique tokens in the data.\n",
      "There are 562 characters in the data.\n",
      "The lexical diversity is 0.794 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 4\n",
      "come: 4\n",
      "around: 4\n",
      "im: 3\n",
      "used: 3\n",
      "[102, 81, 0.7941176470588235, 562]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 124 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 557 characters in the data.\n",
      "The lexical diversity is 0.492 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 17\n",
      "dont: 15\n",
      "hide: 11\n",
      "care: 4\n",
      "heart: 3\n",
      "[124, 61, 0.49193548387096775, 557]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 81 unique tokens in the data.\n",
      "There are 622 characters in the data.\n",
      "The lexical diversity is 0.604 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 8\n",
      "aint: 7\n",
      "use: 6\n",
      "think: 5\n",
      "twice: 5\n",
      "[134, 81, 0.6044776119402985, 622]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 537 characters in the data.\n",
      "The lexical diversity is 0.463 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 5\n",
      "time: 5\n",
      "try: 4\n",
      "close: 4\n",
      "rose: 4\n",
      "[121, 56, 0.4628099173553719, 537]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 483 characters in the data.\n",
      "The lexical diversity is 0.406 in the data.\n",
      "The 5 most common tokens are:\n",
      "right: 12\n",
      "alls: 10\n",
      "man: 8\n",
      "woman: 6\n",
      "want: 5\n",
      "[101, 41, 0.40594059405940597, 483]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 153 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 692 characters in the data.\n",
      "The lexical diversity is 0.399 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 15\n",
      "song: 9\n",
      "dove: 7\n",
      "ill: 7\n",
      "lamore: 5\n",
      "[153, 61, 0.39869281045751637, 692]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 112 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 488 characters in the data.\n",
      "The lexical diversity is 0.598 in the data.\n",
      "The 5 most common tokens are:\n",
      "see: 6\n",
      "love: 4\n",
      "sweet: 4\n",
      "never: 4\n",
      "come: 4\n",
      "[112, 67, 0.5982142857142857, 488]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 389 characters in the data.\n",
      "The lexical diversity is 0.577 in the data.\n",
      "The 5 most common tokens are:\n",
      "rock: 6\n",
      "know: 4\n",
      "wont: 4\n",
      "push: 3\n",
      "mountain: 3\n",
      "[78, 45, 0.5769230769230769, 389]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 122 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 591 characters in the data.\n",
      "The lexical diversity is 0.598 in the data.\n",
      "The 5 most common tokens are:\n",
      "believe: 16\n",
      "magic: 10\n",
      "like: 6\n",
      "music: 5\n",
      "go: 4\n",
      "[122, 73, 0.5983606557377049, 591]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 91 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 383 characters in the data.\n",
      "The lexical diversity is 0.440 in the data.\n",
      "The 5 most common tokens are:\n",
      "dream: 8\n",
      "hes: 7\n",
      "oh: 7\n",
      "baby: 4\n",
      "love: 4\n",
      "[91, 40, 0.43956043956043955, 383]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 521 characters in the data.\n",
      "The lexical diversity is 0.460 in the data.\n",
      "The 5 most common tokens are:\n",
      "dressed: 8\n",
      "kill: 8\n",
      "im: 7\n",
      "know: 6\n",
      "one: 4\n",
      "[113, 52, 0.46017699115044247, 521]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 104 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 548 characters in the data.\n",
      "The lexical diversity is 0.481 in the data.\n",
      "The 5 most common tokens are:\n",
      "mornin: 7\n",
      "love: 7\n",
      "early: 6\n",
      "strangers: 6\n",
      "without: 4\n",
      "[104, 50, 0.4807692307692308, 548]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 57 tokens in the data.\n",
      "There are 23 unique tokens in the data.\n",
      "There are 301 characters in the data.\n",
      "The lexical diversity is 0.404 in the data.\n",
      "The 5 most common tokens are:\n",
      "easy: 14\n",
      "people: 7\n",
      "proud: 4\n",
      "cold: 3\n",
      "say: 3\n",
      "[57, 23, 0.40350877192982454, 301]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 106 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 605 characters in the data.\n",
      "The lexical diversity is 0.689 in the data.\n",
      "The 5 most common tokens are:\n",
      "might: 5\n",
      "something: 5\n",
      "elusive: 3\n",
      "butterfly: 3\n",
      "dreams: 3\n",
      "[106, 73, 0.6886792452830188, 605]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 143 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 703 characters in the data.\n",
      "The lexical diversity is 0.350 in the data.\n",
      "The 5 most common tokens are:\n",
      "fire: 16\n",
      "emotional: 13\n",
      "cant: 8\n",
      "see: 6\n",
      "baby: 6\n",
      "[143, 50, 0.34965034965034963, 703]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 132 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 637 characters in the data.\n",
      "The lexical diversity is 0.462 in the data.\n",
      "The 5 most common tokens are:\n",
      "company: 10\n",
      "fast: 7\n",
      "youre: 7\n",
      "life: 4\n",
      "lord: 4\n",
      "[132, 61, 0.4621212121212121, 637]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 167 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 862 characters in the data.\n",
      "The lexical diversity is 0.389 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 16\n",
      "scars: 13\n",
      "favorite: 12\n",
      "loves: 6\n",
      "oh: 6\n",
      "[167, 65, 0.38922155688622756, 862]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 143 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 814 characters in the data.\n",
      "The lexical diversity is 0.573 in the data.\n",
      "The 5 most common tokens are:\n",
      "fernando: 18\n",
      "night: 5\n",
      "would: 5\n",
      "friend: 5\n",
      "could: 4\n",
      "[143, 82, 0.5734265734265734, 814]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 143 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 813 characters in the data.\n",
      "The lexical diversity is 0.580 in the data.\n",
      "The 5 most common tokens are:\n",
      "fernando: 17\n",
      "night: 5\n",
      "would: 5\n",
      "friend: 5\n",
      "could: 4\n",
      "[143, 83, 0.5804195804195804, 813]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 157 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 705 characters in the data.\n",
      "The lexical diversity is 0.522 in the data.\n",
      "The 5 most common tokens are:\n",
      "ive: 12\n",
      "seen: 12\n",
      "thought: 7\n",
      "see: 5\n",
      "time: 5\n",
      "[157, 82, 0.5222929936305732, 705]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 147 tokens in the data.\n",
      "There are 79 unique tokens in the data.\n",
      "There are 723 characters in the data.\n",
      "The lexical diversity is 0.537 in the data.\n",
      "The 5 most common tokens are:\n",
      "still: 8\n",
      "fires: 7\n",
      "eden: 7\n",
      "love: 7\n",
      "remember: 6\n",
      "[147, 79, 0.5374149659863946, 723]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 506 characters in the data.\n",
      "The lexical diversity is 0.726 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 8\n",
      "fit: 7\n",
      "fly: 7\n",
      "cant: 3\n",
      "see: 3\n",
      "[113, 82, 0.7256637168141593, 506]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 124 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 676 characters in the data.\n",
      "The lexical diversity is 0.597 in the data.\n",
      "The 5 most common tokens are:\n",
      "travis: 12\n",
      "wish: 3\n",
      "could: 3\n",
      "helped: 3\n",
      "somehow: 3\n",
      "[124, 74, 0.5967741935483871, 676]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 118 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 638 characters in the data.\n",
      "The lexical diversity is 0.542 in the data.\n",
      "The 5 most common tokens are:\n",
      "whats: 14\n",
      "stop: 7\n",
      "sound: 7\n",
      "everybody: 7\n",
      "look: 7\n",
      "[118, 64, 0.5423728813559322, 638]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 404 characters in the data.\n",
      "The lexical diversity is 0.731 in the data.\n",
      "The 5 most common tokens are:\n",
      "whatever: 4\n",
      "games: 3\n",
      "youre: 3\n",
      "love: 3\n",
      "im: 2\n",
      "[78, 57, 0.7307692307692307, 404]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 117 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 603 characters in the data.\n",
      "The lexical diversity is 0.513 in the data.\n",
      "The 5 most common tokens are:\n",
      "oh: 10\n",
      "cadillac: 8\n",
      "geronimos: 7\n",
      "back: 7\n",
      "boys: 6\n",
      "[117, 60, 0.5128205128205128, 603]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 156 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 793 characters in the data.\n",
      "The lexical diversity is 0.378 in the data.\n",
      "The 5 most common tokens are:\n",
      "gimme: 33\n",
      "man: 11\n",
      "midnight: 11\n",
      "theres: 4\n",
      "one: 4\n",
      "[156, 59, 0.3782051282051282, 793]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 120 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 500 characters in the data.\n",
      "The lexical diversity is 0.283 in the data.\n",
      "The 5 most common tokens are:\n",
      "wait: 12\n",
      "girl: 11\n",
      "dont: 11\n",
      "come: 11\n",
      "wanna: 11\n",
      "[120, 34, 0.2833333333333333, 500]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 564 characters in the data.\n",
      "The lexical diversity is 0.328 in the data.\n",
      "The 5 most common tokens are:\n",
      "away: 28\n",
      "wanna: 12\n",
      "take: 8\n",
      "get: 6\n",
      "old: 6\n",
      "[134, 44, 0.3283582089552239, 564]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 111 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 509 characters in the data.\n",
      "The lexical diversity is 0.640 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 8\n",
      "give: 5\n",
      "fightin: 5\n",
      "chance: 5\n",
      "away: 3\n",
      "[111, 71, 0.6396396396396397, 509]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 92 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 373 characters in the data.\n",
      "The lexical diversity is 0.380 in the data.\n",
      "The 5 most common tokens are:\n",
      "go: 18\n",
      "darlin: 7\n",
      "dont: 6\n",
      "see: 5\n",
      "want: 5\n",
      "[92, 35, 0.3804347826086957, 373]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 75 unique tokens in the data.\n",
      "There are 575 characters in the data.\n",
      "The lexical diversity is 0.682 in the data.\n",
      "The 5 most common tokens are:\n",
      "chorus: 4\n",
      "tramps: 3\n",
      "thieves: 3\n",
      "money: 3\n",
      "theyd: 3\n",
      "[110, 75, 0.6818181818181818, 575]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 391 characters in the data.\n",
      "The lexical diversity is 0.808 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 3\n",
      "chorus: 3\n",
      "halfbreed: 3\n",
      "cherokee: 2\n",
      "ashamed: 2\n",
      "[73, 59, 0.8082191780821918, 391]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 92 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 457 characters in the data.\n",
      "The lexical diversity is 0.511 in the data.\n",
      "The 5 most common tokens are:\n",
      "joe: 10\n",
      "president: 5\n",
      "happiness: 4\n",
      "thing: 4\n",
      "called: 4\n",
      "[92, 47, 0.5108695652173914, 457]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 125 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 568 characters in the data.\n",
      "The lexical diversity is 0.520 in the data.\n",
      "The 5 most common tokens are:\n",
      "happy: 7\n",
      "day: 7\n",
      "met: 6\n",
      "ever: 6\n",
      "never: 5\n",
      "[125, 65, 0.52, 568]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 136 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 670 characters in the data.\n",
      "The lexical diversity is 0.529 in the data.\n",
      "The 5 most common tokens are:\n",
      "hard: 7\n",
      "enough: 7\n",
      "getting: 7\n",
      "dont: 5\n",
      "could: 5\n",
      "[136, 72, 0.5294117647058824, 670]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 70 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 338 characters in the data.\n",
      "The lexical diversity is 0.600 in the data.\n",
      "The 5 most common tokens are:\n",
      "hes: 7\n",
      "brother: 7\n",
      "aint: 5\n",
      "heavy: 5\n",
      "long: 3\n",
      "[70, 42, 0.6, 338]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 153 tokens in the data.\n",
      "There are 93 unique tokens in the data.\n",
      "There are 774 characters in the data.\n",
      "The lexical diversity is 0.608 in the data.\n",
      "The 5 most common tokens are:\n",
      "heart: 14\n",
      "stone: 10\n",
      "wish: 7\n",
      "dont: 5\n",
      "sometimes: 5\n",
      "[153, 93, 0.6078431372549019, 774]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 529 characters in the data.\n",
      "The lexical diversity is 0.645 in the data.\n",
      "The 5 most common tokens are:\n",
      "hell: 9\n",
      "never: 9\n",
      "know: 9\n",
      "mine: 3\n",
      "son: 3\n",
      "[110, 71, 0.6454545454545455, 529]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 231 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 1026 characters in the data.\n",
      "The lexical diversity is 0.221 in the data.\n",
      "The 5 most common tokens are:\n",
      "see: 16\n",
      "something: 16\n",
      "go: 12\n",
      "lets: 12\n",
      "roll: 12\n",
      "[231, 51, 0.22077922077922077, 1026]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 95 tokens in the data.\n",
      "There are 78 unique tokens in the data.\n",
      "There are 483 characters in the data.\n",
      "The lexical diversity is 0.821 in the data.\n",
      "The 5 most common tokens are:\n",
      "beautiful: 4\n",
      "like: 3\n",
      "ill: 3\n",
      "made: 2\n",
      "music: 2\n",
      "[95, 78, 0.8210526315789474, 483]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 107 tokens in the data.\n",
      "There are 32 unique tokens in the data.\n",
      "There are 433 characters in the data.\n",
      "The lexical diversity is 0.299 in the data.\n",
      "The 5 most common tokens are:\n",
      "shot: 11\n",
      "hey: 10\n",
      "joe: 9\n",
      "goin: 6\n",
      "said: 6\n",
      "[107, 32, 0.29906542056074764, 433]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 150 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 707 characters in the data.\n",
      "The lexical diversity is 0.453 in the data.\n",
      "The 5 most common tokens are:\n",
      "holdin: 26\n",
      "love: 16\n",
      "im: 15\n",
      "time: 11\n",
      "mind: 6\n",
      "[150, 68, 0.4533333333333333, 707]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 176 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 835 characters in the data.\n",
      "The lexical diversity is 0.375 in the data.\n",
      "The 5 most common tokens are:\n",
      "holy: 16\n",
      "smoke: 16\n",
      "say: 11\n",
      "get: 6\n",
      "solve: 6\n",
      "[176, 66, 0.375, 835]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 106 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 616 characters in the data.\n",
      "The lexical diversity is 0.604 in the data.\n",
      "The 5 most common tokens are:\n",
      "home: 9\n",
      "homeward: 7\n",
      "bound: 7\n",
      "silently: 4\n",
      "evry: 3\n",
      "[106, 64, 0.6037735849056604, 616]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 74 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 330 characters in the data.\n",
      "The lexical diversity is 0.635 in the data.\n",
      "The 5 most common tokens are:\n",
      "house: 7\n",
      "one: 5\n",
      "home: 4\n",
      "room: 4\n",
      "chair: 3\n",
      "[74, 47, 0.6351351351351351, 330]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 88 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 421 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "mend: 7\n",
      "broken: 7\n",
      "heart: 5\n",
      "stop: 4\n",
      "man: 3\n",
      "[88, 44, 0.5, 421]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 88 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 395 characters in the data.\n",
      "The lexical diversity is 0.455 in the data.\n",
      "The 5 most common tokens are:\n",
      "long: 9\n",
      "going: 9\n",
      "oh: 7\n",
      "heaven: 4\n",
      "could: 3\n",
      "[88, 40, 0.45454545454545453, 395]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 129 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 643 characters in the data.\n",
      "The lexical diversity is 0.442 in the data.\n",
      "The 5 most common tokens are:\n",
      "believe: 34\n",
      "man: 21\n",
      "got: 8\n",
      "every: 3\n",
      "baby: 3\n",
      "[129, 57, 0.4418604651162791, 643]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 152 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 781 characters in the data.\n",
      "The lexical diversity is 0.395 in the data.\n",
      "The 5 most common tokens are:\n",
      "dream: 15\n",
      "youre: 10\n",
      "dont: 9\n",
      "sleep: 9\n",
      "never: 6\n",
      "[152, 60, 0.39473684210526316, 781]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 86 tokens in the data.\n",
      "There are 49 unique tokens in the data.\n",
      "There are 413 characters in the data.\n",
      "The lexical diversity is 0.570 in the data.\n",
      "The 5 most common tokens are:\n",
      "youve: 9\n",
      "loved: 8\n",
      "somebody: 7\n",
      "ive: 5\n",
      "like: 4\n",
      "[86, 49, 0.5697674418604651, 413]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 437 characters in the data.\n",
      "The lexical diversity is 0.484 in the data.\n",
      "The 5 most common tokens are:\n",
      "feel: 6\n",
      "something: 5\n",
      "air: 5\n",
      "magic: 4\n",
      "used: 4\n",
      "[93, 45, 0.4838709677419355, 437]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 204 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 888 characters in the data.\n",
      "The lexical diversity is 0.314 in the data.\n",
      "The 5 most common tokens are:\n",
      "could: 19\n",
      "back: 15\n",
      "turn: 11\n",
      "time: 11\n",
      "id: 7\n",
      "[204, 64, 0.3137254901960784, 888]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 75 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 359 characters in the data.\n",
      "The lexical diversity is 0.640 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 6\n",
      "knew: 5\n",
      "would: 4\n",
      "many: 4\n",
      "cowboy: 3\n",
      "[75, 48, 0.64, 359]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 678 characters in the data.\n",
      "The lexical diversity is 0.425 in the data.\n",
      "The 5 most common tokens are:\n",
      "away: 9\n",
      "take: 8\n",
      "baby: 7\n",
      "since: 7\n",
      "youve: 7\n",
      "[134, 57, 0.4253731343283582, 678]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 147 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 694 characters in the data.\n",
      "The lexical diversity is 0.320 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 21\n",
      "gonna: 18\n",
      "found: 12\n",
      "hes: 6\n",
      "new: 5\n",
      "[147, 47, 0.3197278911564626, 694]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 59 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 239 characters in the data.\n",
      "The lexical diversity is 0.475 in the data.\n",
      "The 5 most common tokens are:\n",
      "bad: 13\n",
      "got: 7\n",
      "aint: 5\n",
      "good: 4\n",
      "way: 2\n",
      "[59, 28, 0.4745762711864407, 239]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 72 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 345 characters in the data.\n",
      "The lexical diversity is 0.569 in the data.\n",
      "The 5 most common tokens are:\n",
      "sleep: 13\n",
      "go: 7\n",
      "imagine: 6\n",
      "youre: 6\n",
      "look: 2\n",
      "[72, 41, 0.5694444444444444, 345]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 115 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 467 characters in the data.\n",
      "The lexical diversity is 0.513 in the data.\n",
      "The 5 most common tokens are:\n",
      "got: 25\n",
      "babe: 15\n",
      "dont: 4\n",
      "say: 3\n",
      "wont: 3\n",
      "[115, 59, 0.5130434782608696, 467]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 59 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 267 characters in the data.\n",
      "The lexical diversity is 0.559 in the data.\n",
      "The 5 most common tokens are:\n",
      "alone: 6\n",
      "hate: 5\n",
      "sleep: 5\n",
      "know: 3\n",
      "could: 2\n",
      "[59, 33, 0.559322033898305, 267]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 132 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 675 characters in the data.\n",
      "The lexical diversity is 0.462 in the data.\n",
      "The 5 most common tokens are:\n",
      "hope: 15\n",
      "find: 8\n",
      "youre: 6\n",
      "know: 5\n",
      "id: 3\n",
      "[132, 61, 0.4621212121212121, 675]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 45 tokens in the data.\n",
      "There are 18 unique tokens in the data.\n",
      "There are 168 characters in the data.\n",
      "The lexical diversity is 0.400 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 7\n",
      "uh: 6\n",
      "yes: 5\n",
      "know: 4\n",
      "dont: 4\n",
      "[45, 18, 0.4, 168]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 540 characters in the data.\n",
      "The lexical diversity is 0.536 in the data.\n",
      "The 5 most common tokens are:\n",
      "stop: 7\n",
      "ill: 6\n",
      "never: 6\n",
      "loving: 6\n",
      "one: 4\n",
      "[110, 59, 0.5363636363636364, 540]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 111 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 510 characters in the data.\n",
      "The lexical diversity is 0.604 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 16\n",
      "making: 6\n",
      "oh: 6\n",
      "ooh: 5\n",
      "dont: 3\n",
      "[111, 67, 0.6036036036036037, 510]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 50 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 240 characters in the data.\n",
      "The lexical diversity is 0.720 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 4\n",
      "im: 3\n",
      "blowin: 3\n",
      "away: 3\n",
      "ive: 2\n",
      "[50, 36, 0.72, 240]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 646 characters in the data.\n",
      "The lexical diversity is 0.364 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 12\n",
      "im: 10\n",
      "middle: 9\n",
      "something: 8\n",
      "understand: 8\n",
      "[121, 44, 0.36363636363636365, 646]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 72 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 393 characters in the data.\n",
      "The lexical diversity is 0.861 in the data.\n",
      "The 5 most common tokens are:\n",
      "dream: 3\n",
      "impossible: 2\n",
      "fight: 2\n",
      "right: 2\n",
      "reach: 2\n",
      "[72, 62, 0.8611111111111112, 393]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 77 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 397 characters in the data.\n",
      "The lexical diversity is 0.727 in the data.\n",
      "The 5 most common tokens are:\n",
      "like: 4\n",
      "chorus: 3\n",
      "night: 2\n",
      "mama: 2\n",
      "used: 2\n",
      "[77, 56, 0.7272727272727273, 397]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 719 characters in the data.\n",
      "The lexical diversity is 0.425 in the data.\n",
      "The 5 most common tokens are:\n",
      "got: 9\n",
      "way: 8\n",
      "im: 6\n",
      "take: 6\n",
      "paralyze: 5\n",
      "[146, 62, 0.4246575342465753, 719]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 412 characters in the data.\n",
      "The lexical diversity is 0.724 in the data.\n",
      "The 5 most common tokens are:\n",
      "danced: 7\n",
      "saw: 4\n",
      "man: 3\n",
      "wife: 3\n",
      "kept: 3\n",
      "[87, 63, 0.7241379310344828, 412]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 68 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 348 characters in the data.\n",
      "The lexical diversity is 0.603 in the data.\n",
      "The 5 most common tokens are:\n",
      "cant: 4\n",
      "get: 4\n",
      "island: 3\n",
      "need: 3\n",
      "way: 3\n",
      "[68, 41, 0.6029411764705882, 348]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 70 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 324 characters in the data.\n",
      "The lexical diversity is 0.857 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 4\n",
      "adds: 3\n",
      "way: 2\n",
      "look: 2\n",
      "heart: 2\n",
      "[70, 60, 0.8571428571428571, 324]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 56 tokens in the data.\n",
      "There are 31 unique tokens in the data.\n",
      "There are 260 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "The 5 most common tokens are:\n",
      "eyes: 6\n",
      "gets: 4\n",
      "go: 4\n",
      "around: 4\n",
      "many: 4\n",
      "[56, 31, 0.5535714285714286, 260]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 69 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 319 characters in the data.\n",
      "The lexical diversity is 0.768 in the data.\n",
      "The 5 most common tokens are:\n",
      "away: 6\n",
      "threw: 4\n",
      "love: 4\n",
      "dont: 2\n",
      "cant: 2\n",
      "[69, 53, 0.7681159420289855, 319]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 89 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 433 characters in the data.\n",
      "The lexical diversity is 0.472 in the data.\n",
      "The 5 most common tokens are:\n",
      "monday: 8\n",
      "might: 7\n",
      "well: 7\n",
      "stay: 7\n",
      "nothing: 6\n",
      "[89, 42, 0.47191011235955055, 433]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 631 characters in the data.\n",
      "The lexical diversity is 0.511 in the data.\n",
      "The 5 most common tokens are:\n",
      "shame: 12\n",
      "cryin: 11\n",
      "love: 11\n",
      "dont: 10\n",
      "happen: 9\n",
      "[137, 70, 0.5109489051094891, 631]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 482 characters in the data.\n",
      "The lexical diversity is 0.431 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 10\n",
      "mans: 7\n",
      "hes: 7\n",
      "lost: 7\n",
      "nothing: 6\n",
      "[102, 44, 0.43137254901960786, 482]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 56 tokens in the data.\n",
      "There are 31 unique tokens in the data.\n",
      "There are 278 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "The 5 most common tokens are:\n",
      "unusual: 9\n",
      "anyone: 6\n",
      "love: 5\n",
      "see: 3\n",
      "find: 3\n",
      "[56, 31, 0.5535714285714286, 278]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 84 tokens in the data.\n",
      "There are 29 unique tokens in the data.\n",
      "There are 366 characters in the data.\n",
      "The lexical diversity is 0.345 in the data.\n",
      "The 5 most common tokens are:\n",
      "late: 11\n",
      "love: 11\n",
      "say: 4\n",
      "bad: 4\n",
      "know: 4\n",
      "[84, 29, 0.34523809523809523, 366]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 191 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 892 characters in the data.\n",
      "The lexical diversity is 0.398 in the data.\n",
      "The 5 most common tokens are:\n",
      "time: 31\n",
      "theres: 17\n",
      "walk: 14\n",
      "alone: 14\n",
      "gotta: 10\n",
      "[191, 76, 0.39790575916230364, 892]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 161 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 770 characters in the data.\n",
      "The lexical diversity is 0.416 in the data.\n",
      "The 5 most common tokens are:\n",
      "come: 24\n",
      "till: 16\n",
      "burn: 16\n",
      "walk: 12\n",
      "guilded: 10\n",
      "[161, 67, 0.4161490683229814, 770]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 501 characters in the data.\n",
      "The lexical diversity is 0.716 in the data.\n",
      "The 5 most common tokens are:\n",
      "want: 17\n",
      "bad: 4\n",
      "honey: 4\n",
      "wait: 3\n",
      "wasnt: 2\n",
      "[102, 73, 0.7156862745098039, 501]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 67 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 319 characters in the data.\n",
      "The lexical diversity is 0.537 in the data.\n",
      "The 5 most common tokens are:\n",
      "wasnt: 6\n",
      "ready: 6\n",
      "walked: 6\n",
      "last: 3\n",
      "night: 3\n",
      "[67, 36, 0.5373134328358209, 319]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 54 tokens in the data.\n",
      "There are 24 unique tokens in the data.\n",
      "There are 280 characters in the data.\n",
      "The lexical diversity is 0.444 in the data.\n",
      "The 5 most common tokens are:\n",
      "wait: 8\n",
      "till: 5\n",
      "forever: 4\n",
      "takes: 3\n",
      "thousand: 3\n",
      "[54, 24, 0.4444444444444444, 280]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 99 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 455 characters in the data.\n",
      "The lexical diversity is 0.586 in the data.\n",
      "The 5 most common tokens are:\n",
      "way: 8\n",
      "treated: 8\n",
      "wouldnt: 7\n",
      "dog: 7\n",
      "treat: 6\n",
      "[99, 58, 0.5858585858585859, 455]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 122 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 555 characters in the data.\n",
      "The lexical diversity is 0.574 in the data.\n",
      "The 5 most common tokens are:\n",
      "sonny: 6\n",
      "boy: 6\n",
      "im: 6\n",
      "forsake: 4\n",
      "coming: 4\n",
      "[122, 70, 0.5737704918032787, 555]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 124 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 586 characters in the data.\n",
      "The lexical diversity is 0.524 in the data.\n",
      "The 5 most common tokens are:\n",
      "julie: 31\n",
      "lying: 6\n",
      "im: 5\n",
      "youre: 5\n",
      "well: 4\n",
      "[124, 65, 0.5241935483870968, 586]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 94 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 464 characters in the data.\n",
      "The lexical diversity is 0.479 in the data.\n",
      "The 5 most common tokens are:\n",
      "enough: 16\n",
      "keep: 9\n",
      "hangin: 8\n",
      "ah: 5\n",
      "honey: 4\n",
      "[94, 45, 0.4787234042553192, 464]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 210 tokens in the data.\n",
      "There are 105 unique tokens in the data.\n",
      "There are 965 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 10\n",
      "youre: 9\n",
      "come: 9\n",
      "baby: 9\n",
      "tonight: 8\n",
      "[210, 105, 0.5, 965]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 103 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 472 characters in the data.\n",
      "The lexical diversity is 0.621 in the data.\n",
      "The 5 most common tokens are:\n",
      "one: 8\n",
      "time: 8\n",
      "ive: 5\n",
      "got: 4\n",
      "believe: 4\n",
      "[103, 64, 0.6213592233009708, 472]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 77 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 391 characters in the data.\n",
      "The lexical diversity is 0.545 in the data.\n",
      "The 5 most common tokens are:\n",
      "ive: 6\n",
      "youre: 5\n",
      "looking: 5\n",
      "never: 3\n",
      "time: 3\n",
      "[77, 42, 0.5454545454545454, 391]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 166 tokens in the data.\n",
      "There are 79 unique tokens in the data.\n",
      "There are 811 characters in the data.\n",
      "The lexical diversity is 0.476 in the data.\n",
      "The 5 most common tokens are:\n",
      "kiss: 36\n",
      "makin: 4\n",
      "miss: 4\n",
      "hiding: 4\n",
      "daylight: 4\n",
      "[166, 79, 0.4759036144578313, 811]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 127 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 652 characters in the data.\n",
      "The lexical diversity is 0.339 in the data.\n",
      "The 5 most common tokens are:\n",
      "knock: 28\n",
      "better: 12\n",
      "wood: 11\n",
      "love: 7\n",
      "thunder: 6\n",
      "[127, 43, 0.33858267716535434, 652]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 144 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 692 characters in the data.\n",
      "The lexical diversity is 0.451 in the data.\n",
      "The 5 most common tokens are:\n",
      "get: 16\n",
      "im: 12\n",
      "coming: 6\n",
      "la: 5\n",
      "plane: 5\n",
      "[144, 65, 0.4513888888888889, 692]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 508 characters in the data.\n",
      "The lexical diversity is 0.421 in the data.\n",
      "The 5 most common tokens are:\n",
      "lay: 20\n",
      "stay: 12\n",
      "baby: 11\n",
      "across: 6\n",
      "big: 6\n",
      "[121, 51, 0.4214876033057851, 508]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 65 tokens in the data.\n",
      "There are 21 unique tokens in the data.\n",
      "There are 256 characters in the data.\n",
      "The lexical diversity is 0.323 in the data.\n",
      "The 5 most common tokens are:\n",
      "let: 16\n",
      "easy: 7\n",
      "youre: 6\n",
      "ah: 6\n",
      "gonna: 5\n",
      "[65, 21, 0.3230769230769231, 256]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 144 tokens in the data.\n",
      "There are 85 unique tokens in the data.\n",
      "There are 699 characters in the data.\n",
      "The lexical diversity is 0.590 in the data.\n",
      "The 5 most common tokens are:\n",
      "shes: 13\n",
      "pretty: 9\n",
      "tied: 9\n",
      "hangin: 6\n",
      "upside: 6\n",
      "[144, 85, 0.5902777777777778, 699]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 114 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 526 characters in the data.\n",
      "The lexical diversity is 0.596 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 5\n",
      "lie: 4\n",
      "youre: 4\n",
      "us: 4\n",
      "one: 4\n",
      "[114, 68, 0.5964912280701754, 526]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 149 tokens in the data.\n",
      "There are 106 unique tokens in the data.\n",
      "There are 794 characters in the data.\n",
      "The lexical diversity is 0.711 in the data.\n",
      "The 5 most common tokens are:\n",
      "like: 8\n",
      "feel: 6\n",
      "rolling: 4\n",
      "stone: 4\n",
      "used: 4\n",
      "[149, 106, 0.7114093959731543, 794]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 52 tokens in the data.\n",
      "There are 38 unique tokens in the data.\n",
      "There are 275 characters in the data.\n",
      "The lexical diversity is 0.731 in the data.\n",
      "The 5 most common tokens are:\n",
      "living: 3\n",
      "sad: 3\n",
      "house: 2\n",
      "divided: 2\n",
      "look: 2\n",
      "[52, 38, 0.7307692307692307, 275]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 130 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 639 characters in the data.\n",
      "The lexical diversity is 0.431 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 14\n",
      "long: 9\n",
      "affair: 9\n",
      "distant: 8\n",
      "station: 8\n",
      "[130, 56, 0.4307692307692308, 639]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 46 tokens in the data.\n",
      "There are 21 unique tokens in the data.\n",
      "There are 200 characters in the data.\n",
      "The lexical diversity is 0.457 in the data.\n",
      "The 5 most common tokens are:\n",
      "look: 7\n",
      "tell: 6\n",
      "see: 6\n",
      "nights: 2\n",
      "long: 2\n",
      "[46, 21, 0.45652173913043476, 200]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 154 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 826 characters in the data.\n",
      "The lexical diversity is 0.370 in the data.\n",
      "The 5 most common tokens are:\n",
      "enough: 21\n",
      "love: 18\n",
      "understanding: 9\n",
      "theres: 6\n",
      "got: 5\n",
      "[154, 57, 0.37012987012987014, 826]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 105 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 534 characters in the data.\n",
      "The lexical diversity is 0.552 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 10\n",
      "enough: 10\n",
      "gotta: 6\n",
      "comes: 4\n",
      "goes: 3\n",
      "[105, 58, 0.5523809523809524, 534]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 500 characters in the data.\n",
      "The lexical diversity is 0.464 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 19\n",
      "hurts: 13\n",
      "know: 6\n",
      "lot: 5\n",
      "isnt: 4\n",
      "[110, 51, 0.4636363636363636, 500]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 89 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 408 characters in the data.\n",
      "The lexical diversity is 0.562 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 13\n",
      "hurts: 8\n",
      "lot: 5\n",
      "know: 4\n",
      "ive: 3\n",
      "[89, 50, 0.5617977528089888, 408]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 540 characters in the data.\n",
      "The lexical diversity is 0.398 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 15\n",
      "place: 10\n",
      "lonely: 7\n",
      "im: 7\n",
      "almost: 6\n",
      "[113, 45, 0.39823008849557523, 540]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 715 characters in the data.\n",
      "The lexical diversity is 0.575 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 16\n",
      "groove: 16\n",
      "move: 14\n",
      "get: 4\n",
      "like: 3\n",
      "[146, 84, 0.5753424657534246, 715]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 68 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 296 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "ill: 5\n",
      "love: 4\n",
      "oh: 4\n",
      "heart: 3\n",
      "ever: 3\n",
      "[68, 34, 0.5, 296]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 119 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 638 characters in the data.\n",
      "The lexical diversity is 0.437 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 12\n",
      "rooftop: 8\n",
      "remember: 7\n",
      "got: 6\n",
      "night: 5\n",
      "[119, 52, 0.4369747899159664, 638]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 120 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 650 characters in the data.\n",
      "The lexical diversity is 0.525 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 13\n",
      "one: 13\n",
      "another: 13\n",
      "everybody: 9\n",
      "needs: 3\n",
      "[120, 63, 0.525, 650]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 108 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 534 characters in the data.\n",
      "The lexical diversity is 0.407 in the data.\n",
      "The 5 most common tokens are:\n",
      "pain: 8\n",
      "theres: 7\n",
      "well: 6\n",
      "guess: 6\n",
      "help: 6\n",
      "[108, 44, 0.4074074074074074, 534]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 75 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 400 characters in the data.\n",
      "The lexical diversity is 0.813 in the data.\n",
      "The 5 most common tokens are:\n",
      "well: 4\n",
      "lovers: 3\n",
      "forever: 2\n",
      "offer: 2\n",
      "show: 2\n",
      "[75, 61, 0.8133333333333334, 400]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 89 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 408 characters in the data.\n",
      "The lexical diversity is 0.663 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 7\n",
      "high: 4\n",
      "mi: 4\n",
      "amore: 4\n",
      "could: 4\n",
      "[89, 59, 0.6629213483146067, 408]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 86 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 354 characters in the data.\n",
      "The lexical diversity is 0.674 in the data.\n",
      "The 5 most common tokens are:\n",
      "put: 11\n",
      "lid: 11\n",
      "right: 3\n",
      "time: 3\n",
      "whats: 2\n",
      "[86, 58, 0.6744186046511628, 354]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 105 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 451 characters in the data.\n",
      "The lexical diversity is 0.343 in the data.\n",
      "The 5 most common tokens are:\n",
      "main: 15\n",
      "man: 15\n",
      "youre: 14\n",
      "oh: 8\n",
      "woman: 6\n",
      "[105, 36, 0.34285714285714286, 451]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 111 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 465 characters in the data.\n",
      "The lexical diversity is 0.495 in the data.\n",
      "The 5 most common tokens are:\n",
      "make: 11\n",
      "man: 9\n",
      "love: 6\n",
      "lord: 5\n",
      "ah: 5\n",
      "[111, 55, 0.4954954954954955, 465]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 108 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 512 characters in the data.\n",
      "The lexical diversity is 0.583 in the data.\n",
      "The 5 most common tokens are:\n",
      "mama: 10\n",
      "dollies: 5\n",
      "babies: 5\n",
      "away: 5\n",
      "big: 4\n",
      "[108, 63, 0.5833333333333334, 512]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 159 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 692 characters in the data.\n",
      "The lexical diversity is 0.428 in the data.\n",
      "The 5 most common tokens are:\n",
      "mamma: 11\n",
      "mia: 11\n",
      "ive: 9\n",
      "go: 9\n",
      "know: 6\n",
      "[159, 68, 0.4276729559748428, 692]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 170 tokens in the data.\n",
      "There are 124 unique tokens in the data.\n",
      "There are 803 characters in the data.\n",
      "The lexical diversity is 0.729 in the data.\n",
      "The 5 most common tokens are:\n",
      "build: 4\n",
      "death: 4\n",
      "hide: 4\n",
      "see: 4\n",
      "im: 4\n",
      "[170, 124, 0.7294117647058823, 803]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 397 characters in the data.\n",
      "The lexical diversity is 0.872 in the data.\n",
      "The 5 most common tokens are:\n",
      "melody: 6\n",
      "days: 3\n",
      "home: 2\n",
      "sleep: 2\n",
      "wont: 2\n",
      "[78, 68, 0.8717948717948718, 397]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 90 unique tokens in the data.\n",
      "There are 565 characters in the data.\n",
      "The lexical diversity is 0.744 in the data.\n",
      "The 5 most common tokens are:\n",
      "milord: 12\n",
      "come: 3\n",
      "lips: 3\n",
      "love: 3\n",
      "hearts: 3\n",
      "[121, 90, 0.743801652892562, 565]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 173 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 893 characters in the data.\n",
      "The lexical diversity is 0.376 in the data.\n",
      "The 5 most common tokens are:\n",
      "mirror: 22\n",
      "image: 21\n",
      "see: 10\n",
      "life: 6\n",
      "think: 5\n",
      "[173, 65, 0.37572254335260113, 893]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 118 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 617 characters in the data.\n",
      "The lexical diversity is 0.619 in the data.\n",
      "The 5 most common tokens are:\n",
      "little: 10\n",
      "may: 5\n",
      "miss: 4\n",
      "subway: 4\n",
      "1952: 4\n",
      "[118, 73, 0.6186440677966102, 617]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 80 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 335 characters in the data.\n",
      "The lexical diversity is 0.525 in the data.\n",
      "The 5 most common tokens are:\n",
      "momma: 10\n",
      "hey: 10\n",
      "look: 6\n",
      "sharp: 6\n",
      "ill: 3\n",
      "[80, 42, 0.525, 335]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 86 tokens in the data.\n",
      "There are 37 unique tokens in the data.\n",
      "There are 384 characters in the data.\n",
      "The lexical diversity is 0.430 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 7\n",
      "loving: 6\n",
      "oh: 4\n",
      "youre: 3\n",
      "youll: 3\n",
      "[86, 37, 0.43023255813953487, 384]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 77 tokens in the data.\n",
      "There are 18 unique tokens in the data.\n",
      "There are 323 characters in the data.\n",
      "The lexical diversity is 0.234 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 23\n",
      "way: 9\n",
      "move: 8\n",
      "keep: 6\n",
      "groove: 4\n",
      "[77, 18, 0.23376623376623376, 323]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 434 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 8\n",
      "change: 6\n",
      "strange: 5\n",
      "ask: 4\n",
      "face: 3\n",
      "[87, 58, 0.6666666666666666, 434]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 83 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 373 characters in the data.\n",
      "The lexical diversity is 0.337 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 32\n",
      "good: 10\n",
      "oh: 8\n",
      "everywhere: 4\n",
      "understood: 3\n",
      "[83, 28, 0.3373493975903614, 373]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 114 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 526 characters in the data.\n",
      "The lexical diversity is 0.421 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 29\n",
      "know: 6\n",
      "youre: 5\n",
      "feel: 5\n",
      "somewhere: 4\n",
      "[114, 48, 0.42105263157894735, 526]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 116 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 508 characters in the data.\n",
      "The lexical diversity is 0.578 in the data.\n",
      "The 5 most common tokens are:\n",
      "far: 9\n",
      "gone: 9\n",
      "know: 9\n",
      "doesnt: 5\n",
      "son: 4\n",
      "[116, 67, 0.5775862068965517, 508]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 514 characters in the data.\n",
      "The lexical diversity is 0.566 in the data.\n",
      "The 5 most common tokens are:\n",
      "needles: 7\n",
      "pins: 7\n",
      "stop: 5\n",
      "saw: 4\n",
      "face: 4\n",
      "[113, 64, 0.5663716814159292, 514]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 88 tokens in the data.\n",
      "There are 39 unique tokens in the data.\n",
      "There are 437 characters in the data.\n",
      "The lexical diversity is 0.443 in the data.\n",
      "The 5 most common tokens are:\n",
      "never: 8\n",
      "well: 8\n",
      "dont: 4\n",
      "oklahoma: 4\n",
      "matter: 4\n",
      "[88, 39, 0.4431818181818182, 437]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 463 characters in the data.\n",
      "The lexical diversity is 0.676 in the data.\n",
      "The 5 most common tokens are:\n",
      "cant: 7\n",
      "wait: 6\n",
      "holy: 5\n",
      "mother: 5\n",
      "ive: 3\n",
      "[102, 69, 0.6764705882352942, 463]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 130 tokens in the data.\n",
      "There are 79 unique tokens in the data.\n",
      "There are 666 characters in the data.\n",
      "The lexical diversity is 0.608 in the data.\n",
      "The 5 most common tokens are:\n",
      "world: 5\n",
      "know: 5\n",
      "enough: 4\n",
      "love: 4\n",
      "either: 4\n",
      "[130, 79, 0.6076923076923076, 666]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 126 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 564 characters in the data.\n",
      "The lexical diversity is 0.659 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 6\n",
      "river: 6\n",
      "dont: 6\n",
      "ol: 5\n",
      "keeps: 4\n",
      "[126, 83, 0.6587301587301587, 564]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 501 characters in the data.\n",
      "The lexical diversity is 0.518 in the data.\n",
      "The 5 most common tokens are:\n",
      "one: 19\n",
      "love: 6\n",
      "end: 4\n",
      "much: 4\n",
      "take: 4\n",
      "[110, 57, 0.5181818181818182, 501]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 116 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 551 characters in the data.\n",
      "The lexical diversity is 0.388 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 13\n",
      "cant: 13\n",
      "find: 12\n",
      "one: 11\n",
      "honest: 11\n",
      "[116, 45, 0.3879310344827586, 551]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 117 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 595 characters in the data.\n",
      "The lexical diversity is 0.462 in the data.\n",
      "The 5 most common tokens are:\n",
      "one: 13\n",
      "us: 13\n",
      "lonely: 5\n",
      "wishing: 5\n",
      "feeling: 4\n",
      "[117, 54, 0.46153846153846156, 595]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 131 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 596 characters in the data.\n",
      "The lexical diversity is 0.412 in the data.\n",
      "The 5 most common tokens are:\n",
      "one: 18\n",
      "step: 17\n",
      "small: 16\n",
      "time: 7\n",
      "weve: 5\n",
      "[131, 54, 0.4122137404580153, 596]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 108 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 467 characters in the data.\n",
      "The lexical diversity is 0.370 in the data.\n",
      "The 5 most common tokens are:\n",
      "ooga: 38\n",
      "boo: 13\n",
      "find: 7\n",
      "go: 5\n",
      "heres: 4\n",
      "[108, 40, 0.37037037037037035, 467]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 49 tokens in the data.\n",
      "There are 25 unique tokens in the data.\n",
      "There are 208 characters in the data.\n",
      "The lexical diversity is 0.510 in the data.\n",
      "The 5 most common tokens are:\n",
      "come: 7\n",
      "love: 6\n",
      "day: 5\n",
      "well: 4\n",
      "wait: 2\n",
      "[49, 25, 0.5102040816326531, 208]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 94 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 467 characters in the data.\n",
      "The lexical diversity is 0.755 in the data.\n",
      "The 5 most common tokens are:\n",
      "san: 4\n",
      "francisco: 4\n",
      "day: 4\n",
      "lady: 3\n",
      "met: 3\n",
      "[94, 71, 0.7553191489361702, 467]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 128 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 662 characters in the data.\n",
      "The lexical diversity is 0.547 in the data.\n",
      "The 5 most common tokens are:\n",
      "outrageous: 16\n",
      "im: 12\n",
      "rage: 7\n",
      "gonna: 6\n",
      "say: 3\n",
      "[128, 70, 0.546875, 662]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 115 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 598 characters in the data.\n",
      "The lexical diversity is 0.565 in the data.\n",
      "The 5 most common tokens are:\n",
      "need: 8\n",
      "right: 8\n",
      "paradise: 5\n",
      "loving: 5\n",
      "dont: 4\n",
      "[115, 65, 0.5652173913043478, 598]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 241 tokens in the data.\n",
      "There are 87 unique tokens in the data.\n",
      "There are 1244 characters in the data.\n",
      "The lexical diversity is 0.361 in the data.\n",
      "The 5 most common tokens are:\n",
      "perfection: 18\n",
      "love: 15\n",
      "ive: 13\n",
      "driven: 11\n",
      "know: 9\n",
      "[241, 87, 0.36099585062240663, 1244]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 84 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 376 characters in the data.\n",
      "The lexical diversity is 0.393 in the data.\n",
      "The 5 most common tokens are:\n",
      "pied: 9\n",
      "piper: 9\n",
      "im: 8\n",
      "follow: 6\n",
      "babe: 5\n",
      "[84, 33, 0.39285714285714285, 376]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 144 tokens in the data.\n",
      "There are 78 unique tokens in the data.\n",
      "There are 637 characters in the data.\n",
      "The lexical diversity is 0.542 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 11\n",
      "pirate: 8\n",
      "know: 8\n",
      "much: 5\n",
      "sea: 5\n",
      "[144, 78, 0.5416666666666666, 637]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 46 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 200 characters in the data.\n",
      "The lexical diversity is 0.783 in the data.\n",
      "The 5 most common tokens are:\n",
      "far: 2\n",
      "time: 2\n",
      "see: 2\n",
      "drift: 2\n",
      "machine: 2\n",
      "[46, 36, 0.782608695652174, 200]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 150 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 662 characters in the data.\n",
      "The lexical diversity is 0.333 in the data.\n",
      "The 5 most common tokens are:\n",
      "oh: 22\n",
      "pride: 12\n",
      "night: 8\n",
      "wont: 8\n",
      "stop: 8\n",
      "[150, 50, 0.3333333333333333, 662]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 154 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 761 characters in the data.\n",
      "The lexical diversity is 0.338 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 18\n",
      "prisoner: 12\n",
      "love: 10\n",
      "hey: 8\n",
      "got: 4\n",
      "[154, 52, 0.33766233766233766, 761]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 484 characters in the data.\n",
      "The lexical diversity is 0.723 in the data.\n",
      "The 5 most common tokens are:\n",
      "rain: 15\n",
      "ooh: 3\n",
      "see: 3\n",
      "youre: 3\n",
      "chorus: 3\n",
      "[101, 73, 0.7227722772277227, 484]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 547 characters in the data.\n",
      "The lexical diversity is 0.281 in the data.\n",
      "The 5 most common tokens are:\n",
      "time: 20\n",
      "love: 18\n",
      "real: 9\n",
      "still: 8\n",
      "believe: 8\n",
      "[121, 34, 0.2809917355371901, 547]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 378 characters in the data.\n",
      "The lexical diversity is 0.479 in the data.\n",
      "The 5 most common tokens are:\n",
      "believe: 6\n",
      "find: 6\n",
      "reason: 4\n",
      "id: 3\n",
      "way: 3\n",
      "[73, 35, 0.4794520547945205, 378]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 144 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 626 characters in the data.\n",
      "The lexical diversity is 0.424 in the data.\n",
      "The 5 most common tokens are:\n",
      "red: 27\n",
      "see: 9\n",
      "like: 5\n",
      "around: 4\n",
      "heart: 4\n",
      "[144, 61, 0.4236111111111111, 626]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 25 unique tokens in the data.\n",
      "There are 435 characters in the data.\n",
      "The lexical diversity is 0.245 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 13\n",
      "rescue: 10\n",
      "come: 10\n",
      "im: 9\n",
      "lonely: 7\n",
      "[102, 25, 0.24509803921568626, 435]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 154 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 693 characters in the data.\n",
      "The lexical diversity is 0.519 in the data.\n",
      "The 5 most common tokens are:\n",
      "feel: 8\n",
      "fine: 8\n",
      "hes: 7\n",
      "beat: 6\n",
      "rock: 5\n",
      "[154, 80, 0.5194805194805194, 693]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 131 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 659 characters in the data.\n",
      "The lexical diversity is 0.351 in the data.\n",
      "The 5 most common tokens are:\n",
      "rudy: 19\n",
      "youre: 16\n",
      "still: 8\n",
      "always: 8\n",
      "mind: 8\n",
      "[131, 46, 0.3511450381679389, 659]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 135 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 713 characters in the data.\n",
      "The lexical diversity is 0.311 in the data.\n",
      "The 5 most common tokens are:\n",
      "runaway: 23\n",
      "cant: 12\n",
      "love: 11\n",
      "find: 10\n",
      "gotta: 9\n",
      "[135, 42, 0.3111111111111111, 713]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 153 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 699 characters in the data.\n",
      "The lexical diversity is 0.536 in the data.\n",
      "The 5 most common tokens are:\n",
      "runnin: 25\n",
      "sail: 9\n",
      "keep: 5\n",
      "like: 5\n",
      "cant: 4\n",
      "[153, 82, 0.5359477124183006, 699]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 76 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 424 characters in the data.\n",
      "The lexical diversity is 0.842 in the data.\n",
      "The 5 most common tokens are:\n",
      "eyes: 4\n",
      "dont: 3\n",
      "youre: 3\n",
      "im: 2\n",
      "long: 2\n",
      "[76, 64, 0.8421052631578947, 424]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 197 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 877 characters in the data.\n",
      "The lexical diversity is 0.320 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 17\n",
      "tears: 13\n",
      "know: 13\n",
      "cryin: 13\n",
      "youll: 12\n",
      "[197, 63, 0.3197969543147208, 877]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 497 characters in the data.\n",
      "The lexical diversity is 0.604 in the data.\n",
      "The 5 most common tokens are:\n",
      "blade: 7\n",
      "think: 6\n",
      "see: 6\n",
      "big: 6\n",
      "im: 4\n",
      "[101, 61, 0.6039603960396039, 497]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 117 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 539 characters in the data.\n",
      "The lexical diversity is 0.427 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 11\n",
      "want: 8\n",
      "dont: 7\n",
      "say: 6\n",
      "whats: 6\n",
      "[117, 50, 0.42735042735042733, 539]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 138 tokens in the data.\n",
      "There are 99 unique tokens in the data.\n",
      "There are 740 characters in the data.\n",
      "The lexical diversity is 0.717 in the data.\n",
      "The 5 most common tokens are:\n",
      "send: 5\n",
      "today: 4\n",
      "man: 3\n",
      "call: 3\n",
      "say: 3\n",
      "[138, 99, 0.717391304347826, 740]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 67 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 350 characters in the data.\n",
      "The lexical diversity is 0.687 in the data.\n",
      "The 5 most common tokens are:\n",
      "yeah: 5\n",
      "princess: 4\n",
      "prince: 4\n",
      "shadow: 3\n",
      "meant: 3\n",
      "[67, 46, 0.6865671641791045, 350]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 142 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 655 characters in the data.\n",
      "The lexical diversity is 0.387 in the data.\n",
      "The 5 most common tokens are:\n",
      "things: 19\n",
      "come: 17\n",
      "shape: 16\n",
      "two: 8\n",
      "one: 5\n",
      "[142, 55, 0.3873239436619718, 655]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 154 tokens in the data.\n",
      "There are 91 unique tokens in the data.\n",
      "There are 745 characters in the data.\n",
      "The lexical diversity is 0.591 in the data.\n",
      "The 5 most common tokens are:\n",
      "loves: 8\n",
      "shes: 8\n",
      "hear: 7\n",
      "music: 6\n",
      "got: 6\n",
      "[154, 91, 0.5909090909090909, 745]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 226 tokens in the data.\n",
      "There are 128 unique tokens in the data.\n",
      "There are 1117 characters in the data.\n",
      "The lexical diversity is 0.566 in the data.\n",
      "The 5 most common tokens are:\n",
      "shoppin: 26\n",
      "im: 14\n",
      "gonna: 8\n",
      "buy: 4\n",
      "blues: 4\n",
      "[226, 128, 0.5663716814159292, 1117]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 109 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 525 characters in the data.\n",
      "The lexical diversity is 0.771 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 4\n",
      "back: 4\n",
      "silver: 3\n",
      "wings: 3\n",
      "golden: 3\n",
      "[109, 84, 0.7706422018348624, 525]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 88 tokens in the data.\n",
      "There are 39 unique tokens in the data.\n",
      "There are 439 characters in the data.\n",
      "The lexical diversity is 0.443 in the data.\n",
      "The 5 most common tokens are:\n",
      "sing: 9\n",
      "youll: 8\n",
      "supper: 4\n",
      "get: 4\n",
      "swallow: 4\n",
      "[88, 39, 0.4431818181818182, 439]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 481 characters in the data.\n",
      "The lexical diversity is 0.446 in the data.\n",
      "The 5 most common tokens are:\n",
      "sirens: 7\n",
      "sound: 6\n",
      "sky: 3\n",
      "leave: 3\n",
      "behind: 3\n",
      "[101, 45, 0.44554455445544555, 481]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 184 tokens in the data.\n",
      "There are 116 unique tokens in the data.\n",
      "There are 971 characters in the data.\n",
      "The lexical diversity is 0.630 in the data.\n",
      "The 5 most common tokens are:\n",
      "mercy: 17\n",
      "sisters: 9\n",
      "grace: 6\n",
      "place: 6\n",
      "shows: 5\n",
      "[184, 116, 0.6304347826086957, 971]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 97 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 456 characters in the data.\n",
      "The lexical diversity is 0.495 in the data.\n",
      "The 5 most common tokens are:\n",
      "sittin: 9\n",
      "dock: 8\n",
      "bay: 8\n",
      "roll: 5\n",
      "watchin: 4\n",
      "[97, 48, 0.4948453608247423, 456]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 149 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 655 characters in the data.\n",
      "The lexical diversity is 0.356 in the data.\n",
      "The 5 most common tokens are:\n",
      "skin: 16\n",
      "deep: 16\n",
      "bone: 13\n",
      "im: 9\n",
      "go: 8\n",
      "[149, 53, 0.35570469798657717, 655]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 74 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 378 characters in the data.\n",
      "The lexical diversity is 0.581 in the data.\n",
      "The 5 most common tokens are:\n",
      "children: 6\n",
      "still: 5\n",
      "time: 4\n",
      "close: 3\n",
      "theres: 3\n",
      "[74, 43, 0.581081081081081, 378]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 84 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 425 characters in the data.\n",
      "The lexical diversity is 0.655 in the data.\n",
      "The 5 most common tokens are:\n",
      "song: 7\n",
      "singing: 6\n",
      "life: 4\n",
      "ive: 3\n",
      "alone: 3\n",
      "[84, 55, 0.6547619047619048, 425]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 507 characters in the data.\n",
      "The lexical diversity is 0.400 in the data.\n",
      "The 5 most common tokens are:\n",
      "youre: 11\n",
      "gone: 8\n",
      "try: 8\n",
      "love: 5\n",
      "though: 5\n",
      "[110, 44, 0.4, 507]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 147 tokens in the data.\n",
      "There are 91 unique tokens in the data.\n",
      "There are 737 characters in the data.\n",
      "The lexical diversity is 0.619 in the data.\n",
      "The 5 most common tokens are:\n",
      "spring: 10\n",
      "long: 10\n",
      "time: 7\n",
      "said: 4\n",
      "ah: 4\n",
      "[147, 91, 0.6190476190476191, 737]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 160 tokens in the data.\n",
      "There are 106 unique tokens in the data.\n",
      "There are 774 characters in the data.\n",
      "The lexical diversity is 0.662 in the data.\n",
      "The 5 most common tokens are:\n",
      "come: 9\n",
      "never: 6\n",
      "singing: 5\n",
      "go: 4\n",
      "make: 4\n",
      "[160, 106, 0.6625, 774]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 129 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 648 characters in the data.\n",
      "The lexical diversity is 0.589 in the data.\n",
      "The 5 most common tokens are:\n",
      "startin: 12\n",
      "back: 6\n",
      "let: 4\n",
      "time: 4\n",
      "around: 4\n",
      "[129, 76, 0.5891472868217055, 648]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 122 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 611 characters in the data.\n",
      "The lexical diversity is 0.467 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 15\n",
      "still: 12\n",
      "baby: 6\n",
      "oh: 5\n",
      "cried: 4\n",
      "[122, 57, 0.4672131147540984, 611]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 99 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 447 characters in the data.\n",
      "The lexical diversity is 0.465 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 11\n",
      "still: 9\n",
      "love: 9\n",
      "lying: 6\n",
      "ive: 5\n",
      "[99, 46, 0.46464646464646464, 447]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 175 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 822 characters in the data.\n",
      "The lexical diversity is 0.354 in the data.\n",
      "The 5 most common tokens are:\n",
      "enough: 20\n",
      "strong: 16\n",
      "im: 13\n",
      "say: 7\n",
      "know: 7\n",
      "[175, 62, 0.35428571428571426, 822]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 80 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 364 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "sunny: 14\n",
      "love: 8\n",
      "thank: 6\n",
      "true: 4\n",
      "gave: 4\n",
      "[80, 40, 0.5, 364]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 388 characters in the data.\n",
      "The lexical diversity is 0.495 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 11\n",
      "ah: 7\n",
      "oh: 6\n",
      "love: 5\n",
      "ooh: 5\n",
      "[93, 46, 0.4946236559139785, 388]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 211 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 998 characters in the data.\n",
      "The lexical diversity is 0.336 in the data.\n",
      "The 5 most common tokens are:\n",
      "take: 31\n",
      "boys: 31\n",
      "well: 10\n",
      "might: 9\n",
      "wise: 9\n",
      "[211, 71, 0.33649289099526064, 998]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 196 tokens in the data.\n",
      "There are 77 unique tokens in the data.\n",
      "There are 883 characters in the data.\n",
      "The lexical diversity is 0.393 in the data.\n",
      "The 5 most common tokens are:\n",
      "gotta: 11\n",
      "heart: 10\n",
      "take: 9\n",
      "like: 9\n",
      "man: 9\n",
      "[196, 77, 0.39285714285714285, 883]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 55 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 256 characters in the data.\n",
      "The lexical diversity is 0.727 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 5\n",
      "little: 3\n",
      "dont: 3\n",
      "forever: 3\n",
      "take: 2\n",
      "[55, 40, 0.7272727272727273, 256]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 222 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 987 characters in the data.\n",
      "The lexical diversity is 0.248 in the data.\n",
      "The 5 most common tokens are:\n",
      "home: 39\n",
      "take: 37\n",
      "heaven: 11\n",
      "wanna: 7\n",
      "baby: 7\n",
      "[222, 55, 0.24774774774774774, 987]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 237 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 1128 characters in the data.\n",
      "The lexical diversity is 0.291 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 27\n",
      "baby: 25\n",
      "heart: 23\n",
      "takin: 17\n",
      "im: 15\n",
      "[237, 69, 0.2911392405063291, 1128]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 179 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 802 characters in the data.\n",
      "The lexical diversity is 0.324 in the data.\n",
      "The 5 most common tokens are:\n",
      "taxi: 32\n",
      "ride: 18\n",
      "im: 17\n",
      "gonna: 17\n",
      "night: 13\n",
      "[179, 58, 0.3240223463687151, 802]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 76 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 363 characters in the data.\n",
      "The lexical diversity is 0.368 in the data.\n",
      "The 5 most common tokens are:\n",
      "bells: 13\n",
      "say: 12\n",
      "rhymney: 5\n",
      "give: 4\n",
      "sad: 4\n",
      "[76, 28, 0.3684210526315789, 363]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 105 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 483 characters in the data.\n",
      "The lexical diversity is 0.571 in the data.\n",
      "The 5 most common tokens are:\n",
      "bigger: 5\n",
      "come: 5\n",
      "harder: 5\n",
      "fall: 5\n",
      "oh: 4\n",
      "[105, 60, 0.5714285714285714, 483]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 132 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 651 characters in the data.\n",
      "The lexical diversity is 0.576 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 15\n",
      "book: 13\n",
      "writing: 6\n",
      "heyho: 3\n",
      "broken: 3\n",
      "[132, 76, 0.5757575757575758, 651]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 339 characters in the data.\n",
      "The lexical diversity is 0.577 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 6\n",
      "wont: 4\n",
      "let: 4\n",
      "go: 4\n",
      "ill: 4\n",
      "[78, 45, 0.5769230769230769, 339]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 108 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 544 characters in the data.\n",
      "The lexical diversity is 0.778 in the data.\n",
      "The 5 most common tokens are:\n",
      "heard: 3\n",
      "news: 3\n",
      "fall: 2\n",
      "knew: 2\n",
      "well: 2\n",
      "[108, 84, 0.7777777777777778, 544]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 49 unique tokens in the data.\n",
      "There are 311 characters in the data.\n",
      "The lexical diversity is 0.671 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 4\n",
      "think: 3\n",
      "see: 3\n",
      "anymore: 3\n",
      "know: 3\n",
      "[73, 49, 0.6712328767123288, 311]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 85 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 401 characters in the data.\n",
      "The lexical diversity is 0.471 in the data.\n",
      "The 5 most common tokens are:\n",
      "passes: 6\n",
      "goes: 5\n",
      "girl: 4\n",
      "ipanema: 4\n",
      "tall: 3\n",
      "[85, 40, 0.47058823529411764, 401]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 99 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 474 characters in the data.\n",
      "The lexical diversity is 0.727 in the data.\n",
      "The 5 most common tokens are:\n",
      "ever: 8\n",
      "greatest: 4\n",
      "song: 4\n",
      "heard: 4\n",
      "ive: 3\n",
      "[99, 72, 0.7272727272727273, 474]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 203 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 1031 characters in the data.\n",
      "The lexical diversity is 0.286 in the data.\n",
      "The 5 most common tokens are:\n",
      "greatest: 20\n",
      "thing: 14\n",
      "youre: 12\n",
      "see: 8\n",
      "ill: 8\n",
      "[203, 58, 0.2857142857142857, 1031]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 90 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 428 characters in the data.\n",
      "The lexical diversity is 0.533 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 11\n",
      "gunman: 10\n",
      "mercy: 5\n",
      "time: 3\n",
      "sights: 3\n",
      "[90, 48, 0.5333333333333333, 428]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 398 characters in the data.\n",
      "The lexical diversity is 0.460 in the data.\n",
      "The 5 most common tokens are:\n",
      "long: 9\n",
      "road: 6\n",
      "winding: 5\n",
      "door: 4\n",
      "standing: 4\n",
      "[87, 40, 0.45977011494252873, 398]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 105 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 458 characters in the data.\n",
      "The lexical diversity is 0.486 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 7\n",
      "hes: 6\n",
      "man: 5\n",
      "love: 4\n",
      "ill: 4\n",
      "[105, 51, 0.4857142857142857, 458]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 88 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 429 characters in the data.\n",
      "The lexical diversity is 0.841 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 5\n",
      "got: 3\n",
      "away: 3\n",
      "night: 2\n",
      "dreams: 2\n",
      "[88, 74, 0.8409090909090909, 429]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 450 characters in the data.\n",
      "The lexical diversity is 0.759 in the data.\n",
      "The 5 most common tokens are:\n",
      "good: 5\n",
      "musics: 4\n",
      "chorus: 4\n",
      "come: 4\n",
      "back: 4\n",
      "[87, 66, 0.7586206896551724, 450]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 226 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 1076 characters in the data.\n",
      "The lexical diversity is 0.319 in the data.\n",
      "The 5 most common tokens are:\n",
      "doodoo: 28\n",
      "name: 11\n",
      "game: 11\n",
      "whats: 9\n",
      "know: 7\n",
      "[226, 72, 0.3185840707964602, 1076]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 706 characters in the data.\n",
      "The lexical diversity is 0.493 in the data.\n",
      "The 5 most common tokens are:\n",
      "power: 14\n",
      "every: 6\n",
      "believe: 5\n",
      "holds: 4\n",
      "hand: 4\n",
      "[146, 72, 0.4931506849315068, 706]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 67 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 320 characters in the data.\n",
      "The lexical diversity is 0.493 in the data.\n",
      "The 5 most common tokens are:\n",
      "show: 14\n",
      "fortune: 5\n",
      "ill: 4\n",
      "young: 4\n",
      "many: 4\n",
      "[67, 33, 0.4925373134328358, 320]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 123 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 577 characters in the data.\n",
      "The lexical diversity is 0.512 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 7\n",
      "love: 6\n",
      "sometimes: 6\n",
      "mistake: 5\n",
      "give: 5\n",
      "[123, 63, 0.5121951219512195, 577]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 82 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 386 characters in the data.\n",
      "The lexical diversity is 0.659 in the data.\n",
      "The 5 most common tokens are:\n",
      "days: 9\n",
      "ive: 5\n",
      "oh: 5\n",
      "well: 4\n",
      "forgotten: 3\n",
      "[82, 54, 0.6585365853658537, 386]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 409 characters in the data.\n",
      "The lexical diversity is 0.355 in the data.\n",
      "The 5 most common tokens are:\n",
      "thats: 14\n",
      "kiss: 13\n",
      "know: 7\n",
      "oh: 6\n",
      "want: 5\n",
      "[93, 33, 0.3548387096774194, 409]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 118 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 581 characters in the data.\n",
      "The lexical diversity is 0.288 in the data.\n",
      "The 5 most common tokens are:\n",
      "aint: 11\n",
      "gonna: 11\n",
      "always: 7\n",
      "sun: 6\n",
      "shine: 6\n",
      "[118, 34, 0.288135593220339, 581]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 71 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 408 characters in the data.\n",
      "The lexical diversity is 0.775 in the data.\n",
      "The 5 most common tokens are:\n",
      "thought: 4\n",
      "loving: 4\n",
      "right: 4\n",
      "way: 2\n",
      "im: 2\n",
      "[71, 55, 0.7746478873239436, 408]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 127 tokens in the data.\n",
      "There are 98 unique tokens in the data.\n",
      "There are 675 characters in the data.\n",
      "The lexical diversity is 0.772 in the data.\n",
      "The 5 most common tokens are:\n",
      "times: 6\n",
      "achangin: 6\n",
      "come: 5\n",
      "dont: 4\n",
      "later: 4\n",
      "[127, 98, 0.7716535433070866, 675]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 72 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 330 characters in the data.\n",
      "The lexical diversity is 0.569 in the data.\n",
      "The 5 most common tokens are:\n",
      "long: 7\n",
      "never: 6\n",
      "twelfth: 5\n",
      "love: 4\n",
      "ill: 3\n",
      "[72, 41, 0.5694444444444444, 330]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 71 tokens in the data.\n",
      "There are 30 unique tokens in the data.\n",
      "There are 280 characters in the data.\n",
      "The lexical diversity is 0.423 in the data.\n",
      "The 5 most common tokens are:\n",
      "way: 9\n",
      "love: 7\n",
      "meet: 2\n",
      "boy: 2\n",
      "like: 2\n",
      "[71, 30, 0.4225352112676056, 280]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 143 tokens in the data.\n",
      "There are 98 unique tokens in the data.\n",
      "There are 751 characters in the data.\n",
      "The lexical diversity is 0.685 in the data.\n",
      "The 5 most common tokens are:\n",
      "takes: 9\n",
      "winner: 7\n",
      "small: 5\n",
      "standing: 3\n",
      "feel: 3\n",
      "[143, 98, 0.6853146853146853, 751]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 112 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 562 characters in the data.\n",
      "The lexical diversity is 0.714 in the data.\n",
      "The 5 most common tokens are:\n",
      "godforsaken: 5\n",
      "day: 5\n",
      "youve: 5\n",
      "gone: 5\n",
      "away: 5\n",
      "[112, 80, 0.7142857142857143, 562]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 116 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 581 characters in the data.\n",
      "The lexical diversity is 0.595 in the data.\n",
      "The 5 most common tokens are:\n",
      "song: 7\n",
      "lonely: 6\n",
      "hear: 4\n",
      "dont: 4\n",
      "gonna: 4\n",
      "[116, 69, 0.5948275862068966, 581]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 112 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 581 characters in the data.\n",
      "The lexical diversity is 0.571 in the data.\n",
      "The 5 most common tokens are:\n",
      "thunderstorm: 4\n",
      "good: 4\n",
      "feel: 4\n",
      "knew: 3\n",
      "coming: 3\n",
      "[112, 64, 0.5714285714285714, 581]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 357 characters in the data.\n",
      "The lexical diversity is 0.551 in the data.\n",
      "The 5 most common tokens are:\n",
      "time: 9\n",
      "people: 5\n",
      "go: 5\n",
      "oh: 4\n",
      "good: 4\n",
      "[78, 43, 0.5512820512820513, 357]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 389 characters in the data.\n",
      "The lexical diversity is 0.630 in the data.\n",
      "The 5 most common tokens are:\n",
      "throw: 6\n",
      "tonight: 5\n",
      "ill: 5\n",
      "staying: 5\n",
      "cause: 3\n",
      "[73, 46, 0.6301369863013698, 389]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 85 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 367 characters in the data.\n",
      "The lexical diversity is 0.424 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 6\n",
      "touch: 5\n",
      "go: 5\n",
      "weak: 4\n",
      "strong: 4\n",
      "[85, 36, 0.4235294117647059, 367]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 130 tokens in the data.\n",
      "There are 81 unique tokens in the data.\n",
      "There are 616 characters in the data.\n",
      "The lexical diversity is 0.623 in the data.\n",
      "The 5 most common tokens are:\n",
      "gotta: 10\n",
      "get: 10\n",
      "train: 7\n",
      "thought: 5\n",
      "time: 4\n",
      "[130, 81, 0.6230769230769231, 616]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 63 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 316 characters in the data.\n",
      "The lexical diversity is 0.857 in the data.\n",
      "The 5 most common tokens are:\n",
      "two: 2\n",
      "people: 2\n",
      "clinging: 2\n",
      "thread: 2\n",
      "wake: 2\n",
      "[63, 54, 0.8571428571428571, 316]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 69 tokens in the data.\n",
      "There are 49 unique tokens in the data.\n",
      "There are 299 characters in the data.\n",
      "The lexical diversity is 0.710 in the data.\n",
      "The 5 most common tokens are:\n",
      "time: 4\n",
      "go: 4\n",
      "youre: 3\n",
      "im: 3\n",
      "stay: 3\n",
      "[69, 49, 0.7101449275362319, 299]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 175 tokens in the data.\n",
      "There are 85 unique tokens in the data.\n",
      "There are 917 characters in the data.\n",
      "The lexical diversity is 0.486 in the data.\n",
      "The 5 most common tokens are:\n",
      "walking: 22\n",
      "memphis: 18\n",
      "feet: 10\n",
      "feel: 10\n",
      "got: 5\n",
      "[175, 85, 0.4857142857142857, 917]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 436 characters in the data.\n",
      "The lexical diversity is 0.430 in the data.\n",
      "The 5 most common tokens are:\n",
      "walk: 17\n",
      "take: 4\n",
      "hand: 4\n",
      "count: 4\n",
      "troubles: 4\n",
      "[93, 40, 0.43010752688172044, 436]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 141 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 712 characters in the data.\n",
      "The lexical diversity is 0.426 in the data.\n",
      "The 5 most common tokens are:\n",
      "see: 9\n",
      "walls: 8\n",
      "wanna: 8\n",
      "crashing: 7\n",
      "cause: 6\n",
      "[141, 60, 0.425531914893617, 712]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 176 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 941 characters in the data.\n",
      "The lexical diversity is 0.432 in the data.\n",
      "The 5 most common tokens are:\n",
      "war: 9\n",
      "paint: 9\n",
      "soft: 9\n",
      "feathers: 9\n",
      "love: 6\n",
      "[176, 76, 0.4318181818181818, 941]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 144 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 683 characters in the data.\n",
      "The lexical diversity is 0.458 in the data.\n",
      "The 5 most common tokens are:\n",
      "good: 16\n",
      "wasnt: 9\n",
      "know: 6\n",
      "party: 5\n",
      "baby: 5\n",
      "[144, 66, 0.4583333333333333, 683]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 107 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 619 characters in the data.\n",
      "The lexical diversity is 0.402 in the data.\n",
      "The 5 most common tokens are:\n",
      "waterloo: 21\n",
      "woah: 8\n",
      "ever: 4\n",
      "knowing: 4\n",
      "fate: 4\n",
      "[107, 43, 0.40186915887850466, 619]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 79 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 370 characters in the data.\n",
      "The lexical diversity is 0.532 in the data.\n",
      "The 5 most common tokens are:\n",
      "fly: 7\n",
      "home: 7\n",
      "well: 4\n",
      "sooner: 4\n",
      "later: 4\n",
      "[79, 42, 0.5316455696202531, 370]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 471 characters in the data.\n",
      "The lexical diversity is 0.613 in the data.\n",
      "The 5 most common tokens are:\n",
      "alone: 9\n",
      "sleep: 8\n",
      "youre: 3\n",
      "sooner: 3\n",
      "later: 3\n",
      "[93, 57, 0.6129032258064516, 471]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 91 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 497 characters in the data.\n",
      "The lexical diversity is 0.637 in the data.\n",
      "The 5 most common tokens are:\n",
      "little: 8\n",
      "welcome: 6\n",
      "burlesque: 6\n",
      "show: 4\n",
      "less: 2\n",
      "[91, 58, 0.6373626373626373, 497]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 117 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 497 characters in the data.\n",
      "The lexical diversity is 0.462 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 16\n",
      "make: 16\n",
      "know: 9\n",
      "got: 6\n",
      "may: 5\n",
      "[117, 54, 0.46153846153846156, 497]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 106 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 577 characters in the data.\n",
      "The lexical diversity is 0.585 in the data.\n",
      "The 5 most common tokens are:\n",
      "moonlight: 6\n",
      "way: 6\n",
      "loves: 5\n",
      "dreams: 5\n",
      "change: 5\n",
      "[106, 62, 0.5849056603773585, 577]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 25 tokens in the data.\n",
      "There are 15 unique tokens in the data.\n",
      "There are 133 characters in the data.\n",
      "The lexical diversity is 0.600 in the data.\n",
      "The 5 most common tokens are:\n",
      "whatll: 8\n",
      "far: 2\n",
      "away: 2\n",
      "blue: 2\n",
      "im: 1\n",
      "[25, 15, 0.6, 133]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 139 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 674 characters in the data.\n",
      "The lexical diversity is 0.489 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 11\n",
      "calls: 11\n",
      "name: 11\n",
      "theres: 4\n",
      "way: 4\n",
      "[139, 68, 0.4892086330935252, 674]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 160 tokens in the data.\n",
      "There are 75 unique tokens in the data.\n",
      "There are 847 characters in the data.\n",
      "The lexical diversity is 0.469 in the data.\n",
      "The 5 most common tokens are:\n",
      "shame: 13\n",
      "lovers: 9\n",
      "become: 9\n",
      "strangers: 9\n",
      "dont: 7\n",
      "[160, 75, 0.46875, 847]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 119 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 557 characters in the data.\n",
      "The lexical diversity is 0.513 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 12\n",
      "gone: 10\n",
      "gotta: 7\n",
      "theres: 5\n",
      "strong: 4\n",
      "[119, 61, 0.5126050420168067, 557]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 109 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 493 characters in the data.\n",
      "The lexical diversity is 0.697 in the data.\n",
      "The 5 most common tokens are:\n",
      "moneys: 9\n",
      "gone: 9\n",
      "still: 4\n",
      "oh: 4\n",
      "want: 3\n",
      "[109, 76, 0.6972477064220184, 493]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 82 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 358 characters in the data.\n",
      "The lexical diversity is 0.573 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 8\n",
      "find: 7\n",
      "youre: 7\n",
      "goin: 6\n",
      "let: 6\n",
      "[82, 47, 0.573170731707317, 358]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 173 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 785 characters in the data.\n",
      "The lexical diversity is 0.324 in the data.\n",
      "The 5 most common tokens are:\n",
      "walk: 25\n",
      "away: 19\n",
      "wont: 11\n",
      "crying: 6\n",
      "cause: 5\n",
      "[173, 56, 0.3236994219653179, 785]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 58 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 237 characters in the data.\n",
      "The lexical diversity is 0.724 in the data.\n",
      "The 5 most common tokens are:\n",
      "go: 5\n",
      "dont: 4\n",
      "know: 4\n",
      "right: 3\n",
      "youre: 2\n",
      "[58, 42, 0.7241379310344828, 237]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 81 unique tokens in the data.\n",
      "There are 722 characters in the data.\n",
      "The lexical diversity is 0.555 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 13\n",
      "believe: 10\n",
      "oh: 5\n",
      "love: 4\n",
      "hope: 4\n",
      "[146, 81, 0.5547945205479452, 722]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 45 tokens in the data.\n",
      "There are 24 unique tokens in the data.\n",
      "There are 188 characters in the data.\n",
      "The lexical diversity is 0.533 in the data.\n",
      "The 5 most common tokens are:\n",
      "born: 4\n",
      "tell: 3\n",
      "im: 3\n",
      "hope: 2\n",
      "try: 2\n",
      "[45, 24, 0.5333333333333333, 188]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 60 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 318 characters in the data.\n",
      "The lexical diversity is 0.583 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 11\n",
      "tomorrow: 7\n",
      "still: 5\n",
      "tonight: 3\n",
      "tell: 2\n",
      "[60, 35, 0.5833333333333334, 318]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 130 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 618 characters in the data.\n",
      "The lexical diversity is 0.508 in the data.\n",
      "The 5 most common tokens are:\n",
      "wait: 12\n",
      "know: 6\n",
      "feels: 6\n",
      "love: 5\n",
      "youre: 4\n",
      "[130, 66, 0.5076923076923077, 618]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 99 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 499 characters in the data.\n",
      "The lexical diversity is 0.687 in the data.\n",
      "The 5 most common tokens are:\n",
      "heart: 5\n",
      "without: 4\n",
      "cause: 4\n",
      "alone: 3\n",
      "broken: 3\n",
      "[99, 68, 0.6868686868686869, 499]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 218 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 1108 characters in the data.\n",
      "The lexical diversity is 0.271 in the data.\n",
      "The 5 most common tokens are:\n",
      "world: 35\n",
      "womans: 33\n",
      "tell: 12\n",
      "truth: 12\n",
      "im: 10\n",
      "[218, 59, 0.2706422018348624, 1108]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 558 characters in the data.\n",
      "The lexical diversity is 0.618 in the data.\n",
      "The 5 most common tokens are:\n",
      "girl: 11\n",
      "working: 9\n",
      "shes: 6\n",
      "livin: 3\n",
      "mans: 3\n",
      "[110, 68, 0.6181818181818182, 558]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 138 tokens in the data.\n",
      "There are 79 unique tokens in the data.\n",
      "There are 605 characters in the data.\n",
      "The lexical diversity is 0.572 in the data.\n",
      "The 5 most common tokens are:\n",
      "kids: 13\n",
      "say: 5\n",
      "mother: 5\n",
      "ill: 4\n",
      "im: 4\n",
      "[138, 79, 0.572463768115942, 605]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 39 unique tokens in the data.\n",
      "There are 425 characters in the data.\n",
      "The lexical diversity is 0.448 in the data.\n",
      "The 5 most common tokens are:\n",
      "believe: 9\n",
      "dont: 8\n",
      "love: 7\n",
      "say: 4\n",
      "stay: 4\n",
      "[87, 39, 0.4482758620689655, 425]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 596 characters in the data.\n",
      "The lexical diversity is 0.448 in the data.\n",
      "The 5 most common tokens are:\n",
      "havent: 8\n",
      "seen: 8\n",
      "last: 8\n",
      "im: 7\n",
      "ive: 6\n",
      "[134, 60, 0.44776119402985076, 596]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 59 tokens in the data.\n",
      "There are 38 unique tokens in the data.\n",
      "There are 272 characters in the data.\n",
      "The lexical diversity is 0.644 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 9\n",
      "baby: 4\n",
      "well: 3\n",
      "love: 3\n",
      "youre: 2\n",
      "[59, 38, 0.6440677966101694, 272]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 96 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 479 characters in the data.\n",
      "The lexical diversity is 0.562 in the data.\n",
      "The 5 most common tokens are:\n",
      "young: 6\n",
      "pretty: 6\n",
      "say: 5\n",
      "make: 5\n",
      "youre: 5\n",
      "[96, 54, 0.5625, 479]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 445 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "The 5 most common tokens are:\n",
      "tomorrow: 10\n",
      "let: 8\n",
      "tonight: 3\n",
      "one: 3\n",
      "night: 3\n",
      "[87, 58, 0.6666666666666666, 445]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 74 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 332 characters in the data.\n",
      "The lexical diversity is 0.473 in the data.\n",
      "The 5 most common tokens are:\n",
      "every: 6\n",
      "ever: 6\n",
      "take: 5\n",
      "sometimes: 4\n",
      "ooh: 4\n",
      "[74, 35, 0.47297297297297297, 332]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 83 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 358 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "The 5 most common tokens are:\n",
      "made: 6\n",
      "happy: 6\n",
      "im: 6\n",
      "came: 6\n",
      "life: 5\n",
      "[83, 46, 0.5542168674698795, 358]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 132 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 569 characters in the data.\n",
      "The lexical diversity is 0.265 in the data.\n",
      "The 5 most common tokens are:\n",
      "hold: 25\n",
      "really: 17\n",
      "got: 17\n",
      "youve: 9\n",
      "want: 8\n",
      "[132, 35, 0.26515151515151514, 569]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 172 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 858 characters in the data.\n",
      "The lexical diversity is 0.302 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 29\n",
      "wouldnt: 27\n",
      "love: 23\n",
      "knocked: 5\n",
      "door: 5\n",
      "[172, 52, 0.3023255813953488, 858]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 205 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 887 characters in the data.\n",
      "The lexical diversity is 0.390 in the data.\n",
      "The 5 most common tokens are:\n",
      "got: 24\n",
      "work: 16\n",
      "88: 14\n",
      "days: 14\n",
      "ive: 11\n",
      "[205, 80, 0.3902439024390244, 887]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 66 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 305 characters in the data.\n",
      "The lexical diversity is 0.606 in the data.\n",
      "The 5 most common tokens are:\n",
      "really: 6\n",
      "thing: 5\n",
      "want: 4\n",
      "baby: 4\n",
      "aint: 3\n",
      "[66, 40, 0.6060606060606061, 305]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 119 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 578 characters in the data.\n",
      "The lexical diversity is 0.471 in the data.\n",
      "The 5 most common tokens are:\n",
      "pressure: 13\n",
      "tell: 10\n",
      "like: 9\n",
      "boy: 8\n",
      "anytime: 5\n",
      "[119, 56, 0.47058823529411764, 578]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 77 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 343 characters in the data.\n",
      "The lexical diversity is 0.442 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 19\n",
      "forgive: 13\n",
      "wont: 3\n",
      "give: 3\n",
      "chance: 3\n",
      "[77, 34, 0.44155844155844154, 343]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 174 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 713 characters in the data.\n",
      "The lexical diversity is 0.190 in the data.\n",
      "The 5 most common tokens are:\n",
      "party: 19\n",
      "go: 15\n",
      "beach: 14\n",
      "ok: 14\n",
      "lets: 10\n",
      "[174, 33, 0.1896551724137931, 713]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 129 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 639 characters in the data.\n",
      "The lexical diversity is 0.457 in the data.\n",
      "The 5 most common tokens are:\n",
      "music: 7\n",
      "anyway: 7\n",
      "yeah: 6\n",
      "im: 6\n",
      "right: 6\n",
      "[129, 59, 0.4573643410852713, 639]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 175 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 857 characters in the data.\n",
      "The lexical diversity is 0.474 in the data.\n",
      "The 5 most common tokens are:\n",
      "never: 29\n",
      "mine: 14\n",
      "theres: 5\n",
      "every: 5\n",
      "cause: 5\n",
      "[175, 83, 0.4742857142857143, 857]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 166 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 785 characters in the data.\n",
      "The lexical diversity is 0.307 in the data.\n",
      "The 5 most common tokens are:\n",
      "lines: 20\n",
      "reading: 19\n",
      "like: 15\n",
      "baby: 13\n",
      "im: 8\n",
      "[166, 51, 0.3072289156626506, 785]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 181 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 856 characters in the data.\n",
      "The lexical diversity is 0.420 in the data.\n",
      "The 5 most common tokens are:\n",
      "wont: 8\n",
      "dont: 7\n",
      "really: 7\n",
      "city: 6\n",
      "make: 6\n",
      "[181, 76, 0.4198895027624309, 856]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 10 tokens in the data.\n",
      "There are 10 unique tokens in the data.\n",
      "There are 67 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "The 5 most common tokens are:\n",
      "bionic: 1\n",
      "woman: 1\n",
      "good: 1\n",
      "evening: 1\n",
      "ladies: 1\n",
      "[10, 10, 1.0, 67]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 91 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 436 characters in the data.\n",
      "The lexical diversity is 0.582 in the data.\n",
      "The 5 most common tokens are:\n",
      "youre: 10\n",
      "blow: 7\n",
      "mind: 7\n",
      "baby: 4\n",
      "ill: 4\n",
      "[91, 53, 0.5824175824175825, 436]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 64 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 342 characters in the data.\n",
      "The lexical diversity is 0.703 in the data.\n",
      "The 5 most common tokens are:\n",
      "break: 3\n",
      "suckers: 3\n",
      "nobody: 2\n",
      "knows: 2\n",
      "whats: 2\n",
      "[64, 45, 0.703125, 342]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 277 tokens in the data.\n",
      "There are 132 unique tokens in the data.\n",
      "There are 1384 characters in the data.\n",
      "The lexical diversity is 0.477 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 13\n",
      "looking: 11\n",
      "moneyman: 11\n",
      "win: 10\n",
      "good: 8\n",
      "[277, 132, 0.47653429602888087, 1384]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 169 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 823 characters in the data.\n",
      "The lexical diversity is 0.373 in the data.\n",
      "The 5 most common tokens are:\n",
      "like: 12\n",
      "wasting: 12\n",
      "time: 12\n",
      "bum: 11\n",
      "new: 11\n",
      "[169, 63, 0.3727810650887574, 823]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 138 tokens in the data.\n",
      "There are 97 unique tokens in the data.\n",
      "There are 690 characters in the data.\n",
      "The lexical diversity is 0.703 in the data.\n",
      "The 5 most common tokens are:\n",
      "bumpy: 4\n",
      "ride: 4\n",
      "whos: 4\n",
      "hold: 4\n",
      "youve: 4\n",
      "[138, 97, 0.7028985507246377, 690]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 130 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 640 characters in the data.\n",
      "The lexical diversity is 0.362 in the data.\n",
      "The 5 most common tokens are:\n",
      "call: 7\n",
      "girlfriend: 7\n",
      "give: 6\n",
      "tell: 6\n",
      "time: 5\n",
      "[130, 47, 0.36153846153846153, 640]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 351 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 1542 characters in the data.\n",
      "The lexical diversity is 0.177 in the data.\n",
      "The 5 most common tokens are:\n",
      "deng: 32\n",
      "digi: 32\n",
      "bomb: 16\n",
      "di: 16\n",
      "gi: 16\n",
      "[351, 62, 0.17663817663817663, 1542]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 152 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 729 characters in the data.\n",
      "The lexical diversity is 0.553 in the data.\n",
      "The 5 most common tokens are:\n",
      "girl: 10\n",
      "crash: 7\n",
      "burn: 7\n",
      "dont: 6\n",
      "mind: 5\n",
      "[152, 84, 0.5526315789473685, 729]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 283 tokens in the data.\n",
      "There are 89 unique tokens in the data.\n",
      "There are 1638 characters in the data.\n",
      "The lexical diversity is 0.314 in the data.\n",
      "The 5 most common tokens are:\n",
      "criminal: 17\n",
      "intent: 17\n",
      "somebody: 16\n",
      "alert: 16\n",
      "authorities: 16\n",
      "[283, 89, 0.31448763250883394, 1638]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 158 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 735 characters in the data.\n",
      "The lexical diversity is 0.468 in the data.\n",
      "The 5 most common tokens are:\n",
      "get: 11\n",
      "cry: 7\n",
      "older: 7\n",
      "never: 7\n",
      "told: 7\n",
      "[158, 74, 0.46835443037974683, 735]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 170 tokens in the data.\n",
      "There are 162 unique tokens in the data.\n",
      "There are 1042 characters in the data.\n",
      "The lexical diversity is 0.953 in the data.\n",
      "The 5 most common tokens are:\n",
      "konichiwa: 2\n",
      "records: 2\n",
      "get: 2\n",
      "listen: 2\n",
      "turn: 2\n",
      "[170, 162, 0.9529411764705882, 1042]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 187 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 879 characters in the data.\n",
      "The lexical diversity is 0.332 in the data.\n",
      "The 5 most common tokens are:\n",
      "wow: 16\n",
      "like: 12\n",
      "queen: 9\n",
      "dancehall: 8\n",
      "thing: 8\n",
      "[187, 62, 0.3315508021390374, 879]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 187 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 879 characters in the data.\n",
      "The lexical diversity is 0.332 in the data.\n",
      "The 5 most common tokens are:\n",
      "wow: 16\n",
      "like: 12\n",
      "queen: 9\n",
      "dancehall: 8\n",
      "thing: 8\n",
      "[187, 62, 0.3315508021390374, 879]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 603 characters in the data.\n",
      "The lexical diversity is 0.416 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 19\n",
      "oh: 11\n",
      "dancing: 10\n",
      "keep: 9\n",
      "youre: 5\n",
      "[137, 57, 0.41605839416058393, 603]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 614 characters in the data.\n",
      "The lexical diversity is 0.423 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 19\n",
      "dancing: 10\n",
      "keep: 9\n",
      "ohh: 7\n",
      "youre: 5\n",
      "[137, 58, 0.4233576642335766, 614]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 81 tokens in the data.\n",
      "There are 29 unique tokens in the data.\n",
      "There are 375 characters in the data.\n",
      "The lexical diversity is 0.358 in the data.\n",
      "The 5 most common tokens are:\n",
      "lets: 9\n",
      "dont: 6\n",
      "know: 5\n",
      "wait: 4\n",
      "hurts: 4\n",
      "[81, 29, 0.35802469135802467, 375]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 177 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 1078 characters in the data.\n",
      "The lexical diversity is 0.226 in the data.\n",
      "The 5 most common tokens are:\n",
      "killing: 68\n",
      "drinking: 16\n",
      "dont: 10\n",
      "fucking: 10\n",
      "tell: 10\n",
      "[177, 40, 0.22598870056497175, 1078]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 177 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 1078 characters in the data.\n",
      "The lexical diversity is 0.226 in the data.\n",
      "The 5 most common tokens are:\n",
      "killing: 68\n",
      "drinking: 16\n",
      "dont: 10\n",
      "fucking: 10\n",
      "tell: 10\n",
      "[177, 40, 0.22598870056497175, 1078]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 151 tokens in the data.\n",
      "There are 87 unique tokens in the data.\n",
      "There are 731 characters in the data.\n",
      "The lexical diversity is 0.576 in the data.\n",
      "The 5 most common tokens are:\n",
      "come: 10\n",
      "stop: 9\n",
      "music: 8\n",
      "baby: 8\n",
      "dont: 6\n",
      "[151, 87, 0.5761589403973509, 731]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 67 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 297 characters in the data.\n",
      "The lexical diversity is 0.522 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 7\n",
      "wanna: 7\n",
      "back: 5\n",
      "want: 3\n",
      "even: 3\n",
      "[67, 35, 0.5223880597014925, 297]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 95 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 447 characters in the data.\n",
      "The lexical diversity is 0.600 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 9\n",
      "takes: 6\n",
      "around: 4\n",
      "got: 4\n",
      "love: 4\n",
      "[95, 57, 0.6, 447]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 111 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 520 characters in the data.\n",
      "The lexical diversity is 0.631 in the data.\n",
      "The 5 most common tokens are:\n",
      "really: 4\n",
      "want: 4\n",
      "right: 4\n",
      "show: 3\n",
      "respect: 3\n",
      "[111, 70, 0.6306306306306306, 520]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 103 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 550 characters in the data.\n",
      "The lexical diversity is 0.621 in the data.\n",
      "The 5 most common tokens are:\n",
      "right: 9\n",
      "youre: 4\n",
      "words: 4\n",
      "unspoken: 4\n",
      "falls: 4\n",
      "[103, 64, 0.6213592233009708, 550]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 153 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 818 characters in the data.\n",
      "The lexical diversity is 0.412 in the data.\n",
      "The 5 most common tokens are:\n",
      "electric: 28\n",
      "cant: 6\n",
      "deny: 6\n",
      "natural: 5\n",
      "high: 5\n",
      "[153, 63, 0.4117647058823529, 818]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 199 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 993 characters in the data.\n",
      "The lexical diversity is 0.302 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 23\n",
      "never: 21\n",
      "ever: 18\n",
      "brokenhearted: 11\n",
      "come: 8\n",
      "[199, 60, 0.3015075376884422, 993]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 96 tokens in the data.\n",
      "There are 29 unique tokens in the data.\n",
      "There are 459 characters in the data.\n",
      "The lexical diversity is 0.302 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 12\n",
      "waiting: 10\n",
      "every: 9\n",
      "little: 9\n",
      "thing: 9\n",
      "[96, 29, 0.3020833333333333, 459]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 246 tokens in the data.\n",
      "There are 113 unique tokens in the data.\n",
      "There are 1352 characters in the data.\n",
      "The lexical diversity is 0.459 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 8\n",
      "got: 7\n",
      "gone: 7\n",
      "tech: 7\n",
      "never: 7\n",
      "[246, 113, 0.45934959349593496, 1352]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 246 tokens in the data.\n",
      "There are 113 unique tokens in the data.\n",
      "There are 1352 characters in the data.\n",
      "The lexical diversity is 0.459 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 8\n",
      "got: 7\n",
      "gone: 7\n",
      "tech: 7\n",
      "never: 7\n",
      "[246, 113, 0.45934959349593496, 1352]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 224 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 999 characters in the data.\n",
      "The lexical diversity is 0.357 in the data.\n",
      "The 5 most common tokens are:\n",
      "got: 35\n",
      "get: 21\n",
      "together: 11\n",
      "gone: 10\n",
      "cant: 8\n",
      "[224, 80, 0.35714285714285715, 999]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 112 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 530 characters in the data.\n",
      "The lexical diversity is 0.616 in the data.\n",
      "The 5 most common tokens are:\n",
      "right: 7\n",
      "back: 6\n",
      "im: 6\n",
      "giving: 4\n",
      "nothing: 4\n",
      "[112, 69, 0.6160714285714286, 530]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 216 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 961 characters in the data.\n",
      "The lexical diversity is 0.236 in the data.\n",
      "The 5 most common tokens are:\n",
      "work: 43\n",
      "got: 21\n",
      "shake: 16\n",
      "make: 12\n",
      "fit: 12\n",
      "[216, 51, 0.2361111111111111, 961]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 254 tokens in the data.\n",
      "There are 96 unique tokens in the data.\n",
      "There are 1240 characters in the data.\n",
      "The lexical diversity is 0.378 in the data.\n",
      "The 5 most common tokens are:\n",
      "handle: 18\n",
      "cant: 17\n",
      "youre: 11\n",
      "sure: 10\n",
      "yeah: 8\n",
      "[254, 96, 0.3779527559055118, 1240]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 713 characters in the data.\n",
      "The lexical diversity is 0.313 in the data.\n",
      "The 5 most common tokens are:\n",
      "hang: 12\n",
      "gonna: 12\n",
      "im: 7\n",
      "right: 6\n",
      "guess: 4\n",
      "[134, 42, 0.31343283582089554, 713]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 713 characters in the data.\n",
      "The lexical diversity is 0.313 in the data.\n",
      "The 5 most common tokens are:\n",
      "hang: 12\n",
      "gonna: 12\n",
      "im: 7\n",
      "right: 6\n",
      "guess: 4\n",
      "[134, 42, 0.31343283582089554, 713]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 547 characters in the data.\n",
      "The lexical diversity is 0.431 in the data.\n",
      "The 5 most common tokens are:\n",
      "hang: 11\n",
      "gonna: 8\n",
      "im: 5\n",
      "right: 4\n",
      "guess: 3\n",
      "[102, 44, 0.43137254901960786, 547]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 150 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 748 characters in the data.\n",
      "The lexical diversity is 0.493 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 12\n",
      "healthy: 11\n",
      "ever: 9\n",
      "strange: 7\n",
      "feeling: 7\n",
      "[150, 74, 0.49333333333333335, 748]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 48 tokens in the data.\n",
      "There are 32 unique tokens in the data.\n",
      "There are 246 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "The 5 most common tokens are:\n",
      "go: 5\n",
      "thought: 3\n",
      "makin: 3\n",
      "another: 2\n",
      "baby: 2\n",
      "[48, 32, 0.6666666666666666, 246]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 221 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 1028 characters in the data.\n",
      "The lexical diversity is 0.271 in the data.\n",
      "The 5 most common tokens are:\n",
      "get: 19\n",
      "baby: 18\n",
      "honey: 14\n",
      "want: 13\n",
      "need: 10\n",
      "[221, 60, 0.27149321266968324, 1028]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 92 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 455 characters in the data.\n",
      "The lexical diversity is 0.696 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 5\n",
      "time: 5\n",
      "right: 4\n",
      "cause: 3\n",
      "long: 3\n",
      "[92, 64, 0.6956521739130435, 455]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 479 characters in the data.\n",
      "The lexical diversity is 0.389 in the data.\n",
      "The 5 most common tokens are:\n",
      "move: 15\n",
      "human: 13\n",
      "im: 12\n",
      "dont: 8\n",
      "body: 8\n",
      "[113, 44, 0.3893805309734513, 479]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 234 tokens in the data.\n",
      "There are 89 unique tokens in the data.\n",
      "There are 1186 characters in the data.\n",
      "The lexical diversity is 0.380 in the data.\n",
      "The 5 most common tokens are:\n",
      "include: 19\n",
      "dont: 16\n",
      "world: 8\n",
      "fall: 8\n",
      "apart: 8\n",
      "[234, 89, 0.3803418803418803, 1186]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 182 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 894 characters in the data.\n",
      "The lexical diversity is 0.313 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 22\n",
      "love: 20\n",
      "like: 13\n",
      "gonna: 12\n",
      "indestructible: 9\n",
      "[182, 57, 0.3131868131868132, 894]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 182 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 887 characters in the data.\n",
      "The lexical diversity is 0.330 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 20\n",
      "love: 18\n",
      "like: 13\n",
      "gonna: 10\n",
      "indestructible: 9\n",
      "[182, 60, 0.32967032967032966, 887]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 670 characters in the data.\n",
      "The lexical diversity is 0.452 in the data.\n",
      "The 5 most common tokens are:\n",
      "eyes: 9\n",
      "look: 8\n",
      "ok: 7\n",
      "like: 6\n",
      "think: 6\n",
      "[146, 66, 0.4520547945205479, 670]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 670 characters in the data.\n",
      "The lexical diversity is 0.452 in the data.\n",
      "The 5 most common tokens are:\n",
      "eyes: 9\n",
      "look: 8\n",
      "ok: 7\n",
      "like: 6\n",
      "think: 6\n",
      "[146, 66, 0.4520547945205479, 670]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 59 tokens in the data.\n",
      "There are 32 unique tokens in the data.\n",
      "There are 279 characters in the data.\n",
      "The lexical diversity is 0.542 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 7\n",
      "heart: 6\n",
      "im: 4\n",
      "never: 4\n",
      "think: 3\n",
      "[59, 32, 0.5423728813559322, 279]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 109 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 478 characters in the data.\n",
      "The lexical diversity is 0.495 in the data.\n",
      "The 5 most common tokens are:\n",
      "wish: 11\n",
      "baby: 6\n",
      "know: 4\n",
      "could: 4\n",
      "day: 4\n",
      "[109, 54, 0.4954128440366973, 478]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 554 characters in the data.\n",
      "The lexical diversity is 0.418 in the data.\n",
      "The 5 most common tokens are:\n",
      "u: 31\n",
      "jack: 25\n",
      "ill: 16\n",
      "youre: 5\n",
      "go: 3\n",
      "[146, 61, 0.4178082191780822, 554]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 467 characters in the data.\n",
      "The lexical diversity is 0.752 in the data.\n",
      "The 5 most common tokens are:\n",
      "jag: 4\n",
      "och: 4\n",
      "som: 4\n",
      "en: 3\n",
      "nr: 3\n",
      "[101, 76, 0.7524752475247525, 467]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 83 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 400 characters in the data.\n",
      "The lexical diversity is 0.687 in the data.\n",
      "The 5 most common tokens are:\n",
      "another: 5\n",
      "baby: 5\n",
      "girlfriend: 4\n",
      "say: 4\n",
      "stay: 4\n",
      "[83, 57, 0.6867469879518072, 400]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 180 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 812 characters in the data.\n",
      "The lexical diversity is 0.317 in the data.\n",
      "The 5 most common tokens are:\n",
      "ill: 17\n",
      "keep: 16\n",
      "fire: 8\n",
      "burning: 8\n",
      "even: 8\n",
      "[180, 57, 0.31666666666666665, 812]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 195 tokens in the data.\n",
      "There are 151 unique tokens in the data.\n",
      "There are 994 characters in the data.\n",
      "The lexical diversity is 0.774 in the data.\n",
      "The 5 most common tokens are:\n",
      "like: 10\n",
      "im: 7\n",
      "konichiwa: 4\n",
      "bitches: 4\n",
      "wanna: 4\n",
      "[195, 151, 0.7743589743589744, 994]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 164 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 731 characters in the data.\n",
      "The lexical diversity is 0.488 in the data.\n",
      "The 5 most common tokens are:\n",
      "gone: 26\n",
      "long: 23\n",
      "im: 18\n",
      "today: 5\n",
      "coming: 4\n",
      "[164, 80, 0.4878048780487805, 731]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 530 characters in the data.\n",
      "The lexical diversity is 0.289 in the data.\n",
      "The 5 most common tokens are:\n",
      "cant: 23\n",
      "control: 16\n",
      "dont: 16\n",
      "like: 15\n",
      "hey: 4\n",
      "[121, 35, 0.2892561983471074, 530]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 315 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 1440 characters in the data.\n",
      "The lexical diversity is 0.152 in the data.\n",
      "The 5 most common tokens are:\n",
      "boom: 46\n",
      "free: 32\n",
      "baby: 24\n",
      "love: 19\n",
      "give: 18\n",
      "[315, 48, 0.1523809523809524, 1440]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 246 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 1162 characters in the data.\n",
      "The lexical diversity is 0.171 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 25\n",
      "know: 16\n",
      "kills: 15\n",
      "cus: 14\n",
      "dont: 11\n",
      "[246, 42, 0.17073170731707318, 1162]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 247 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 1167 characters in the data.\n",
      "The lexical diversity is 0.170 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 25\n",
      "know: 16\n",
      "kills: 15\n",
      "cus: 14\n",
      "dont: 11\n",
      "[247, 42, 0.1700404858299595, 1167]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 147 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 659 characters in the data.\n",
      "The lexical diversity is 0.463 in the data.\n",
      "The 5 most common tokens are:\n",
      "work: 13\n",
      "lets: 12\n",
      "thing: 8\n",
      "weve: 6\n",
      "got: 6\n",
      "[147, 68, 0.46258503401360546, 659]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 188 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 1003 characters in the data.\n",
      "The lexical diversity is 0.404 in the data.\n",
      "The 5 most common tokens are:\n",
      "space: 10\n",
      "left: 10\n",
      "theres: 10\n",
      "empty: 9\n",
      "behind: 9\n",
      "[188, 76, 0.40425531914893614, 1003]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 98 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 531 characters in the data.\n",
      "The lexical diversity is 0.643 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 7\n",
      "morning: 4\n",
      "friday: 4\n",
      "saturday: 4\n",
      "sunday: 4\n",
      "[98, 63, 0.6428571428571429, 531]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 82 tokens in the data.\n",
      "There are 30 unique tokens in the data.\n",
      "There are 350 characters in the data.\n",
      "The lexical diversity is 0.366 in the data.\n",
      "The 5 most common tokens are:\n",
      "life: 14\n",
      "gone: 7\n",
      "love: 7\n",
      "let: 6\n",
      "monument: 4\n",
      "[82, 30, 0.36585365853658536, 350]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 74 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 319 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 8\n",
      "dont: 8\n",
      "go: 5\n",
      "moonlight: 3\n",
      "oh: 3\n",
      "[74, 41, 0.5540540540540541, 319]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 100 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 510 characters in the data.\n",
      "The lexical diversity is 0.680 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 5\n",
      "chorus: 4\n",
      "thats: 4\n",
      "im: 4\n",
      "dont: 4\n",
      "[100, 68, 0.68, 510]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 524 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "The 5 most common tokens are:\n",
      "truth: 12\n",
      "dont: 6\n",
      "cause: 4\n",
      "chorus: 4\n",
      "cant: 3\n",
      "[102, 68, 0.6666666666666666, 524]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 126 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 555 characters in the data.\n",
      "The lexical diversity is 0.468 in the data.\n",
      "The 5 most common tokens are:\n",
      "none: 14\n",
      "take: 6\n",
      "away: 6\n",
      "ive: 4\n",
      "im: 4\n",
      "[126, 59, 0.46825396825396826, 555]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 126 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 555 characters in the data.\n",
      "The lexical diversity is 0.468 in the data.\n",
      "The 5 most common tokens are:\n",
      "none: 14\n",
      "take: 6\n",
      "away: 6\n",
      "ive: 4\n",
      "im: 4\n",
      "[126, 59, 0.46825396825396826, 555]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 94 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 486 characters in the data.\n",
      "The lexical diversity is 0.745 in the data.\n",
      "The 5 most common tokens are:\n",
      "never: 4\n",
      "hes: 4\n",
      "isnt: 3\n",
      "chorus: 3\n",
      "loveless: 3\n",
      "[94, 70, 0.7446808510638298, 486]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 90 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 417 characters in the data.\n",
      "The lexical diversity is 0.689 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 6\n",
      "dont: 6\n",
      "chorus: 4\n",
      "youre: 4\n",
      "say: 4\n",
      "[90, 62, 0.6888888888888889, 417]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 96 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 448 characters in the data.\n",
      "The lexical diversity is 0.573 in the data.\n",
      "The 5 most common tokens are:\n",
      "yeah: 14\n",
      "say: 7\n",
      "people: 6\n",
      "never: 5\n",
      "play: 3\n",
      "[96, 55, 0.5729166666666666, 448]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 194 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 954 characters in the data.\n",
      "The lexical diversity is 0.376 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 20\n",
      "psycho: 19\n",
      "youre: 15\n",
      "know: 11\n",
      "dont: 9\n",
      "[194, 73, 0.37628865979381443, 954]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 52 tokens in the data.\n",
      "There are 39 unique tokens in the data.\n",
      "There are 257 characters in the data.\n",
      "The lexical diversity is 0.750 in the data.\n",
      "The 5 most common tokens are:\n",
      "boy: 5\n",
      "hey: 4\n",
      "little: 3\n",
      "lost: 2\n",
      "robot: 2\n",
      "[52, 39, 0.75, 257]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 94 unique tokens in the data.\n",
      "There are 701 characters in the data.\n",
      "The lexical diversity is 0.686 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 8\n",
      "robyn: 7\n",
      "make: 4\n",
      "let: 3\n",
      "know: 3\n",
      "[137, 94, 0.6861313868613139, 701]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 52 tokens in the data.\n",
      "There are 14 unique tokens in the data.\n",
      "There are 222 characters in the data.\n",
      "The lexical diversity is 0.269 in the data.\n",
      "The 5 most common tokens are:\n",
      "want: 28\n",
      "say: 9\n",
      "woman: 3\n",
      "ready: 2\n",
      "sayit: 1\n",
      "[52, 14, 0.2692307692307692, 222]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 104 tokens in the data.\n",
      "There are 38 unique tokens in the data.\n",
      "There are 483 characters in the data.\n",
      "The lexical diversity is 0.365 in the data.\n",
      "The 5 most common tokens are:\n",
      "got: 11\n",
      "say: 11\n",
      "baby: 9\n",
      "something: 6\n",
      "tonight: 5\n",
      "[104, 38, 0.36538461538461536, 483]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 138 tokens in the data.\n",
      "There are 25 unique tokens in the data.\n",
      "There are 510 characters in the data.\n",
      "The lexical diversity is 0.181 in the data.\n",
      "The 5 most common tokens are:\n",
      "set: 44\n",
      "got: 34\n",
      "free: 18\n",
      "know: 15\n",
      "body: 4\n",
      "[138, 25, 0.18115942028985507, 510]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 97 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 480 characters in the data.\n",
      "The lexical diversity is 0.680 in the data.\n",
      "The 5 most common tokens are:\n",
      "known: 9\n",
      "let: 3\n",
      "even: 3\n",
      "know: 3\n",
      "believe: 3\n",
      "[97, 66, 0.6804123711340206, 480]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 97 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 480 characters in the data.\n",
      "The lexical diversity is 0.680 in the data.\n",
      "The 5 most common tokens are:\n",
      "known: 9\n",
      "let: 3\n",
      "even: 3\n",
      "know: 3\n",
      "believe: 3\n",
      "[97, 66, 0.6804123711340206, 480]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 181 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 815 characters in the data.\n",
      "The lexical diversity is 0.315 in the data.\n",
      "The 5 most common tokens are:\n",
      "show: 34\n",
      "love: 24\n",
      "alright: 10\n",
      "baby: 8\n",
      "one: 7\n",
      "[181, 57, 0.3149171270718232, 815]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 85 tokens in the data.\n",
      "There are 32 unique tokens in the data.\n",
      "There are 450 characters in the data.\n",
      "The lexical diversity is 0.376 in the data.\n",
      "The 5 most common tokens are:\n",
      "stars: 12\n",
      "forever: 10\n",
      "together: 6\n",
      "4x: 6\n",
      "right: 6\n",
      "[85, 32, 0.3764705882352941, 450]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 180 tokens in the data.\n",
      "There are 89 unique tokens in the data.\n",
      "There are 829 characters in the data.\n",
      "The lexical diversity is 0.494 in the data.\n",
      "The 5 most common tokens are:\n",
      "still: 12\n",
      "im: 9\n",
      "know: 7\n",
      "let: 6\n",
      "girl: 5\n",
      "[180, 89, 0.49444444444444446, 829]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 74 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 338 characters in the data.\n",
      "The lexical diversity is 0.378 in the data.\n",
      "The 5 most common tokens are:\n",
      "tell: 21\n",
      "today: 11\n",
      "want: 8\n",
      "chance: 2\n",
      "dance: 2\n",
      "[74, 28, 0.3783783783783784, 338]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 171 tokens in the data.\n",
      "There are 96 unique tokens in the data.\n",
      "There are 779 characters in the data.\n",
      "The lexical diversity is 0.561 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 8\n",
      "always: 7\n",
      "time: 6\n",
      "love: 6\n",
      "cause: 6\n",
      "[171, 96, 0.5614035087719298, 779]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 129 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 624 characters in the data.\n",
      "The lexical diversity is 0.411 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 14\n",
      "taking: 12\n",
      "time: 6\n",
      "could: 5\n",
      "one: 5\n",
      "[129, 53, 0.4108527131782946, 624]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 29 tokens in the data.\n",
      "There are 16 unique tokens in the data.\n",
      "There are 127 characters in the data.\n",
      "The lexical diversity is 0.552 in the data.\n",
      "The 5 most common tokens are:\n",
      "uh: 6\n",
      "like: 4\n",
      "dont: 2\n",
      "gimme: 2\n",
      "somethin: 2\n",
      "[29, 16, 0.5517241379310345, 127]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 108 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 521 characters in the data.\n",
      "The lexical diversity is 0.769 in the data.\n",
      "The 5 most common tokens are:\n",
      "see: 4\n",
      "love: 4\n",
      "underneath: 3\n",
      "heart: 3\n",
      "chorus: 3\n",
      "[108, 83, 0.7685185185185185, 521]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 83 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 435 characters in the data.\n",
      "The lexical diversity is 0.711 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 6\n",
      "shes: 5\n",
      "universal: 3\n",
      "woman: 3\n",
      "chorus: 3\n",
      "[83, 59, 0.7108433734939759, 435]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 323 tokens in the data.\n",
      "There are 183 unique tokens in the data.\n",
      "There are 1600 characters in the data.\n",
      "The lexical diversity is 0.567 in the data.\n",
      "The 5 most common tokens are:\n",
      "better: 42\n",
      "know: 33\n",
      "fuck: 15\n",
      "im: 8\n",
      "yyou: 7\n",
      "[323, 183, 0.56656346749226, 1600]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 323 tokens in the data.\n",
      "There are 183 unique tokens in the data.\n",
      "There are 1600 characters in the data.\n",
      "The lexical diversity is 0.567 in the data.\n",
      "The 5 most common tokens are:\n",
      "better: 42\n",
      "know: 33\n",
      "fuck: 15\n",
      "im: 8\n",
      "yyou: 7\n",
      "[323, 183, 0.56656346749226, 1600]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 222 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 1129 characters in the data.\n",
      "The lexical diversity is 0.324 in the data.\n",
      "The 5 most common tokens are:\n",
      "dance: 68\n",
      "beat: 67\n",
      "dont: 7\n",
      "stop: 7\n",
      "loud: 3\n",
      "[222, 72, 0.32432432432432434, 1129]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 222 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 1129 characters in the data.\n",
      "The lexical diversity is 0.324 in the data.\n",
      "The 5 most common tokens are:\n",
      "dance: 68\n",
      "beat: 67\n",
      "dont: 7\n",
      "stop: 7\n",
      "loud: 3\n",
      "[222, 72, 0.32432432432432434, 1129]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 55 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 266 characters in the data.\n",
      "The lexical diversity is 0.764 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 5\n",
      "thinkin: 3\n",
      "go: 2\n",
      "thoughts: 2\n",
      "used: 2\n",
      "[55, 42, 0.7636363636363637, 266]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 170 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 762 characters in the data.\n",
      "The lexical diversity is 0.318 in the data.\n",
      "The 5 most common tokens are:\n",
      "girl: 24\n",
      "whos: 19\n",
      "cant: 10\n",
      "take: 7\n",
      "pressure: 7\n",
      "[170, 54, 0.3176470588235294, 762]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 106 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 537 characters in the data.\n",
      "The lexical diversity is 0.311 in the data.\n",
      "The 5 most common tokens are:\n",
      "every: 12\n",
      "heartbeat: 9\n",
      "hurts: 8\n",
      "could: 6\n",
      "dont: 6\n",
      "[106, 33, 0.3113207547169811, 537]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 81 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 366 characters in the data.\n",
      "The lexical diversity is 0.691 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 5\n",
      "youve: 4\n",
      "got: 4\n",
      "ive: 3\n",
      "something: 2\n",
      "[81, 56, 0.691358024691358, 366]\n"
     ]
    }
   ],
   "source": [
    "# Descriptive_stats for lyrics\n",
    "\n",
    "def descriptive_stats(tokens, num_tokens=5, verbose=True):\n",
    "    # Calculate the number of tokens\n",
    "    total_tokens = len(tokens)\n",
    "    \n",
    "    # Calculate the number of unique tokens\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    \n",
    "    # Calculate the number of characters\n",
    "    num_characters = sum(len(token) for token in tokens)\n",
    "    \n",
    "    # Calculate the lexical diversity\n",
    "    lexical_diversity = num_unique_tokens / total_tokens if total_tokens > 0 else 0.0\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"There are {total_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # Print the num_tokens most common tokens\n",
    "        most_common_tokens = Counter(tokens).most_common(num_tokens)\n",
    "        print(f\"The {num_tokens} most common tokens are:\")\n",
    "        for token, frequency in most_common_tokens:\n",
    "            print(f\"{token}: {frequency}\")\n",
    "    \n",
    "    return [total_tokens, num_unique_tokens, lexical_diversity, num_characters]\n",
    "\n",
    "# List directories in the lyrics folder\n",
    "lyrics_path = os.path.join(data_location, lyrics_folder)\n",
    "if os.path.exists(lyrics_path):\n",
    "    lyrics_dirs = os.listdir(lyrics_path)\n",
    "\n",
    "    # Read and clean lyrics data\n",
    "    all_lyrics = []\n",
    "    for lyrics_dir in lyrics_dirs:\n",
    "        dir_path = os.path.join(lyrics_path, lyrics_dir)\n",
    "        if os.path.isdir(dir_path):\n",
    "            files = os.listdir(dir_path)\n",
    "            for file in files:\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        lyrics_data = f.read()\n",
    "                        cleaned_data = clean_and_tokenize(lyrics_data)\n",
    "                        all_lyrics.append({\n",
    "                            'artist': lyrics_dir,\n",
    "                            'lyrics': lyrics_data,\n",
    "                            'cleaned_lyrics': cleaned_data\n",
    "                        })\n",
    "                except FileNotFoundError as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                except PermissionError as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "    # Create a DataFrame for the lyrics data\n",
    "    lyrics_df = pd.DataFrame(all_lyrics)\n",
    "    print(\"Lyrics DataFrame:\")\n",
    "    print(lyrics_df.head())\n",
    "\n",
    "    # Perform descriptive statistics on cleaned lyrics data\n",
    "    for index, row in lyrics_df.iterrows():\n",
    "        print(f\"\\nDescriptive statistics for {row['artist']} lyrics:\")\n",
    "        stats = descriptive_stats(row['cleaned_lyrics'], verbose=True)\n",
    "        print(stats)\n",
    "else:\n",
    "    print(f\"Lyrics directory does not exist: {lyrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f07fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics DataFrame:\n",
      "  artist                                             lyrics  \\\n",
      "0   cher  \"88 Degrees\"\\n\\n\\n\\nStuck in L.A., ain't got n...   \n",
      "1   cher  \"A Different Kind Of Love Song\"\\n\\n\\n\\nWhat if...   \n",
      "2   cher  \"After All\"\\n\\n\\n\\nWell, here we are again\\nI ...   \n",
      "3   cher  \"Again\"\\n\\n\\n\\nAgain evening finds me at your ...   \n",
      "4   cher  \"Alfie\"\\n\\n\\n\\nWhat's it all about, Alfie?\\nIs...   \n",
      "\n",
      "                                      cleaned_lyrics  \n",
      "0  [88, degrees, stuck, la, aint, got, friends, h...  \n",
      "1  [different, kind, love, song, world, crazy, sa...  \n",
      "2  [well, guess, must, fate, weve, tried, deep, i...  \n",
      "3  [evening, finds, door, ask, could, try, dont, ...  \n",
      "4  [alfie, whats, alfie, moment, live, whats, sor...  \n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 182 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 831 characters in the data.\n",
      "The lexical diversity is 0.451 in the data.\n",
      "The 5 most common tokens are:\n",
      "cause: 9\n",
      "hot: 8\n",
      "im: 8\n",
      "yeah: 8\n",
      "88: 6\n",
      "[182, 82, 0.45054945054945056, 831]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 691 characters in the data.\n",
      "The lexical diversity is 0.299 in the data.\n",
      "The 5 most common tokens are:\n",
      "kind: 17\n",
      "different: 16\n",
      "love: 16\n",
      "song: 16\n",
      "ooh: 14\n",
      "[137, 41, 0.29927007299270075, 691]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 120 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 603 characters in the data.\n",
      "The lexical diversity is 0.492 in the data.\n",
      "The 5 most common tokens are:\n",
      "two: 8\n",
      "weve: 6\n",
      "back: 6\n",
      "guess: 5\n",
      "stops: 4\n",
      "[120, 59, 0.49166666666666664, 603]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 34 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 143 characters in the data.\n",
      "The lexical diversity is 0.824 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 3\n",
      "door: 2\n",
      "know: 2\n",
      "never: 2\n",
      "see: 2\n",
      "[34, 28, 0.8235294117647058, 143]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 67 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 339 characters in the data.\n",
      "The lexical diversity is 0.687 in the data.\n",
      "The 5 most common tokens are:\n",
      "alfie: 11\n",
      "love: 4\n",
      "believe: 3\n",
      "whats: 2\n",
      "meant: 2\n",
      "[67, 46, 0.6865671641791045, 339]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 104 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 491 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "The 5 most common tokens are:\n",
      "need: 7\n",
      "wanna: 6\n",
      "like: 5\n",
      "alive: 3\n",
      "rain: 3\n",
      "[104, 72, 0.6923076923076923, 491]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 94 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 461 characters in the data.\n",
      "The lexical diversity is 0.574 in the data.\n",
      "The 5 most common tokens are:\n",
      "heart: 6\n",
      "feel: 6\n",
      "cant: 5\n",
      "way: 5\n",
      "wants: 5\n",
      "[94, 54, 0.574468085106383, 461]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 83 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 462 characters in the data.\n",
      "The lexical diversity is 0.578 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 10\n",
      "friends: 10\n",
      "want: 8\n",
      "really: 6\n",
      "aint: 3\n",
      "[83, 48, 0.5783132530120482, 462]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 663 characters in the data.\n",
      "The lexical diversity is 0.321 in the data.\n",
      "The 5 most common tokens are:\n",
      "nothing: 11\n",
      "youre: 11\n",
      "baby: 10\n",
      "dont: 8\n",
      "wanna: 8\n",
      "[134, 43, 0.3208955223880597, 663]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 68 tokens in the data.\n",
      "There are 29 unique tokens in the data.\n",
      "There are 241 characters in the data.\n",
      "The lexical diversity is 0.426 in the data.\n",
      "The 5 most common tokens are:\n",
      "blue: 9\n",
      "im: 8\n",
      "one: 6\n",
      "hes: 5\n",
      "time: 4\n",
      "[68, 29, 0.4264705882352941, 241]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 490 characters in the data.\n",
      "The lexical diversity is 0.564 in the data.\n",
      "The 5 most common tokens are:\n",
      "thing: 8\n",
      "know: 5\n",
      "bad: 5\n",
      "let: 4\n",
      "go: 4\n",
      "[101, 57, 0.5643564356435643, 490]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 642 characters in the data.\n",
      "The lexical diversity is 0.540 in the data.\n",
      "The 5 most common tokens are:\n",
      "apples: 7\n",
      "dont: 7\n",
      "fall: 7\n",
      "far: 7\n",
      "tree: 7\n",
      "[137, 74, 0.5401459854014599, 642]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 490 characters in the data.\n",
      "The lexical diversity is 0.509 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 12\n",
      "cant: 7\n",
      "one: 5\n",
      "way: 4\n",
      "spend: 4\n",
      "[110, 56, 0.509090909090909, 490]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 390 characters in the data.\n",
      "The lexical diversity is 0.452 in the data.\n",
      "The 5 most common tokens are:\n",
      "without: 11\n",
      "world: 8\n",
      "heroes: 7\n",
      "dont: 6\n",
      "know: 6\n",
      "[73, 33, 0.4520547945205479, 390]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 123 tokens in the data.\n",
      "There are 93 unique tokens in the data.\n",
      "There are 667 characters in the data.\n",
      "The lexical diversity is 0.756 in the data.\n",
      "The 5 most common tokens are:\n",
      "young: 7\n",
      "girl: 6\n",
      "left: 4\n",
      "love: 4\n",
      "made: 2\n",
      "[123, 93, 0.7560975609756098, 667]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 498 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 13\n",
      "im: 12\n",
      "street: 7\n",
      "feet: 6\n",
      "get: 3\n",
      "[110, 55, 0.5, 498]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 174 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 752 characters in the data.\n",
      "The lexical diversity is 0.408 in the data.\n",
      "The 5 most common tokens are:\n",
      "bang: 62\n",
      "shot: 10\n",
      "baby: 9\n",
      "ground: 6\n",
      "hit: 4\n",
      "[174, 71, 0.40804597701149425, 752]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 100 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 445 characters in the data.\n",
      "The lexical diversity is 0.530 in the data.\n",
      "The 5 most common tokens are:\n",
      "bang: 26\n",
      "shot: 6\n",
      "baby: 3\n",
      "hit: 3\n",
      "ground: 3\n",
      "[100, 53, 0.53, 445]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 488 characters in the data.\n",
      "The lexical diversity is 0.581 in the data.\n",
      "The 5 most common tokens are:\n",
      "every: 9\n",
      "behind: 4\n",
      "door: 4\n",
      "asking: 4\n",
      "house: 3\n",
      "[93, 54, 0.5806451612903226, 488]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 177 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 885 characters in the data.\n",
      "The lexical diversity is 0.294 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 12\n",
      "love: 11\n",
      "believe: 10\n",
      "youre: 10\n",
      "strong: 10\n",
      "[177, 52, 0.2937853107344633, 885]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 156 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 665 characters in the data.\n",
      "The lexical diversity is 0.359 in the data.\n",
      "The 5 most common tokens are:\n",
      "want: 16\n",
      "dont: 12\n",
      "fade: 9\n",
      "away: 9\n",
      "wanna: 6\n",
      "[156, 56, 0.358974358974359, 665]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 96 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 449 characters in the data.\n",
      "The lexical diversity is 0.490 in the data.\n",
      "The 5 most common tokens are:\n",
      "many: 10\n",
      "blowin: 7\n",
      "wind: 7\n",
      "yes: 7\n",
      "answer: 6\n",
      "[96, 47, 0.4895833333333333, 449]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 526 characters in the data.\n",
      "The lexical diversity is 0.389 in the data.\n",
      "The 5 most common tokens are:\n",
      "body: 26\n",
      "heart: 19\n",
      "im: 4\n",
      "eyes: 3\n",
      "feeling: 3\n",
      "[113, 44, 0.3893805309734513, 526]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 84 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 439 characters in the data.\n",
      "The lexical diversity is 0.655 in the data.\n",
      "The 5 most common tokens are:\n",
      "hunger: 11\n",
      "born: 7\n",
      "never: 5\n",
      "youre: 4\n",
      "dies: 4\n",
      "[84, 55, 0.6547619047619048, 439]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 155 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 783 characters in the data.\n",
      "The lexical diversity is 0.342 in the data.\n",
      "The 5 most common tokens are:\n",
      "borrowed: 10\n",
      "time: 10\n",
      "living: 8\n",
      "love: 8\n",
      "another: 8\n",
      "[155, 53, 0.3419354838709677, 783]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 185 tokens in the data.\n",
      "There are 106 unique tokens in the data.\n",
      "There are 880 characters in the data.\n",
      "The lexical diversity is 0.573 in the data.\n",
      "The 5 most common tokens are:\n",
      "boys: 6\n",
      "go: 6\n",
      "girls: 5\n",
      "cant: 5\n",
      "shine: 4\n",
      "[185, 106, 0.572972972972973, 880]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 80 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 403 characters in the data.\n",
      "The lexical diversity is 0.650 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 6\n",
      "cant: 4\n",
      "morei: 4\n",
      "stop: 4\n",
      "know: 3\n",
      "[80, 52, 0.65, 403]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 31 unique tokens in the data.\n",
      "There are 411 characters in the data.\n",
      "The lexical diversity is 0.304 in the data.\n",
      "The 5 most common tokens are:\n",
      "gotta: 13\n",
      "go: 10\n",
      "im: 9\n",
      "way: 6\n",
      "end: 5\n",
      "[102, 31, 0.30392156862745096, 411]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 115 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 496 characters in the data.\n",
      "The lexical diversity is 0.539 in the data.\n",
      "The 5 most common tokens are:\n",
      "ya: 8\n",
      "fool: 6\n",
      "cant: 6\n",
      "cher: 5\n",
      "greg: 4\n",
      "[115, 62, 0.5391304347826087, 496]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 45 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 200 characters in the data.\n",
      "The lexical diversity is 0.622 in the data.\n",
      "The 5 most common tokens are:\n",
      "carnival: 4\n",
      "ill: 4\n",
      "sing: 3\n",
      "time: 3\n",
      "sun: 2\n",
      "[45, 28, 0.6222222222222222, 200]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 758 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 15\n",
      "carousel: 14\n",
      "around: 10\n",
      "know: 5\n",
      "going: 5\n",
      "[146, 73, 0.5, 758]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 79 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 352 characters in the data.\n",
      "The lexical diversity is 0.671 in the data.\n",
      "The 5 most common tokens are:\n",
      "catch: 5\n",
      "wind: 5\n",
      "ah: 4\n",
      "may: 4\n",
      "well: 4\n",
      "[79, 53, 0.6708860759493671, 352]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 124 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 592 characters in the data.\n",
      "The lexical diversity is 0.379 in the data.\n",
      "The 5 most common tokens are:\n",
      "good: 14\n",
      "times: 8\n",
      "long: 7\n",
      "life: 6\n",
      "gonna: 4\n",
      "[124, 47, 0.3790322580645161, 592]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 99 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 455 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "The 5 most common tokens are:\n",
      "sun: 4\n",
      "chastity: 3\n",
      "one: 3\n",
      "make: 3\n",
      "hate: 3\n",
      "[99, 66, 0.6666666666666666, 455]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 136 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 688 characters in the data.\n",
      "The lexical diversity is 0.493 in the data.\n",
      "The 5 most common tokens are:\n",
      "chiquitita: 13\n",
      "sing: 7\n",
      "like: 6\n",
      "new: 5\n",
      "song: 5\n",
      "[136, 67, 0.49264705882352944, 688]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 183 tokens in the data.\n",
      "There are 85 unique tokens in the data.\n",
      "There are 959 characters in the data.\n",
      "The lexical diversity is 0.464 in the data.\n",
      "The 5 most common tokens are:\n",
      "chiquitita: 14\n",
      "tu: 9\n",
      "que: 8\n",
      "quiero: 7\n",
      "compartir: 6\n",
      "[183, 85, 0.4644808743169399, 959]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 311 characters in the data.\n",
      "The lexical diversity is 0.685 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 7\n",
      "time: 6\n",
      "one: 4\n",
      "wish: 3\n",
      "know: 2\n",
      "[73, 50, 0.684931506849315, 311]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 22 tokens in the data.\n",
      "There are 10 unique tokens in the data.\n",
      "There are 145 characters in the data.\n",
      "The lexical diversity is 0.455 in the data.\n",
      "The 5 most common tokens are:\n",
      "nguqo: 4\n",
      "ngqothwane: 4\n",
      "igqira: 2\n",
      "lendlela: 2\n",
      "sebeqabele: 2\n",
      "[22, 10, 0.45454545454545453, 145]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 342 characters in the data.\n",
      "The lexical diversity is 0.603 in the data.\n",
      "The 5 most common tokens are:\n",
      "ill: 8\n",
      "stay: 7\n",
      "come: 5\n",
      "youll: 5\n",
      "true: 4\n",
      "[78, 47, 0.6025641025641025, 342]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 124 tokens in the data.\n",
      "There are 87 unique tokens in the data.\n",
      "There are 577 characters in the data.\n",
      "The lexical diversity is 0.702 in the data.\n",
      "The 5 most common tokens are:\n",
      "come: 7\n",
      "window: 4\n",
      "dont: 4\n",
      "let: 4\n",
      "im: 3\n",
      "[124, 87, 0.7016129032258065, 577]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 143 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 716 characters in the data.\n",
      "The lexical diversity is 0.434 in the data.\n",
      "The 5 most common tokens are:\n",
      "couldve: 19\n",
      "baby: 13\n",
      "see: 7\n",
      "say: 5\n",
      "standing: 5\n",
      "[143, 62, 0.43356643356643354, 716]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 430 characters in the data.\n",
      "The lexical diversity is 0.376 in the data.\n",
      "The 5 most common tokens are:\n",
      "cry: 11\n",
      "like: 10\n",
      "baby: 10\n",
      "think: 5\n",
      "love: 5\n",
      "[93, 35, 0.3763440860215054, 430]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 62 tokens in the data.\n",
      "There are 23 unique tokens in the data.\n",
      "There are 273 characters in the data.\n",
      "The lexical diversity is 0.371 in the data.\n",
      "The 5 most common tokens are:\n",
      "cry: 11\n",
      "sleep: 8\n",
      "hes: 5\n",
      "gone: 5\n",
      "still: 4\n",
      "[62, 23, 0.3709677419354839, 273]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 116 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 589 characters in the data.\n",
      "The lexical diversity is 0.483 in the data.\n",
      "The 5 most common tokens are:\n",
      "dancing: 10\n",
      "queen: 10\n",
      "dance: 5\n",
      "digging: 5\n",
      "youre: 4\n",
      "[116, 56, 0.4827586206896552, 589]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 92 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 497 characters in the data.\n",
      "The lexical diversity is 0.620 in the data.\n",
      "The 5 most common tokens are:\n",
      "dangerous: 6\n",
      "times: 6\n",
      "would: 6\n",
      "keep: 4\n",
      "know: 3\n",
      "[92, 57, 0.6195652173913043, 497]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 80 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 358 characters in the data.\n",
      "The lexical diversity is 0.650 in the data.\n",
      "The 5 most common tokens are:\n",
      "danny: 4\n",
      "boy: 4\n",
      "come: 4\n",
      "oh: 3\n",
      "find: 3\n",
      "[80, 52, 0.65, 358]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 131 tokens in the data.\n",
      "There are 101 unique tokens in the data.\n",
      "There are 655 characters in the data.\n",
      "The lexical diversity is 0.771 in the data.\n",
      "The 5 most common tokens are:\n",
      "dark: 4\n",
      "lady: 4\n",
      "said: 4\n",
      "black: 3\n",
      "chorus: 3\n",
      "[131, 101, 0.7709923664122137, 655]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 94 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 462 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "could: 12\n",
      "start: 6\n",
      "singing: 6\n",
      "song: 5\n",
      "finish: 4\n",
      "[94, 47, 0.5, 462]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 195 tokens in the data.\n",
      "There are 116 unique tokens in the data.\n",
      "There are 964 characters in the data.\n",
      "The lexical diversity is 0.595 in the data.\n",
      "The 5 most common tokens are:\n",
      "youre: 14\n",
      "disaster: 7\n",
      "read: 7\n",
      "lips: 7\n",
      "cake: 5\n",
      "[195, 116, 0.5948717948717949, 964]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 104 tokens in the data.\n",
      "There are 87 unique tokens in the data.\n",
      "There are 521 characters in the data.\n",
      "The lexical diversity is 0.837 in the data.\n",
      "The 5 most common tokens are:\n",
      "dixie: 4\n",
      "wanna: 3\n",
      "like: 3\n",
      "land: 2\n",
      "cotton: 2\n",
      "[104, 87, 0.8365384615384616, 521]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 145 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 744 characters in the data.\n",
      "The lexical diversity is 0.572 in the data.\n",
      "The 5 most common tokens are:\n",
      "dixie: 7\n",
      "girl: 6\n",
      "small: 6\n",
      "day: 4\n",
      "waiting: 3\n",
      "[145, 83, 0.5724137931034483, 744]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 207 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 1028 characters in the data.\n",
      "The lexical diversity is 0.343 in the data.\n",
      "The 5 most common tokens are:\n",
      "anybody: 16\n",
      "really: 16\n",
      "know: 15\n",
      "love: 13\n",
      "somebody: 12\n",
      "[207, 71, 0.34299516908212563, 1028]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 75 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 399 characters in the data.\n",
      "The lexical diversity is 0.373 in the data.\n",
      "The 5 most common tokens are:\n",
      "ever: 16\n",
      "cross: 8\n",
      "mind: 8\n",
      "darling: 7\n",
      "time: 4\n",
      "[75, 28, 0.37333333333333335, 399]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 81 unique tokens in the data.\n",
      "There are 562 characters in the data.\n",
      "The lexical diversity is 0.794 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 4\n",
      "come: 4\n",
      "around: 4\n",
      "im: 3\n",
      "used: 3\n",
      "[102, 81, 0.7941176470588235, 562]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 124 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 557 characters in the data.\n",
      "The lexical diversity is 0.492 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 17\n",
      "dont: 15\n",
      "hide: 11\n",
      "care: 4\n",
      "heart: 3\n",
      "[124, 61, 0.49193548387096775, 557]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 81 unique tokens in the data.\n",
      "There are 622 characters in the data.\n",
      "The lexical diversity is 0.604 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 8\n",
      "aint: 7\n",
      "use: 6\n",
      "think: 5\n",
      "twice: 5\n",
      "[134, 81, 0.6044776119402985, 622]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 537 characters in the data.\n",
      "The lexical diversity is 0.463 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 5\n",
      "time: 5\n",
      "try: 4\n",
      "close: 4\n",
      "rose: 4\n",
      "[121, 56, 0.4628099173553719, 537]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 483 characters in the data.\n",
      "The lexical diversity is 0.406 in the data.\n",
      "The 5 most common tokens are:\n",
      "right: 12\n",
      "alls: 10\n",
      "man: 8\n",
      "woman: 6\n",
      "want: 5\n",
      "[101, 41, 0.40594059405940597, 483]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 153 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 692 characters in the data.\n",
      "The lexical diversity is 0.399 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 15\n",
      "song: 9\n",
      "dove: 7\n",
      "ill: 7\n",
      "lamore: 5\n",
      "[153, 61, 0.39869281045751637, 692]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 112 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 488 characters in the data.\n",
      "The lexical diversity is 0.598 in the data.\n",
      "The 5 most common tokens are:\n",
      "see: 6\n",
      "love: 4\n",
      "sweet: 4\n",
      "never: 4\n",
      "come: 4\n",
      "[112, 67, 0.5982142857142857, 488]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 389 characters in the data.\n",
      "The lexical diversity is 0.577 in the data.\n",
      "The 5 most common tokens are:\n",
      "rock: 6\n",
      "know: 4\n",
      "wont: 4\n",
      "push: 3\n",
      "mountain: 3\n",
      "[78, 45, 0.5769230769230769, 389]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 122 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 591 characters in the data.\n",
      "The lexical diversity is 0.598 in the data.\n",
      "The 5 most common tokens are:\n",
      "believe: 16\n",
      "magic: 10\n",
      "like: 6\n",
      "music: 5\n",
      "go: 4\n",
      "[122, 73, 0.5983606557377049, 591]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 91 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 383 characters in the data.\n",
      "The lexical diversity is 0.440 in the data.\n",
      "The 5 most common tokens are:\n",
      "dream: 8\n",
      "hes: 7\n",
      "oh: 7\n",
      "baby: 4\n",
      "love: 4\n",
      "[91, 40, 0.43956043956043955, 383]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 521 characters in the data.\n",
      "The lexical diversity is 0.460 in the data.\n",
      "The 5 most common tokens are:\n",
      "dressed: 8\n",
      "kill: 8\n",
      "im: 7\n",
      "know: 6\n",
      "one: 4\n",
      "[113, 52, 0.46017699115044247, 521]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 104 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 548 characters in the data.\n",
      "The lexical diversity is 0.481 in the data.\n",
      "The 5 most common tokens are:\n",
      "mornin: 7\n",
      "love: 7\n",
      "early: 6\n",
      "strangers: 6\n",
      "without: 4\n",
      "[104, 50, 0.4807692307692308, 548]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 57 tokens in the data.\n",
      "There are 23 unique tokens in the data.\n",
      "There are 301 characters in the data.\n",
      "The lexical diversity is 0.404 in the data.\n",
      "The 5 most common tokens are:\n",
      "easy: 14\n",
      "people: 7\n",
      "proud: 4\n",
      "cold: 3\n",
      "say: 3\n",
      "[57, 23, 0.40350877192982454, 301]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 106 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 605 characters in the data.\n",
      "The lexical diversity is 0.689 in the data.\n",
      "The 5 most common tokens are:\n",
      "might: 5\n",
      "something: 5\n",
      "elusive: 3\n",
      "butterfly: 3\n",
      "dreams: 3\n",
      "[106, 73, 0.6886792452830188, 605]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 143 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 703 characters in the data.\n",
      "The lexical diversity is 0.350 in the data.\n",
      "The 5 most common tokens are:\n",
      "fire: 16\n",
      "emotional: 13\n",
      "cant: 8\n",
      "see: 6\n",
      "baby: 6\n",
      "[143, 50, 0.34965034965034963, 703]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 132 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 637 characters in the data.\n",
      "The lexical diversity is 0.462 in the data.\n",
      "The 5 most common tokens are:\n",
      "company: 10\n",
      "fast: 7\n",
      "youre: 7\n",
      "life: 4\n",
      "lord: 4\n",
      "[132, 61, 0.4621212121212121, 637]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 167 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 862 characters in the data.\n",
      "The lexical diversity is 0.389 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 16\n",
      "scars: 13\n",
      "favorite: 12\n",
      "loves: 6\n",
      "oh: 6\n",
      "[167, 65, 0.38922155688622756, 862]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 143 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 814 characters in the data.\n",
      "The lexical diversity is 0.573 in the data.\n",
      "The 5 most common tokens are:\n",
      "fernando: 18\n",
      "night: 5\n",
      "would: 5\n",
      "friend: 5\n",
      "could: 4\n",
      "[143, 82, 0.5734265734265734, 814]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 143 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 813 characters in the data.\n",
      "The lexical diversity is 0.580 in the data.\n",
      "The 5 most common tokens are:\n",
      "fernando: 17\n",
      "night: 5\n",
      "would: 5\n",
      "friend: 5\n",
      "could: 4\n",
      "[143, 83, 0.5804195804195804, 813]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 157 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 705 characters in the data.\n",
      "The lexical diversity is 0.522 in the data.\n",
      "The 5 most common tokens are:\n",
      "ive: 12\n",
      "seen: 12\n",
      "thought: 7\n",
      "see: 5\n",
      "time: 5\n",
      "[157, 82, 0.5222929936305732, 705]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 147 tokens in the data.\n",
      "There are 79 unique tokens in the data.\n",
      "There are 723 characters in the data.\n",
      "The lexical diversity is 0.537 in the data.\n",
      "The 5 most common tokens are:\n",
      "still: 8\n",
      "fires: 7\n",
      "eden: 7\n",
      "love: 7\n",
      "remember: 6\n",
      "[147, 79, 0.5374149659863946, 723]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 506 characters in the data.\n",
      "The lexical diversity is 0.726 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 8\n",
      "fit: 7\n",
      "fly: 7\n",
      "cant: 3\n",
      "see: 3\n",
      "[113, 82, 0.7256637168141593, 506]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 124 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 676 characters in the data.\n",
      "The lexical diversity is 0.597 in the data.\n",
      "The 5 most common tokens are:\n",
      "travis: 12\n",
      "wish: 3\n",
      "could: 3\n",
      "helped: 3\n",
      "somehow: 3\n",
      "[124, 74, 0.5967741935483871, 676]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 118 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 638 characters in the data.\n",
      "The lexical diversity is 0.542 in the data.\n",
      "The 5 most common tokens are:\n",
      "whats: 14\n",
      "stop: 7\n",
      "sound: 7\n",
      "everybody: 7\n",
      "look: 7\n",
      "[118, 64, 0.5423728813559322, 638]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 404 characters in the data.\n",
      "The lexical diversity is 0.731 in the data.\n",
      "The 5 most common tokens are:\n",
      "whatever: 4\n",
      "games: 3\n",
      "youre: 3\n",
      "love: 3\n",
      "im: 2\n",
      "[78, 57, 0.7307692307692307, 404]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 117 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 603 characters in the data.\n",
      "The lexical diversity is 0.513 in the data.\n",
      "The 5 most common tokens are:\n",
      "oh: 10\n",
      "cadillac: 8\n",
      "geronimos: 7\n",
      "back: 7\n",
      "boys: 6\n",
      "[117, 60, 0.5128205128205128, 603]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 156 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 793 characters in the data.\n",
      "The lexical diversity is 0.378 in the data.\n",
      "The 5 most common tokens are:\n",
      "gimme: 33\n",
      "man: 11\n",
      "midnight: 11\n",
      "theres: 4\n",
      "one: 4\n",
      "[156, 59, 0.3782051282051282, 793]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 120 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 500 characters in the data.\n",
      "The lexical diversity is 0.283 in the data.\n",
      "The 5 most common tokens are:\n",
      "wait: 12\n",
      "girl: 11\n",
      "dont: 11\n",
      "come: 11\n",
      "wanna: 11\n",
      "[120, 34, 0.2833333333333333, 500]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 564 characters in the data.\n",
      "The lexical diversity is 0.328 in the data.\n",
      "The 5 most common tokens are:\n",
      "away: 28\n",
      "wanna: 12\n",
      "take: 8\n",
      "get: 6\n",
      "old: 6\n",
      "[134, 44, 0.3283582089552239, 564]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 111 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 509 characters in the data.\n",
      "The lexical diversity is 0.640 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 8\n",
      "give: 5\n",
      "fightin: 5\n",
      "chance: 5\n",
      "away: 3\n",
      "[111, 71, 0.6396396396396397, 509]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 92 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 373 characters in the data.\n",
      "The lexical diversity is 0.380 in the data.\n",
      "The 5 most common tokens are:\n",
      "go: 18\n",
      "darlin: 7\n",
      "dont: 6\n",
      "see: 5\n",
      "want: 5\n",
      "[92, 35, 0.3804347826086957, 373]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 75 unique tokens in the data.\n",
      "There are 575 characters in the data.\n",
      "The lexical diversity is 0.682 in the data.\n",
      "The 5 most common tokens are:\n",
      "chorus: 4\n",
      "tramps: 3\n",
      "thieves: 3\n",
      "money: 3\n",
      "theyd: 3\n",
      "[110, 75, 0.6818181818181818, 575]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 391 characters in the data.\n",
      "The lexical diversity is 0.808 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 3\n",
      "chorus: 3\n",
      "halfbreed: 3\n",
      "cherokee: 2\n",
      "ashamed: 2\n",
      "[73, 59, 0.8082191780821918, 391]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 92 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 457 characters in the data.\n",
      "The lexical diversity is 0.511 in the data.\n",
      "The 5 most common tokens are:\n",
      "joe: 10\n",
      "president: 5\n",
      "happiness: 4\n",
      "thing: 4\n",
      "called: 4\n",
      "[92, 47, 0.5108695652173914, 457]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 125 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 568 characters in the data.\n",
      "The lexical diversity is 0.520 in the data.\n",
      "The 5 most common tokens are:\n",
      "happy: 7\n",
      "day: 7\n",
      "met: 6\n",
      "ever: 6\n",
      "never: 5\n",
      "[125, 65, 0.52, 568]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 136 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 670 characters in the data.\n",
      "The lexical diversity is 0.529 in the data.\n",
      "The 5 most common tokens are:\n",
      "hard: 7\n",
      "enough: 7\n",
      "getting: 7\n",
      "dont: 5\n",
      "could: 5\n",
      "[136, 72, 0.5294117647058824, 670]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 70 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 338 characters in the data.\n",
      "The lexical diversity is 0.600 in the data.\n",
      "The 5 most common tokens are:\n",
      "hes: 7\n",
      "brother: 7\n",
      "aint: 5\n",
      "heavy: 5\n",
      "long: 3\n",
      "[70, 42, 0.6, 338]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 153 tokens in the data.\n",
      "There are 93 unique tokens in the data.\n",
      "There are 774 characters in the data.\n",
      "The lexical diversity is 0.608 in the data.\n",
      "The 5 most common tokens are:\n",
      "heart: 14\n",
      "stone: 10\n",
      "wish: 7\n",
      "dont: 5\n",
      "sometimes: 5\n",
      "[153, 93, 0.6078431372549019, 774]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 529 characters in the data.\n",
      "The lexical diversity is 0.645 in the data.\n",
      "The 5 most common tokens are:\n",
      "hell: 9\n",
      "never: 9\n",
      "know: 9\n",
      "mine: 3\n",
      "son: 3\n",
      "[110, 71, 0.6454545454545455, 529]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 231 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 1026 characters in the data.\n",
      "The lexical diversity is 0.221 in the data.\n",
      "The 5 most common tokens are:\n",
      "see: 16\n",
      "something: 16\n",
      "go: 12\n",
      "lets: 12\n",
      "roll: 12\n",
      "[231, 51, 0.22077922077922077, 1026]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 95 tokens in the data.\n",
      "There are 78 unique tokens in the data.\n",
      "There are 483 characters in the data.\n",
      "The lexical diversity is 0.821 in the data.\n",
      "The 5 most common tokens are:\n",
      "beautiful: 4\n",
      "like: 3\n",
      "ill: 3\n",
      "made: 2\n",
      "music: 2\n",
      "[95, 78, 0.8210526315789474, 483]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 107 tokens in the data.\n",
      "There are 32 unique tokens in the data.\n",
      "There are 433 characters in the data.\n",
      "The lexical diversity is 0.299 in the data.\n",
      "The 5 most common tokens are:\n",
      "shot: 11\n",
      "hey: 10\n",
      "joe: 9\n",
      "goin: 6\n",
      "said: 6\n",
      "[107, 32, 0.29906542056074764, 433]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 150 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 707 characters in the data.\n",
      "The lexical diversity is 0.453 in the data.\n",
      "The 5 most common tokens are:\n",
      "holdin: 26\n",
      "love: 16\n",
      "im: 15\n",
      "time: 11\n",
      "mind: 6\n",
      "[150, 68, 0.4533333333333333, 707]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 176 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 835 characters in the data.\n",
      "The lexical diversity is 0.375 in the data.\n",
      "The 5 most common tokens are:\n",
      "holy: 16\n",
      "smoke: 16\n",
      "say: 11\n",
      "get: 6\n",
      "solve: 6\n",
      "[176, 66, 0.375, 835]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 106 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 616 characters in the data.\n",
      "The lexical diversity is 0.604 in the data.\n",
      "The 5 most common tokens are:\n",
      "home: 9\n",
      "homeward: 7\n",
      "bound: 7\n",
      "silently: 4\n",
      "evry: 3\n",
      "[106, 64, 0.6037735849056604, 616]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 74 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 330 characters in the data.\n",
      "The lexical diversity is 0.635 in the data.\n",
      "The 5 most common tokens are:\n",
      "house: 7\n",
      "one: 5\n",
      "home: 4\n",
      "room: 4\n",
      "chair: 3\n",
      "[74, 47, 0.6351351351351351, 330]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 88 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 421 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "mend: 7\n",
      "broken: 7\n",
      "heart: 5\n",
      "stop: 4\n",
      "man: 3\n",
      "[88, 44, 0.5, 421]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 88 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 395 characters in the data.\n",
      "The lexical diversity is 0.455 in the data.\n",
      "The 5 most common tokens are:\n",
      "long: 9\n",
      "going: 9\n",
      "oh: 7\n",
      "heaven: 4\n",
      "could: 3\n",
      "[88, 40, 0.45454545454545453, 395]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 129 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 643 characters in the data.\n",
      "The lexical diversity is 0.442 in the data.\n",
      "The 5 most common tokens are:\n",
      "believe: 34\n",
      "man: 21\n",
      "got: 8\n",
      "every: 3\n",
      "baby: 3\n",
      "[129, 57, 0.4418604651162791, 643]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 152 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 781 characters in the data.\n",
      "The lexical diversity is 0.395 in the data.\n",
      "The 5 most common tokens are:\n",
      "dream: 15\n",
      "youre: 10\n",
      "dont: 9\n",
      "sleep: 9\n",
      "never: 6\n",
      "[152, 60, 0.39473684210526316, 781]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 86 tokens in the data.\n",
      "There are 49 unique tokens in the data.\n",
      "There are 413 characters in the data.\n",
      "The lexical diversity is 0.570 in the data.\n",
      "The 5 most common tokens are:\n",
      "youve: 9\n",
      "loved: 8\n",
      "somebody: 7\n",
      "ive: 5\n",
      "like: 4\n",
      "[86, 49, 0.5697674418604651, 413]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 437 characters in the data.\n",
      "The lexical diversity is 0.484 in the data.\n",
      "The 5 most common tokens are:\n",
      "feel: 6\n",
      "something: 5\n",
      "air: 5\n",
      "magic: 4\n",
      "used: 4\n",
      "[93, 45, 0.4838709677419355, 437]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 204 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 888 characters in the data.\n",
      "The lexical diversity is 0.314 in the data.\n",
      "The 5 most common tokens are:\n",
      "could: 19\n",
      "back: 15\n",
      "turn: 11\n",
      "time: 11\n",
      "id: 7\n",
      "[204, 64, 0.3137254901960784, 888]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 75 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 359 characters in the data.\n",
      "The lexical diversity is 0.640 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 6\n",
      "knew: 5\n",
      "would: 4\n",
      "many: 4\n",
      "cowboy: 3\n",
      "[75, 48, 0.64, 359]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 678 characters in the data.\n",
      "The lexical diversity is 0.425 in the data.\n",
      "The 5 most common tokens are:\n",
      "away: 9\n",
      "take: 8\n",
      "baby: 7\n",
      "since: 7\n",
      "youve: 7\n",
      "[134, 57, 0.4253731343283582, 678]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 147 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 694 characters in the data.\n",
      "The lexical diversity is 0.320 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 21\n",
      "gonna: 18\n",
      "found: 12\n",
      "hes: 6\n",
      "new: 5\n",
      "[147, 47, 0.3197278911564626, 694]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 59 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 239 characters in the data.\n",
      "The lexical diversity is 0.475 in the data.\n",
      "The 5 most common tokens are:\n",
      "bad: 13\n",
      "got: 7\n",
      "aint: 5\n",
      "good: 4\n",
      "way: 2\n",
      "[59, 28, 0.4745762711864407, 239]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 72 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 345 characters in the data.\n",
      "The lexical diversity is 0.569 in the data.\n",
      "The 5 most common tokens are:\n",
      "sleep: 13\n",
      "go: 7\n",
      "imagine: 6\n",
      "youre: 6\n",
      "look: 2\n",
      "[72, 41, 0.5694444444444444, 345]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 115 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 467 characters in the data.\n",
      "The lexical diversity is 0.513 in the data.\n",
      "The 5 most common tokens are:\n",
      "got: 25\n",
      "babe: 15\n",
      "dont: 4\n",
      "say: 3\n",
      "wont: 3\n",
      "[115, 59, 0.5130434782608696, 467]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 59 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 267 characters in the data.\n",
      "The lexical diversity is 0.559 in the data.\n",
      "The 5 most common tokens are:\n",
      "alone: 6\n",
      "hate: 5\n",
      "sleep: 5\n",
      "know: 3\n",
      "could: 2\n",
      "[59, 33, 0.559322033898305, 267]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 132 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 675 characters in the data.\n",
      "The lexical diversity is 0.462 in the data.\n",
      "The 5 most common tokens are:\n",
      "hope: 15\n",
      "find: 8\n",
      "youre: 6\n",
      "know: 5\n",
      "id: 3\n",
      "[132, 61, 0.4621212121212121, 675]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 45 tokens in the data.\n",
      "There are 18 unique tokens in the data.\n",
      "There are 168 characters in the data.\n",
      "The lexical diversity is 0.400 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 7\n",
      "uh: 6\n",
      "yes: 5\n",
      "know: 4\n",
      "dont: 4\n",
      "[45, 18, 0.4, 168]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 540 characters in the data.\n",
      "The lexical diversity is 0.536 in the data.\n",
      "The 5 most common tokens are:\n",
      "stop: 7\n",
      "ill: 6\n",
      "never: 6\n",
      "loving: 6\n",
      "one: 4\n",
      "[110, 59, 0.5363636363636364, 540]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 111 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 510 characters in the data.\n",
      "The lexical diversity is 0.604 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 16\n",
      "making: 6\n",
      "oh: 6\n",
      "ooh: 5\n",
      "dont: 3\n",
      "[111, 67, 0.6036036036036037, 510]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 50 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 240 characters in the data.\n",
      "The lexical diversity is 0.720 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 4\n",
      "im: 3\n",
      "blowin: 3\n",
      "away: 3\n",
      "ive: 2\n",
      "[50, 36, 0.72, 240]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 646 characters in the data.\n",
      "The lexical diversity is 0.364 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 12\n",
      "im: 10\n",
      "middle: 9\n",
      "something: 8\n",
      "understand: 8\n",
      "[121, 44, 0.36363636363636365, 646]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 72 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 393 characters in the data.\n",
      "The lexical diversity is 0.861 in the data.\n",
      "The 5 most common tokens are:\n",
      "dream: 3\n",
      "impossible: 2\n",
      "fight: 2\n",
      "right: 2\n",
      "reach: 2\n",
      "[72, 62, 0.8611111111111112, 393]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 77 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 397 characters in the data.\n",
      "The lexical diversity is 0.727 in the data.\n",
      "The 5 most common tokens are:\n",
      "like: 4\n",
      "chorus: 3\n",
      "night: 2\n",
      "mama: 2\n",
      "used: 2\n",
      "[77, 56, 0.7272727272727273, 397]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 719 characters in the data.\n",
      "The lexical diversity is 0.425 in the data.\n",
      "The 5 most common tokens are:\n",
      "got: 9\n",
      "way: 8\n",
      "im: 6\n",
      "take: 6\n",
      "paralyze: 5\n",
      "[146, 62, 0.4246575342465753, 719]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 412 characters in the data.\n",
      "The lexical diversity is 0.724 in the data.\n",
      "The 5 most common tokens are:\n",
      "danced: 7\n",
      "saw: 4\n",
      "man: 3\n",
      "wife: 3\n",
      "kept: 3\n",
      "[87, 63, 0.7241379310344828, 412]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 68 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 348 characters in the data.\n",
      "The lexical diversity is 0.603 in the data.\n",
      "The 5 most common tokens are:\n",
      "cant: 4\n",
      "get: 4\n",
      "island: 3\n",
      "need: 3\n",
      "way: 3\n",
      "[68, 41, 0.6029411764705882, 348]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 70 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 324 characters in the data.\n",
      "The lexical diversity is 0.857 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 4\n",
      "adds: 3\n",
      "way: 2\n",
      "look: 2\n",
      "heart: 2\n",
      "[70, 60, 0.8571428571428571, 324]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 56 tokens in the data.\n",
      "There are 31 unique tokens in the data.\n",
      "There are 260 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "The 5 most common tokens are:\n",
      "eyes: 6\n",
      "gets: 4\n",
      "go: 4\n",
      "around: 4\n",
      "many: 4\n",
      "[56, 31, 0.5535714285714286, 260]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 69 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 319 characters in the data.\n",
      "The lexical diversity is 0.768 in the data.\n",
      "The 5 most common tokens are:\n",
      "away: 6\n",
      "threw: 4\n",
      "love: 4\n",
      "dont: 2\n",
      "cant: 2\n",
      "[69, 53, 0.7681159420289855, 319]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 89 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 433 characters in the data.\n",
      "The lexical diversity is 0.472 in the data.\n",
      "The 5 most common tokens are:\n",
      "monday: 8\n",
      "might: 7\n",
      "well: 7\n",
      "stay: 7\n",
      "nothing: 6\n",
      "[89, 42, 0.47191011235955055, 433]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 631 characters in the data.\n",
      "The lexical diversity is 0.511 in the data.\n",
      "The 5 most common tokens are:\n",
      "shame: 12\n",
      "cryin: 11\n",
      "love: 11\n",
      "dont: 10\n",
      "happen: 9\n",
      "[137, 70, 0.5109489051094891, 631]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 482 characters in the data.\n",
      "The lexical diversity is 0.431 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 10\n",
      "mans: 7\n",
      "hes: 7\n",
      "lost: 7\n",
      "nothing: 6\n",
      "[102, 44, 0.43137254901960786, 482]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 56 tokens in the data.\n",
      "There are 31 unique tokens in the data.\n",
      "There are 278 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "The 5 most common tokens are:\n",
      "unusual: 9\n",
      "anyone: 6\n",
      "love: 5\n",
      "see: 3\n",
      "find: 3\n",
      "[56, 31, 0.5535714285714286, 278]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 84 tokens in the data.\n",
      "There are 29 unique tokens in the data.\n",
      "There are 366 characters in the data.\n",
      "The lexical diversity is 0.345 in the data.\n",
      "The 5 most common tokens are:\n",
      "late: 11\n",
      "love: 11\n",
      "say: 4\n",
      "bad: 4\n",
      "know: 4\n",
      "[84, 29, 0.34523809523809523, 366]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 191 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 892 characters in the data.\n",
      "The lexical diversity is 0.398 in the data.\n",
      "The 5 most common tokens are:\n",
      "time: 31\n",
      "theres: 17\n",
      "walk: 14\n",
      "alone: 14\n",
      "gotta: 10\n",
      "[191, 76, 0.39790575916230364, 892]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 161 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 770 characters in the data.\n",
      "The lexical diversity is 0.416 in the data.\n",
      "The 5 most common tokens are:\n",
      "come: 24\n",
      "till: 16\n",
      "burn: 16\n",
      "walk: 12\n",
      "guilded: 10\n",
      "[161, 67, 0.4161490683229814, 770]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 501 characters in the data.\n",
      "The lexical diversity is 0.716 in the data.\n",
      "The 5 most common tokens are:\n",
      "want: 17\n",
      "bad: 4\n",
      "honey: 4\n",
      "wait: 3\n",
      "wasnt: 2\n",
      "[102, 73, 0.7156862745098039, 501]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 67 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 319 characters in the data.\n",
      "The lexical diversity is 0.537 in the data.\n",
      "The 5 most common tokens are:\n",
      "wasnt: 6\n",
      "ready: 6\n",
      "walked: 6\n",
      "last: 3\n",
      "night: 3\n",
      "[67, 36, 0.5373134328358209, 319]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 54 tokens in the data.\n",
      "There are 24 unique tokens in the data.\n",
      "There are 280 characters in the data.\n",
      "The lexical diversity is 0.444 in the data.\n",
      "The 5 most common tokens are:\n",
      "wait: 8\n",
      "till: 5\n",
      "forever: 4\n",
      "takes: 3\n",
      "thousand: 3\n",
      "[54, 24, 0.4444444444444444, 280]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 99 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 455 characters in the data.\n",
      "The lexical diversity is 0.586 in the data.\n",
      "The 5 most common tokens are:\n",
      "way: 8\n",
      "treated: 8\n",
      "wouldnt: 7\n",
      "dog: 7\n",
      "treat: 6\n",
      "[99, 58, 0.5858585858585859, 455]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 122 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 555 characters in the data.\n",
      "The lexical diversity is 0.574 in the data.\n",
      "The 5 most common tokens are:\n",
      "sonny: 6\n",
      "boy: 6\n",
      "im: 6\n",
      "forsake: 4\n",
      "coming: 4\n",
      "[122, 70, 0.5737704918032787, 555]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 124 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 586 characters in the data.\n",
      "The lexical diversity is 0.524 in the data.\n",
      "The 5 most common tokens are:\n",
      "julie: 31\n",
      "lying: 6\n",
      "im: 5\n",
      "youre: 5\n",
      "well: 4\n",
      "[124, 65, 0.5241935483870968, 586]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 94 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 464 characters in the data.\n",
      "The lexical diversity is 0.479 in the data.\n",
      "The 5 most common tokens are:\n",
      "enough: 16\n",
      "keep: 9\n",
      "hangin: 8\n",
      "ah: 5\n",
      "honey: 4\n",
      "[94, 45, 0.4787234042553192, 464]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 210 tokens in the data.\n",
      "There are 105 unique tokens in the data.\n",
      "There are 965 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 10\n",
      "youre: 9\n",
      "come: 9\n",
      "baby: 9\n",
      "tonight: 8\n",
      "[210, 105, 0.5, 965]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 103 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 472 characters in the data.\n",
      "The lexical diversity is 0.621 in the data.\n",
      "The 5 most common tokens are:\n",
      "one: 8\n",
      "time: 8\n",
      "ive: 5\n",
      "got: 4\n",
      "believe: 4\n",
      "[103, 64, 0.6213592233009708, 472]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 77 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 391 characters in the data.\n",
      "The lexical diversity is 0.545 in the data.\n",
      "The 5 most common tokens are:\n",
      "ive: 6\n",
      "youre: 5\n",
      "looking: 5\n",
      "never: 3\n",
      "time: 3\n",
      "[77, 42, 0.5454545454545454, 391]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 166 tokens in the data.\n",
      "There are 79 unique tokens in the data.\n",
      "There are 811 characters in the data.\n",
      "The lexical diversity is 0.476 in the data.\n",
      "The 5 most common tokens are:\n",
      "kiss: 36\n",
      "makin: 4\n",
      "miss: 4\n",
      "hiding: 4\n",
      "daylight: 4\n",
      "[166, 79, 0.4759036144578313, 811]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 127 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 652 characters in the data.\n",
      "The lexical diversity is 0.339 in the data.\n",
      "The 5 most common tokens are:\n",
      "knock: 28\n",
      "better: 12\n",
      "wood: 11\n",
      "love: 7\n",
      "thunder: 6\n",
      "[127, 43, 0.33858267716535434, 652]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 144 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 692 characters in the data.\n",
      "The lexical diversity is 0.451 in the data.\n",
      "The 5 most common tokens are:\n",
      "get: 16\n",
      "im: 12\n",
      "coming: 6\n",
      "la: 5\n",
      "plane: 5\n",
      "[144, 65, 0.4513888888888889, 692]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 508 characters in the data.\n",
      "The lexical diversity is 0.421 in the data.\n",
      "The 5 most common tokens are:\n",
      "lay: 20\n",
      "stay: 12\n",
      "baby: 11\n",
      "across: 6\n",
      "big: 6\n",
      "[121, 51, 0.4214876033057851, 508]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 65 tokens in the data.\n",
      "There are 21 unique tokens in the data.\n",
      "There are 256 characters in the data.\n",
      "The lexical diversity is 0.323 in the data.\n",
      "The 5 most common tokens are:\n",
      "let: 16\n",
      "easy: 7\n",
      "youre: 6\n",
      "ah: 6\n",
      "gonna: 5\n",
      "[65, 21, 0.3230769230769231, 256]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 144 tokens in the data.\n",
      "There are 85 unique tokens in the data.\n",
      "There are 699 characters in the data.\n",
      "The lexical diversity is 0.590 in the data.\n",
      "The 5 most common tokens are:\n",
      "shes: 13\n",
      "pretty: 9\n",
      "tied: 9\n",
      "hangin: 6\n",
      "upside: 6\n",
      "[144, 85, 0.5902777777777778, 699]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 114 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 526 characters in the data.\n",
      "The lexical diversity is 0.596 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 5\n",
      "lie: 4\n",
      "youre: 4\n",
      "us: 4\n",
      "one: 4\n",
      "[114, 68, 0.5964912280701754, 526]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 149 tokens in the data.\n",
      "There are 106 unique tokens in the data.\n",
      "There are 794 characters in the data.\n",
      "The lexical diversity is 0.711 in the data.\n",
      "The 5 most common tokens are:\n",
      "like: 8\n",
      "feel: 6\n",
      "rolling: 4\n",
      "stone: 4\n",
      "used: 4\n",
      "[149, 106, 0.7114093959731543, 794]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 52 tokens in the data.\n",
      "There are 38 unique tokens in the data.\n",
      "There are 275 characters in the data.\n",
      "The lexical diversity is 0.731 in the data.\n",
      "The 5 most common tokens are:\n",
      "living: 3\n",
      "sad: 3\n",
      "house: 2\n",
      "divided: 2\n",
      "look: 2\n",
      "[52, 38, 0.7307692307692307, 275]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 130 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 639 characters in the data.\n",
      "The lexical diversity is 0.431 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 14\n",
      "long: 9\n",
      "affair: 9\n",
      "distant: 8\n",
      "station: 8\n",
      "[130, 56, 0.4307692307692308, 639]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 46 tokens in the data.\n",
      "There are 21 unique tokens in the data.\n",
      "There are 200 characters in the data.\n",
      "The lexical diversity is 0.457 in the data.\n",
      "The 5 most common tokens are:\n",
      "look: 7\n",
      "tell: 6\n",
      "see: 6\n",
      "nights: 2\n",
      "long: 2\n",
      "[46, 21, 0.45652173913043476, 200]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 154 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 826 characters in the data.\n",
      "The lexical diversity is 0.370 in the data.\n",
      "The 5 most common tokens are:\n",
      "enough: 21\n",
      "love: 18\n",
      "understanding: 9\n",
      "theres: 6\n",
      "got: 5\n",
      "[154, 57, 0.37012987012987014, 826]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 105 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 534 characters in the data.\n",
      "The lexical diversity is 0.552 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 10\n",
      "enough: 10\n",
      "gotta: 6\n",
      "comes: 4\n",
      "goes: 3\n",
      "[105, 58, 0.5523809523809524, 534]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 500 characters in the data.\n",
      "The lexical diversity is 0.464 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 19\n",
      "hurts: 13\n",
      "know: 6\n",
      "lot: 5\n",
      "isnt: 4\n",
      "[110, 51, 0.4636363636363636, 500]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 89 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 408 characters in the data.\n",
      "The lexical diversity is 0.562 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 13\n",
      "hurts: 8\n",
      "lot: 5\n",
      "know: 4\n",
      "ive: 3\n",
      "[89, 50, 0.5617977528089888, 408]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 540 characters in the data.\n",
      "The lexical diversity is 0.398 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 15\n",
      "place: 10\n",
      "lonely: 7\n",
      "im: 7\n",
      "almost: 6\n",
      "[113, 45, 0.39823008849557523, 540]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 715 characters in the data.\n",
      "The lexical diversity is 0.575 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 16\n",
      "groove: 16\n",
      "move: 14\n",
      "get: 4\n",
      "like: 3\n",
      "[146, 84, 0.5753424657534246, 715]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 68 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 296 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "ill: 5\n",
      "love: 4\n",
      "oh: 4\n",
      "heart: 3\n",
      "ever: 3\n",
      "[68, 34, 0.5, 296]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 119 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 638 characters in the data.\n",
      "The lexical diversity is 0.437 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 12\n",
      "rooftop: 8\n",
      "remember: 7\n",
      "got: 6\n",
      "night: 5\n",
      "[119, 52, 0.4369747899159664, 638]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 120 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 650 characters in the data.\n",
      "The lexical diversity is 0.525 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 13\n",
      "one: 13\n",
      "another: 13\n",
      "everybody: 9\n",
      "needs: 3\n",
      "[120, 63, 0.525, 650]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 108 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 534 characters in the data.\n",
      "The lexical diversity is 0.407 in the data.\n",
      "The 5 most common tokens are:\n",
      "pain: 8\n",
      "theres: 7\n",
      "well: 6\n",
      "guess: 6\n",
      "help: 6\n",
      "[108, 44, 0.4074074074074074, 534]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 75 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 400 characters in the data.\n",
      "The lexical diversity is 0.813 in the data.\n",
      "The 5 most common tokens are:\n",
      "well: 4\n",
      "lovers: 3\n",
      "forever: 2\n",
      "offer: 2\n",
      "show: 2\n",
      "[75, 61, 0.8133333333333334, 400]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 89 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 408 characters in the data.\n",
      "The lexical diversity is 0.663 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 7\n",
      "high: 4\n",
      "mi: 4\n",
      "amore: 4\n",
      "could: 4\n",
      "[89, 59, 0.6629213483146067, 408]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 86 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 354 characters in the data.\n",
      "The lexical diversity is 0.674 in the data.\n",
      "The 5 most common tokens are:\n",
      "put: 11\n",
      "lid: 11\n",
      "right: 3\n",
      "time: 3\n",
      "whats: 2\n",
      "[86, 58, 0.6744186046511628, 354]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 105 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 451 characters in the data.\n",
      "The lexical diversity is 0.343 in the data.\n",
      "The 5 most common tokens are:\n",
      "main: 15\n",
      "man: 15\n",
      "youre: 14\n",
      "oh: 8\n",
      "woman: 6\n",
      "[105, 36, 0.34285714285714286, 451]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 111 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 465 characters in the data.\n",
      "The lexical diversity is 0.495 in the data.\n",
      "The 5 most common tokens are:\n",
      "make: 11\n",
      "man: 9\n",
      "love: 6\n",
      "lord: 5\n",
      "ah: 5\n",
      "[111, 55, 0.4954954954954955, 465]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 108 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 512 characters in the data.\n",
      "The lexical diversity is 0.583 in the data.\n",
      "The 5 most common tokens are:\n",
      "mama: 10\n",
      "dollies: 5\n",
      "babies: 5\n",
      "away: 5\n",
      "big: 4\n",
      "[108, 63, 0.5833333333333334, 512]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 159 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 692 characters in the data.\n",
      "The lexical diversity is 0.428 in the data.\n",
      "The 5 most common tokens are:\n",
      "mamma: 11\n",
      "mia: 11\n",
      "ive: 9\n",
      "go: 9\n",
      "know: 6\n",
      "[159, 68, 0.4276729559748428, 692]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 170 tokens in the data.\n",
      "There are 124 unique tokens in the data.\n",
      "There are 803 characters in the data.\n",
      "The lexical diversity is 0.729 in the data.\n",
      "The 5 most common tokens are:\n",
      "build: 4\n",
      "death: 4\n",
      "hide: 4\n",
      "see: 4\n",
      "im: 4\n",
      "[170, 124, 0.7294117647058823, 803]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 397 characters in the data.\n",
      "The lexical diversity is 0.872 in the data.\n",
      "The 5 most common tokens are:\n",
      "melody: 6\n",
      "days: 3\n",
      "home: 2\n",
      "sleep: 2\n",
      "wont: 2\n",
      "[78, 68, 0.8717948717948718, 397]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 90 unique tokens in the data.\n",
      "There are 565 characters in the data.\n",
      "The lexical diversity is 0.744 in the data.\n",
      "The 5 most common tokens are:\n",
      "milord: 12\n",
      "come: 3\n",
      "lips: 3\n",
      "love: 3\n",
      "hearts: 3\n",
      "[121, 90, 0.743801652892562, 565]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 173 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 893 characters in the data.\n",
      "The lexical diversity is 0.376 in the data.\n",
      "The 5 most common tokens are:\n",
      "mirror: 22\n",
      "image: 21\n",
      "see: 10\n",
      "life: 6\n",
      "think: 5\n",
      "[173, 65, 0.37572254335260113, 893]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 118 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 617 characters in the data.\n",
      "The lexical diversity is 0.619 in the data.\n",
      "The 5 most common tokens are:\n",
      "little: 10\n",
      "may: 5\n",
      "miss: 4\n",
      "subway: 4\n",
      "1952: 4\n",
      "[118, 73, 0.6186440677966102, 617]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 80 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 335 characters in the data.\n",
      "The lexical diversity is 0.525 in the data.\n",
      "The 5 most common tokens are:\n",
      "momma: 10\n",
      "hey: 10\n",
      "look: 6\n",
      "sharp: 6\n",
      "ill: 3\n",
      "[80, 42, 0.525, 335]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 86 tokens in the data.\n",
      "There are 37 unique tokens in the data.\n",
      "There are 384 characters in the data.\n",
      "The lexical diversity is 0.430 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 7\n",
      "loving: 6\n",
      "oh: 4\n",
      "youre: 3\n",
      "youll: 3\n",
      "[86, 37, 0.43023255813953487, 384]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 77 tokens in the data.\n",
      "There are 18 unique tokens in the data.\n",
      "There are 323 characters in the data.\n",
      "The lexical diversity is 0.234 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 23\n",
      "way: 9\n",
      "move: 8\n",
      "keep: 6\n",
      "groove: 4\n",
      "[77, 18, 0.23376623376623376, 323]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 434 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 8\n",
      "change: 6\n",
      "strange: 5\n",
      "ask: 4\n",
      "face: 3\n",
      "[87, 58, 0.6666666666666666, 434]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 83 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 373 characters in the data.\n",
      "The lexical diversity is 0.337 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 32\n",
      "good: 10\n",
      "oh: 8\n",
      "everywhere: 4\n",
      "understood: 3\n",
      "[83, 28, 0.3373493975903614, 373]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 114 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 526 characters in the data.\n",
      "The lexical diversity is 0.421 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 29\n",
      "know: 6\n",
      "youre: 5\n",
      "feel: 5\n",
      "somewhere: 4\n",
      "[114, 48, 0.42105263157894735, 526]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 116 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 508 characters in the data.\n",
      "The lexical diversity is 0.578 in the data.\n",
      "The 5 most common tokens are:\n",
      "far: 9\n",
      "gone: 9\n",
      "know: 9\n",
      "doesnt: 5\n",
      "son: 4\n",
      "[116, 67, 0.5775862068965517, 508]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 514 characters in the data.\n",
      "The lexical diversity is 0.566 in the data.\n",
      "The 5 most common tokens are:\n",
      "needles: 7\n",
      "pins: 7\n",
      "stop: 5\n",
      "saw: 4\n",
      "face: 4\n",
      "[113, 64, 0.5663716814159292, 514]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 88 tokens in the data.\n",
      "There are 39 unique tokens in the data.\n",
      "There are 437 characters in the data.\n",
      "The lexical diversity is 0.443 in the data.\n",
      "The 5 most common tokens are:\n",
      "never: 8\n",
      "well: 8\n",
      "dont: 4\n",
      "oklahoma: 4\n",
      "matter: 4\n",
      "[88, 39, 0.4431818181818182, 437]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 463 characters in the data.\n",
      "The lexical diversity is 0.676 in the data.\n",
      "The 5 most common tokens are:\n",
      "cant: 7\n",
      "wait: 6\n",
      "holy: 5\n",
      "mother: 5\n",
      "ive: 3\n",
      "[102, 69, 0.6764705882352942, 463]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 130 tokens in the data.\n",
      "There are 79 unique tokens in the data.\n",
      "There are 666 characters in the data.\n",
      "The lexical diversity is 0.608 in the data.\n",
      "The 5 most common tokens are:\n",
      "world: 5\n",
      "know: 5\n",
      "enough: 4\n",
      "love: 4\n",
      "either: 4\n",
      "[130, 79, 0.6076923076923076, 666]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 126 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 564 characters in the data.\n",
      "The lexical diversity is 0.659 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 6\n",
      "river: 6\n",
      "dont: 6\n",
      "ol: 5\n",
      "keeps: 4\n",
      "[126, 83, 0.6587301587301587, 564]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 501 characters in the data.\n",
      "The lexical diversity is 0.518 in the data.\n",
      "The 5 most common tokens are:\n",
      "one: 19\n",
      "love: 6\n",
      "end: 4\n",
      "much: 4\n",
      "take: 4\n",
      "[110, 57, 0.5181818181818182, 501]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 116 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 551 characters in the data.\n",
      "The lexical diversity is 0.388 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 13\n",
      "cant: 13\n",
      "find: 12\n",
      "one: 11\n",
      "honest: 11\n",
      "[116, 45, 0.3879310344827586, 551]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 117 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 595 characters in the data.\n",
      "The lexical diversity is 0.462 in the data.\n",
      "The 5 most common tokens are:\n",
      "one: 13\n",
      "us: 13\n",
      "lonely: 5\n",
      "wishing: 5\n",
      "feeling: 4\n",
      "[117, 54, 0.46153846153846156, 595]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 131 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 596 characters in the data.\n",
      "The lexical diversity is 0.412 in the data.\n",
      "The 5 most common tokens are:\n",
      "one: 18\n",
      "step: 17\n",
      "small: 16\n",
      "time: 7\n",
      "weve: 5\n",
      "[131, 54, 0.4122137404580153, 596]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 108 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 467 characters in the data.\n",
      "The lexical diversity is 0.370 in the data.\n",
      "The 5 most common tokens are:\n",
      "ooga: 38\n",
      "boo: 13\n",
      "find: 7\n",
      "go: 5\n",
      "heres: 4\n",
      "[108, 40, 0.37037037037037035, 467]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 49 tokens in the data.\n",
      "There are 25 unique tokens in the data.\n",
      "There are 208 characters in the data.\n",
      "The lexical diversity is 0.510 in the data.\n",
      "The 5 most common tokens are:\n",
      "come: 7\n",
      "love: 6\n",
      "day: 5\n",
      "well: 4\n",
      "wait: 2\n",
      "[49, 25, 0.5102040816326531, 208]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 94 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 467 characters in the data.\n",
      "The lexical diversity is 0.755 in the data.\n",
      "The 5 most common tokens are:\n",
      "san: 4\n",
      "francisco: 4\n",
      "day: 4\n",
      "lady: 3\n",
      "met: 3\n",
      "[94, 71, 0.7553191489361702, 467]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 128 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 662 characters in the data.\n",
      "The lexical diversity is 0.547 in the data.\n",
      "The 5 most common tokens are:\n",
      "outrageous: 16\n",
      "im: 12\n",
      "rage: 7\n",
      "gonna: 6\n",
      "say: 3\n",
      "[128, 70, 0.546875, 662]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 115 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 598 characters in the data.\n",
      "The lexical diversity is 0.565 in the data.\n",
      "The 5 most common tokens are:\n",
      "need: 8\n",
      "right: 8\n",
      "paradise: 5\n",
      "loving: 5\n",
      "dont: 4\n",
      "[115, 65, 0.5652173913043478, 598]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 241 tokens in the data.\n",
      "There are 87 unique tokens in the data.\n",
      "There are 1244 characters in the data.\n",
      "The lexical diversity is 0.361 in the data.\n",
      "The 5 most common tokens are:\n",
      "perfection: 18\n",
      "love: 15\n",
      "ive: 13\n",
      "driven: 11\n",
      "know: 9\n",
      "[241, 87, 0.36099585062240663, 1244]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 84 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 376 characters in the data.\n",
      "The lexical diversity is 0.393 in the data.\n",
      "The 5 most common tokens are:\n",
      "pied: 9\n",
      "piper: 9\n",
      "im: 8\n",
      "follow: 6\n",
      "babe: 5\n",
      "[84, 33, 0.39285714285714285, 376]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 144 tokens in the data.\n",
      "There are 78 unique tokens in the data.\n",
      "There are 637 characters in the data.\n",
      "The lexical diversity is 0.542 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 11\n",
      "pirate: 8\n",
      "know: 8\n",
      "much: 5\n",
      "sea: 5\n",
      "[144, 78, 0.5416666666666666, 637]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 46 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 200 characters in the data.\n",
      "The lexical diversity is 0.783 in the data.\n",
      "The 5 most common tokens are:\n",
      "far: 2\n",
      "time: 2\n",
      "see: 2\n",
      "drift: 2\n",
      "machine: 2\n",
      "[46, 36, 0.782608695652174, 200]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 150 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 662 characters in the data.\n",
      "The lexical diversity is 0.333 in the data.\n",
      "The 5 most common tokens are:\n",
      "oh: 22\n",
      "pride: 12\n",
      "night: 8\n",
      "wont: 8\n",
      "stop: 8\n",
      "[150, 50, 0.3333333333333333, 662]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 154 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 761 characters in the data.\n",
      "The lexical diversity is 0.338 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 18\n",
      "prisoner: 12\n",
      "love: 10\n",
      "hey: 8\n",
      "got: 4\n",
      "[154, 52, 0.33766233766233766, 761]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 484 characters in the data.\n",
      "The lexical diversity is 0.723 in the data.\n",
      "The 5 most common tokens are:\n",
      "rain: 15\n",
      "ooh: 3\n",
      "see: 3\n",
      "youre: 3\n",
      "chorus: 3\n",
      "[101, 73, 0.7227722772277227, 484]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 547 characters in the data.\n",
      "The lexical diversity is 0.281 in the data.\n",
      "The 5 most common tokens are:\n",
      "time: 20\n",
      "love: 18\n",
      "real: 9\n",
      "still: 8\n",
      "believe: 8\n",
      "[121, 34, 0.2809917355371901, 547]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 378 characters in the data.\n",
      "The lexical diversity is 0.479 in the data.\n",
      "The 5 most common tokens are:\n",
      "believe: 6\n",
      "find: 6\n",
      "reason: 4\n",
      "id: 3\n",
      "way: 3\n",
      "[73, 35, 0.4794520547945205, 378]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 144 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 626 characters in the data.\n",
      "The lexical diversity is 0.424 in the data.\n",
      "The 5 most common tokens are:\n",
      "red: 27\n",
      "see: 9\n",
      "like: 5\n",
      "around: 4\n",
      "heart: 4\n",
      "[144, 61, 0.4236111111111111, 626]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 25 unique tokens in the data.\n",
      "There are 435 characters in the data.\n",
      "The lexical diversity is 0.245 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 13\n",
      "rescue: 10\n",
      "come: 10\n",
      "im: 9\n",
      "lonely: 7\n",
      "[102, 25, 0.24509803921568626, 435]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 154 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 693 characters in the data.\n",
      "The lexical diversity is 0.519 in the data.\n",
      "The 5 most common tokens are:\n",
      "feel: 8\n",
      "fine: 8\n",
      "hes: 7\n",
      "beat: 6\n",
      "rock: 5\n",
      "[154, 80, 0.5194805194805194, 693]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 131 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 659 characters in the data.\n",
      "The lexical diversity is 0.351 in the data.\n",
      "The 5 most common tokens are:\n",
      "rudy: 19\n",
      "youre: 16\n",
      "still: 8\n",
      "always: 8\n",
      "mind: 8\n",
      "[131, 46, 0.3511450381679389, 659]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 135 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 713 characters in the data.\n",
      "The lexical diversity is 0.311 in the data.\n",
      "The 5 most common tokens are:\n",
      "runaway: 23\n",
      "cant: 12\n",
      "love: 11\n",
      "find: 10\n",
      "gotta: 9\n",
      "[135, 42, 0.3111111111111111, 713]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 153 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 699 characters in the data.\n",
      "The lexical diversity is 0.536 in the data.\n",
      "The 5 most common tokens are:\n",
      "runnin: 25\n",
      "sail: 9\n",
      "keep: 5\n",
      "like: 5\n",
      "cant: 4\n",
      "[153, 82, 0.5359477124183006, 699]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 76 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 424 characters in the data.\n",
      "The lexical diversity is 0.842 in the data.\n",
      "The 5 most common tokens are:\n",
      "eyes: 4\n",
      "dont: 3\n",
      "youre: 3\n",
      "im: 2\n",
      "long: 2\n",
      "[76, 64, 0.8421052631578947, 424]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 197 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 877 characters in the data.\n",
      "The lexical diversity is 0.320 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 17\n",
      "tears: 13\n",
      "know: 13\n",
      "cryin: 13\n",
      "youll: 12\n",
      "[197, 63, 0.3197969543147208, 877]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 497 characters in the data.\n",
      "The lexical diversity is 0.604 in the data.\n",
      "The 5 most common tokens are:\n",
      "blade: 7\n",
      "think: 6\n",
      "see: 6\n",
      "big: 6\n",
      "im: 4\n",
      "[101, 61, 0.6039603960396039, 497]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 117 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 539 characters in the data.\n",
      "The lexical diversity is 0.427 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 11\n",
      "want: 8\n",
      "dont: 7\n",
      "say: 6\n",
      "whats: 6\n",
      "[117, 50, 0.42735042735042733, 539]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 138 tokens in the data.\n",
      "There are 99 unique tokens in the data.\n",
      "There are 740 characters in the data.\n",
      "The lexical diversity is 0.717 in the data.\n",
      "The 5 most common tokens are:\n",
      "send: 5\n",
      "today: 4\n",
      "man: 3\n",
      "call: 3\n",
      "say: 3\n",
      "[138, 99, 0.717391304347826, 740]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 67 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 350 characters in the data.\n",
      "The lexical diversity is 0.687 in the data.\n",
      "The 5 most common tokens are:\n",
      "yeah: 5\n",
      "princess: 4\n",
      "prince: 4\n",
      "shadow: 3\n",
      "meant: 3\n",
      "[67, 46, 0.6865671641791045, 350]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 142 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 655 characters in the data.\n",
      "The lexical diversity is 0.387 in the data.\n",
      "The 5 most common tokens are:\n",
      "things: 19\n",
      "come: 17\n",
      "shape: 16\n",
      "two: 8\n",
      "one: 5\n",
      "[142, 55, 0.3873239436619718, 655]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 154 tokens in the data.\n",
      "There are 91 unique tokens in the data.\n",
      "There are 745 characters in the data.\n",
      "The lexical diversity is 0.591 in the data.\n",
      "The 5 most common tokens are:\n",
      "loves: 8\n",
      "shes: 8\n",
      "hear: 7\n",
      "music: 6\n",
      "got: 6\n",
      "[154, 91, 0.5909090909090909, 745]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 226 tokens in the data.\n",
      "There are 128 unique tokens in the data.\n",
      "There are 1117 characters in the data.\n",
      "The lexical diversity is 0.566 in the data.\n",
      "The 5 most common tokens are:\n",
      "shoppin: 26\n",
      "im: 14\n",
      "gonna: 8\n",
      "buy: 4\n",
      "blues: 4\n",
      "[226, 128, 0.5663716814159292, 1117]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 109 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 525 characters in the data.\n",
      "The lexical diversity is 0.771 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 4\n",
      "back: 4\n",
      "silver: 3\n",
      "wings: 3\n",
      "golden: 3\n",
      "[109, 84, 0.7706422018348624, 525]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 88 tokens in the data.\n",
      "There are 39 unique tokens in the data.\n",
      "There are 439 characters in the data.\n",
      "The lexical diversity is 0.443 in the data.\n",
      "The 5 most common tokens are:\n",
      "sing: 9\n",
      "youll: 8\n",
      "supper: 4\n",
      "get: 4\n",
      "swallow: 4\n",
      "[88, 39, 0.4431818181818182, 439]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 481 characters in the data.\n",
      "The lexical diversity is 0.446 in the data.\n",
      "The 5 most common tokens are:\n",
      "sirens: 7\n",
      "sound: 6\n",
      "sky: 3\n",
      "leave: 3\n",
      "behind: 3\n",
      "[101, 45, 0.44554455445544555, 481]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 184 tokens in the data.\n",
      "There are 116 unique tokens in the data.\n",
      "There are 971 characters in the data.\n",
      "The lexical diversity is 0.630 in the data.\n",
      "The 5 most common tokens are:\n",
      "mercy: 17\n",
      "sisters: 9\n",
      "grace: 6\n",
      "place: 6\n",
      "shows: 5\n",
      "[184, 116, 0.6304347826086957, 971]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 97 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 456 characters in the data.\n",
      "The lexical diversity is 0.495 in the data.\n",
      "The 5 most common tokens are:\n",
      "sittin: 9\n",
      "dock: 8\n",
      "bay: 8\n",
      "roll: 5\n",
      "watchin: 4\n",
      "[97, 48, 0.4948453608247423, 456]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 149 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 655 characters in the data.\n",
      "The lexical diversity is 0.356 in the data.\n",
      "The 5 most common tokens are:\n",
      "skin: 16\n",
      "deep: 16\n",
      "bone: 13\n",
      "im: 9\n",
      "go: 8\n",
      "[149, 53, 0.35570469798657717, 655]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 74 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 378 characters in the data.\n",
      "The lexical diversity is 0.581 in the data.\n",
      "The 5 most common tokens are:\n",
      "children: 6\n",
      "still: 5\n",
      "time: 4\n",
      "close: 3\n",
      "theres: 3\n",
      "[74, 43, 0.581081081081081, 378]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 84 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 425 characters in the data.\n",
      "The lexical diversity is 0.655 in the data.\n",
      "The 5 most common tokens are:\n",
      "song: 7\n",
      "singing: 6\n",
      "life: 4\n",
      "ive: 3\n",
      "alone: 3\n",
      "[84, 55, 0.6547619047619048, 425]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 507 characters in the data.\n",
      "The lexical diversity is 0.400 in the data.\n",
      "The 5 most common tokens are:\n",
      "youre: 11\n",
      "gone: 8\n",
      "try: 8\n",
      "love: 5\n",
      "though: 5\n",
      "[110, 44, 0.4, 507]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 147 tokens in the data.\n",
      "There are 91 unique tokens in the data.\n",
      "There are 737 characters in the data.\n",
      "The lexical diversity is 0.619 in the data.\n",
      "The 5 most common tokens are:\n",
      "spring: 10\n",
      "long: 10\n",
      "time: 7\n",
      "said: 4\n",
      "ah: 4\n",
      "[147, 91, 0.6190476190476191, 737]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 160 tokens in the data.\n",
      "There are 106 unique tokens in the data.\n",
      "There are 774 characters in the data.\n",
      "The lexical diversity is 0.662 in the data.\n",
      "The 5 most common tokens are:\n",
      "come: 9\n",
      "never: 6\n",
      "singing: 5\n",
      "go: 4\n",
      "make: 4\n",
      "[160, 106, 0.6625, 774]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 129 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 648 characters in the data.\n",
      "The lexical diversity is 0.589 in the data.\n",
      "The 5 most common tokens are:\n",
      "startin: 12\n",
      "back: 6\n",
      "let: 4\n",
      "time: 4\n",
      "around: 4\n",
      "[129, 76, 0.5891472868217055, 648]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 122 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 611 characters in the data.\n",
      "The lexical diversity is 0.467 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 15\n",
      "still: 12\n",
      "baby: 6\n",
      "oh: 5\n",
      "cried: 4\n",
      "[122, 57, 0.4672131147540984, 611]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 99 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 447 characters in the data.\n",
      "The lexical diversity is 0.465 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 11\n",
      "still: 9\n",
      "love: 9\n",
      "lying: 6\n",
      "ive: 5\n",
      "[99, 46, 0.46464646464646464, 447]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 175 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 822 characters in the data.\n",
      "The lexical diversity is 0.354 in the data.\n",
      "The 5 most common tokens are:\n",
      "enough: 20\n",
      "strong: 16\n",
      "im: 13\n",
      "say: 7\n",
      "know: 7\n",
      "[175, 62, 0.35428571428571426, 822]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 80 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 364 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "The 5 most common tokens are:\n",
      "sunny: 14\n",
      "love: 8\n",
      "thank: 6\n",
      "true: 4\n",
      "gave: 4\n",
      "[80, 40, 0.5, 364]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 388 characters in the data.\n",
      "The lexical diversity is 0.495 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 11\n",
      "ah: 7\n",
      "oh: 6\n",
      "love: 5\n",
      "ooh: 5\n",
      "[93, 46, 0.4946236559139785, 388]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 211 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 998 characters in the data.\n",
      "The lexical diversity is 0.336 in the data.\n",
      "The 5 most common tokens are:\n",
      "take: 31\n",
      "boys: 31\n",
      "well: 10\n",
      "might: 9\n",
      "wise: 9\n",
      "[211, 71, 0.33649289099526064, 998]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 196 tokens in the data.\n",
      "There are 77 unique tokens in the data.\n",
      "There are 883 characters in the data.\n",
      "The lexical diversity is 0.393 in the data.\n",
      "The 5 most common tokens are:\n",
      "gotta: 11\n",
      "heart: 10\n",
      "take: 9\n",
      "like: 9\n",
      "man: 9\n",
      "[196, 77, 0.39285714285714285, 883]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 55 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 256 characters in the data.\n",
      "The lexical diversity is 0.727 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 5\n",
      "little: 3\n",
      "dont: 3\n",
      "forever: 3\n",
      "take: 2\n",
      "[55, 40, 0.7272727272727273, 256]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 222 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 987 characters in the data.\n",
      "The lexical diversity is 0.248 in the data.\n",
      "The 5 most common tokens are:\n",
      "home: 39\n",
      "take: 37\n",
      "heaven: 11\n",
      "wanna: 7\n",
      "baby: 7\n",
      "[222, 55, 0.24774774774774774, 987]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 237 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 1128 characters in the data.\n",
      "The lexical diversity is 0.291 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 27\n",
      "baby: 25\n",
      "heart: 23\n",
      "takin: 17\n",
      "im: 15\n",
      "[237, 69, 0.2911392405063291, 1128]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 179 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 802 characters in the data.\n",
      "The lexical diversity is 0.324 in the data.\n",
      "The 5 most common tokens are:\n",
      "taxi: 32\n",
      "ride: 18\n",
      "im: 17\n",
      "gonna: 17\n",
      "night: 13\n",
      "[179, 58, 0.3240223463687151, 802]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 76 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 363 characters in the data.\n",
      "The lexical diversity is 0.368 in the data.\n",
      "The 5 most common tokens are:\n",
      "bells: 13\n",
      "say: 12\n",
      "rhymney: 5\n",
      "give: 4\n",
      "sad: 4\n",
      "[76, 28, 0.3684210526315789, 363]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 105 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 483 characters in the data.\n",
      "The lexical diversity is 0.571 in the data.\n",
      "The 5 most common tokens are:\n",
      "bigger: 5\n",
      "come: 5\n",
      "harder: 5\n",
      "fall: 5\n",
      "oh: 4\n",
      "[105, 60, 0.5714285714285714, 483]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 132 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 651 characters in the data.\n",
      "The lexical diversity is 0.576 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 15\n",
      "book: 13\n",
      "writing: 6\n",
      "heyho: 3\n",
      "broken: 3\n",
      "[132, 76, 0.5757575757575758, 651]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 339 characters in the data.\n",
      "The lexical diversity is 0.577 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 6\n",
      "wont: 4\n",
      "let: 4\n",
      "go: 4\n",
      "ill: 4\n",
      "[78, 45, 0.5769230769230769, 339]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 108 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 544 characters in the data.\n",
      "The lexical diversity is 0.778 in the data.\n",
      "The 5 most common tokens are:\n",
      "heard: 3\n",
      "news: 3\n",
      "fall: 2\n",
      "knew: 2\n",
      "well: 2\n",
      "[108, 84, 0.7777777777777778, 544]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 49 unique tokens in the data.\n",
      "There are 311 characters in the data.\n",
      "The lexical diversity is 0.671 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 4\n",
      "think: 3\n",
      "see: 3\n",
      "anymore: 3\n",
      "know: 3\n",
      "[73, 49, 0.6712328767123288, 311]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 85 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 401 characters in the data.\n",
      "The lexical diversity is 0.471 in the data.\n",
      "The 5 most common tokens are:\n",
      "passes: 6\n",
      "goes: 5\n",
      "girl: 4\n",
      "ipanema: 4\n",
      "tall: 3\n",
      "[85, 40, 0.47058823529411764, 401]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 99 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 474 characters in the data.\n",
      "The lexical diversity is 0.727 in the data.\n",
      "The 5 most common tokens are:\n",
      "ever: 8\n",
      "greatest: 4\n",
      "song: 4\n",
      "heard: 4\n",
      "ive: 3\n",
      "[99, 72, 0.7272727272727273, 474]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 203 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 1031 characters in the data.\n",
      "The lexical diversity is 0.286 in the data.\n",
      "The 5 most common tokens are:\n",
      "greatest: 20\n",
      "thing: 14\n",
      "youre: 12\n",
      "see: 8\n",
      "ill: 8\n",
      "[203, 58, 0.2857142857142857, 1031]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 90 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 428 characters in the data.\n",
      "The lexical diversity is 0.533 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 11\n",
      "gunman: 10\n",
      "mercy: 5\n",
      "time: 3\n",
      "sights: 3\n",
      "[90, 48, 0.5333333333333333, 428]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 398 characters in the data.\n",
      "The lexical diversity is 0.460 in the data.\n",
      "The 5 most common tokens are:\n",
      "long: 9\n",
      "road: 6\n",
      "winding: 5\n",
      "door: 4\n",
      "standing: 4\n",
      "[87, 40, 0.45977011494252873, 398]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 105 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 458 characters in the data.\n",
      "The lexical diversity is 0.486 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 7\n",
      "hes: 6\n",
      "man: 5\n",
      "love: 4\n",
      "ill: 4\n",
      "[105, 51, 0.4857142857142857, 458]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 88 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 429 characters in the data.\n",
      "The lexical diversity is 0.841 in the data.\n",
      "The 5 most common tokens are:\n",
      "man: 5\n",
      "got: 3\n",
      "away: 3\n",
      "night: 2\n",
      "dreams: 2\n",
      "[88, 74, 0.8409090909090909, 429]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 450 characters in the data.\n",
      "The lexical diversity is 0.759 in the data.\n",
      "The 5 most common tokens are:\n",
      "good: 5\n",
      "musics: 4\n",
      "chorus: 4\n",
      "come: 4\n",
      "back: 4\n",
      "[87, 66, 0.7586206896551724, 450]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 226 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 1076 characters in the data.\n",
      "The lexical diversity is 0.319 in the data.\n",
      "The 5 most common tokens are:\n",
      "doodoo: 28\n",
      "name: 11\n",
      "game: 11\n",
      "whats: 9\n",
      "know: 7\n",
      "[226, 72, 0.3185840707964602, 1076]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 706 characters in the data.\n",
      "The lexical diversity is 0.493 in the data.\n",
      "The 5 most common tokens are:\n",
      "power: 14\n",
      "every: 6\n",
      "believe: 5\n",
      "holds: 4\n",
      "hand: 4\n",
      "[146, 72, 0.4931506849315068, 706]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 67 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 320 characters in the data.\n",
      "The lexical diversity is 0.493 in the data.\n",
      "The 5 most common tokens are:\n",
      "show: 14\n",
      "fortune: 5\n",
      "ill: 4\n",
      "young: 4\n",
      "many: 4\n",
      "[67, 33, 0.4925373134328358, 320]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 123 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 577 characters in the data.\n",
      "The lexical diversity is 0.512 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 7\n",
      "love: 6\n",
      "sometimes: 6\n",
      "mistake: 5\n",
      "give: 5\n",
      "[123, 63, 0.5121951219512195, 577]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 82 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 386 characters in the data.\n",
      "The lexical diversity is 0.659 in the data.\n",
      "The 5 most common tokens are:\n",
      "days: 9\n",
      "ive: 5\n",
      "oh: 5\n",
      "well: 4\n",
      "forgotten: 3\n",
      "[82, 54, 0.6585365853658537, 386]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 409 characters in the data.\n",
      "The lexical diversity is 0.355 in the data.\n",
      "The 5 most common tokens are:\n",
      "thats: 14\n",
      "kiss: 13\n",
      "know: 7\n",
      "oh: 6\n",
      "want: 5\n",
      "[93, 33, 0.3548387096774194, 409]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 118 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 581 characters in the data.\n",
      "The lexical diversity is 0.288 in the data.\n",
      "The 5 most common tokens are:\n",
      "aint: 11\n",
      "gonna: 11\n",
      "always: 7\n",
      "sun: 6\n",
      "shine: 6\n",
      "[118, 34, 0.288135593220339, 581]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 71 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 408 characters in the data.\n",
      "The lexical diversity is 0.775 in the data.\n",
      "The 5 most common tokens are:\n",
      "thought: 4\n",
      "loving: 4\n",
      "right: 4\n",
      "way: 2\n",
      "im: 2\n",
      "[71, 55, 0.7746478873239436, 408]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 127 tokens in the data.\n",
      "There are 98 unique tokens in the data.\n",
      "There are 675 characters in the data.\n",
      "The lexical diversity is 0.772 in the data.\n",
      "The 5 most common tokens are:\n",
      "times: 6\n",
      "achangin: 6\n",
      "come: 5\n",
      "dont: 4\n",
      "later: 4\n",
      "[127, 98, 0.7716535433070866, 675]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 72 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 330 characters in the data.\n",
      "The lexical diversity is 0.569 in the data.\n",
      "The 5 most common tokens are:\n",
      "long: 7\n",
      "never: 6\n",
      "twelfth: 5\n",
      "love: 4\n",
      "ill: 3\n",
      "[72, 41, 0.5694444444444444, 330]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 71 tokens in the data.\n",
      "There are 30 unique tokens in the data.\n",
      "There are 280 characters in the data.\n",
      "The lexical diversity is 0.423 in the data.\n",
      "The 5 most common tokens are:\n",
      "way: 9\n",
      "love: 7\n",
      "meet: 2\n",
      "boy: 2\n",
      "like: 2\n",
      "[71, 30, 0.4225352112676056, 280]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 143 tokens in the data.\n",
      "There are 98 unique tokens in the data.\n",
      "There are 751 characters in the data.\n",
      "The lexical diversity is 0.685 in the data.\n",
      "The 5 most common tokens are:\n",
      "takes: 9\n",
      "winner: 7\n",
      "small: 5\n",
      "standing: 3\n",
      "feel: 3\n",
      "[143, 98, 0.6853146853146853, 751]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 112 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 562 characters in the data.\n",
      "The lexical diversity is 0.714 in the data.\n",
      "The 5 most common tokens are:\n",
      "godforsaken: 5\n",
      "day: 5\n",
      "youve: 5\n",
      "gone: 5\n",
      "away: 5\n",
      "[112, 80, 0.7142857142857143, 562]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 116 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 581 characters in the data.\n",
      "The lexical diversity is 0.595 in the data.\n",
      "The 5 most common tokens are:\n",
      "song: 7\n",
      "lonely: 6\n",
      "hear: 4\n",
      "dont: 4\n",
      "gonna: 4\n",
      "[116, 69, 0.5948275862068966, 581]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 112 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 581 characters in the data.\n",
      "The lexical diversity is 0.571 in the data.\n",
      "The 5 most common tokens are:\n",
      "thunderstorm: 4\n",
      "good: 4\n",
      "feel: 4\n",
      "knew: 3\n",
      "coming: 3\n",
      "[112, 64, 0.5714285714285714, 581]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 78 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 357 characters in the data.\n",
      "The lexical diversity is 0.551 in the data.\n",
      "The 5 most common tokens are:\n",
      "time: 9\n",
      "people: 5\n",
      "go: 5\n",
      "oh: 4\n",
      "good: 4\n",
      "[78, 43, 0.5512820512820513, 357]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 73 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 389 characters in the data.\n",
      "The lexical diversity is 0.630 in the data.\n",
      "The 5 most common tokens are:\n",
      "throw: 6\n",
      "tonight: 5\n",
      "ill: 5\n",
      "staying: 5\n",
      "cause: 3\n",
      "[73, 46, 0.6301369863013698, 389]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 85 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 367 characters in the data.\n",
      "The lexical diversity is 0.424 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 6\n",
      "touch: 5\n",
      "go: 5\n",
      "weak: 4\n",
      "strong: 4\n",
      "[85, 36, 0.4235294117647059, 367]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 130 tokens in the data.\n",
      "There are 81 unique tokens in the data.\n",
      "There are 616 characters in the data.\n",
      "The lexical diversity is 0.623 in the data.\n",
      "The 5 most common tokens are:\n",
      "gotta: 10\n",
      "get: 10\n",
      "train: 7\n",
      "thought: 5\n",
      "time: 4\n",
      "[130, 81, 0.6230769230769231, 616]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 63 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 316 characters in the data.\n",
      "The lexical diversity is 0.857 in the data.\n",
      "The 5 most common tokens are:\n",
      "two: 2\n",
      "people: 2\n",
      "clinging: 2\n",
      "thread: 2\n",
      "wake: 2\n",
      "[63, 54, 0.8571428571428571, 316]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 69 tokens in the data.\n",
      "There are 49 unique tokens in the data.\n",
      "There are 299 characters in the data.\n",
      "The lexical diversity is 0.710 in the data.\n",
      "The 5 most common tokens are:\n",
      "time: 4\n",
      "go: 4\n",
      "youre: 3\n",
      "im: 3\n",
      "stay: 3\n",
      "[69, 49, 0.7101449275362319, 299]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 175 tokens in the data.\n",
      "There are 85 unique tokens in the data.\n",
      "There are 917 characters in the data.\n",
      "The lexical diversity is 0.486 in the data.\n",
      "The 5 most common tokens are:\n",
      "walking: 22\n",
      "memphis: 18\n",
      "feet: 10\n",
      "feel: 10\n",
      "got: 5\n",
      "[175, 85, 0.4857142857142857, 917]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 436 characters in the data.\n",
      "The lexical diversity is 0.430 in the data.\n",
      "The 5 most common tokens are:\n",
      "walk: 17\n",
      "take: 4\n",
      "hand: 4\n",
      "count: 4\n",
      "troubles: 4\n",
      "[93, 40, 0.43010752688172044, 436]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 141 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 712 characters in the data.\n",
      "The lexical diversity is 0.426 in the data.\n",
      "The 5 most common tokens are:\n",
      "see: 9\n",
      "walls: 8\n",
      "wanna: 8\n",
      "crashing: 7\n",
      "cause: 6\n",
      "[141, 60, 0.425531914893617, 712]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 176 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 941 characters in the data.\n",
      "The lexical diversity is 0.432 in the data.\n",
      "The 5 most common tokens are:\n",
      "war: 9\n",
      "paint: 9\n",
      "soft: 9\n",
      "feathers: 9\n",
      "love: 6\n",
      "[176, 76, 0.4318181818181818, 941]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 144 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 683 characters in the data.\n",
      "The lexical diversity is 0.458 in the data.\n",
      "The 5 most common tokens are:\n",
      "good: 16\n",
      "wasnt: 9\n",
      "know: 6\n",
      "party: 5\n",
      "baby: 5\n",
      "[144, 66, 0.4583333333333333, 683]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 107 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 619 characters in the data.\n",
      "The lexical diversity is 0.402 in the data.\n",
      "The 5 most common tokens are:\n",
      "waterloo: 21\n",
      "woah: 8\n",
      "ever: 4\n",
      "knowing: 4\n",
      "fate: 4\n",
      "[107, 43, 0.40186915887850466, 619]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 79 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 370 characters in the data.\n",
      "The lexical diversity is 0.532 in the data.\n",
      "The 5 most common tokens are:\n",
      "fly: 7\n",
      "home: 7\n",
      "well: 4\n",
      "sooner: 4\n",
      "later: 4\n",
      "[79, 42, 0.5316455696202531, 370]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 93 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 471 characters in the data.\n",
      "The lexical diversity is 0.613 in the data.\n",
      "The 5 most common tokens are:\n",
      "alone: 9\n",
      "sleep: 8\n",
      "youre: 3\n",
      "sooner: 3\n",
      "later: 3\n",
      "[93, 57, 0.6129032258064516, 471]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 91 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 497 characters in the data.\n",
      "The lexical diversity is 0.637 in the data.\n",
      "The 5 most common tokens are:\n",
      "little: 8\n",
      "welcome: 6\n",
      "burlesque: 6\n",
      "show: 4\n",
      "less: 2\n",
      "[91, 58, 0.6373626373626373, 497]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 117 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 497 characters in the data.\n",
      "The lexical diversity is 0.462 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 16\n",
      "make: 16\n",
      "know: 9\n",
      "got: 6\n",
      "may: 5\n",
      "[117, 54, 0.46153846153846156, 497]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 106 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 577 characters in the data.\n",
      "The lexical diversity is 0.585 in the data.\n",
      "The 5 most common tokens are:\n",
      "moonlight: 6\n",
      "way: 6\n",
      "loves: 5\n",
      "dreams: 5\n",
      "change: 5\n",
      "[106, 62, 0.5849056603773585, 577]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 25 tokens in the data.\n",
      "There are 15 unique tokens in the data.\n",
      "There are 133 characters in the data.\n",
      "The lexical diversity is 0.600 in the data.\n",
      "The 5 most common tokens are:\n",
      "whatll: 8\n",
      "far: 2\n",
      "away: 2\n",
      "blue: 2\n",
      "im: 1\n",
      "[25, 15, 0.6, 133]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 139 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 674 characters in the data.\n",
      "The lexical diversity is 0.489 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 11\n",
      "calls: 11\n",
      "name: 11\n",
      "theres: 4\n",
      "way: 4\n",
      "[139, 68, 0.4892086330935252, 674]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 160 tokens in the data.\n",
      "There are 75 unique tokens in the data.\n",
      "There are 847 characters in the data.\n",
      "The lexical diversity is 0.469 in the data.\n",
      "The 5 most common tokens are:\n",
      "shame: 13\n",
      "lovers: 9\n",
      "become: 9\n",
      "strangers: 9\n",
      "dont: 7\n",
      "[160, 75, 0.46875, 847]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 119 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 557 characters in the data.\n",
      "The lexical diversity is 0.513 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 12\n",
      "gone: 10\n",
      "gotta: 7\n",
      "theres: 5\n",
      "strong: 4\n",
      "[119, 61, 0.5126050420168067, 557]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 109 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 493 characters in the data.\n",
      "The lexical diversity is 0.697 in the data.\n",
      "The 5 most common tokens are:\n",
      "moneys: 9\n",
      "gone: 9\n",
      "still: 4\n",
      "oh: 4\n",
      "want: 3\n",
      "[109, 76, 0.6972477064220184, 493]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 82 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 358 characters in the data.\n",
      "The lexical diversity is 0.573 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 8\n",
      "find: 7\n",
      "youre: 7\n",
      "goin: 6\n",
      "let: 6\n",
      "[82, 47, 0.573170731707317, 358]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 173 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 785 characters in the data.\n",
      "The lexical diversity is 0.324 in the data.\n",
      "The 5 most common tokens are:\n",
      "walk: 25\n",
      "away: 19\n",
      "wont: 11\n",
      "crying: 6\n",
      "cause: 5\n",
      "[173, 56, 0.3236994219653179, 785]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 58 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 237 characters in the data.\n",
      "The lexical diversity is 0.724 in the data.\n",
      "The 5 most common tokens are:\n",
      "go: 5\n",
      "dont: 4\n",
      "know: 4\n",
      "right: 3\n",
      "youre: 2\n",
      "[58, 42, 0.7241379310344828, 237]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 81 unique tokens in the data.\n",
      "There are 722 characters in the data.\n",
      "The lexical diversity is 0.555 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 13\n",
      "believe: 10\n",
      "oh: 5\n",
      "love: 4\n",
      "hope: 4\n",
      "[146, 81, 0.5547945205479452, 722]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 45 tokens in the data.\n",
      "There are 24 unique tokens in the data.\n",
      "There are 188 characters in the data.\n",
      "The lexical diversity is 0.533 in the data.\n",
      "The 5 most common tokens are:\n",
      "born: 4\n",
      "tell: 3\n",
      "im: 3\n",
      "hope: 2\n",
      "try: 2\n",
      "[45, 24, 0.5333333333333333, 188]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 60 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 318 characters in the data.\n",
      "The lexical diversity is 0.583 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 11\n",
      "tomorrow: 7\n",
      "still: 5\n",
      "tonight: 3\n",
      "tell: 2\n",
      "[60, 35, 0.5833333333333334, 318]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 130 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 618 characters in the data.\n",
      "The lexical diversity is 0.508 in the data.\n",
      "The 5 most common tokens are:\n",
      "wait: 12\n",
      "know: 6\n",
      "feels: 6\n",
      "love: 5\n",
      "youre: 4\n",
      "[130, 66, 0.5076923076923077, 618]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 99 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 499 characters in the data.\n",
      "The lexical diversity is 0.687 in the data.\n",
      "The 5 most common tokens are:\n",
      "heart: 5\n",
      "without: 4\n",
      "cause: 4\n",
      "alone: 3\n",
      "broken: 3\n",
      "[99, 68, 0.6868686868686869, 499]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 218 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 1108 characters in the data.\n",
      "The lexical diversity is 0.271 in the data.\n",
      "The 5 most common tokens are:\n",
      "world: 35\n",
      "womans: 33\n",
      "tell: 12\n",
      "truth: 12\n",
      "im: 10\n",
      "[218, 59, 0.2706422018348624, 1108]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 110 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 558 characters in the data.\n",
      "The lexical diversity is 0.618 in the data.\n",
      "The 5 most common tokens are:\n",
      "girl: 11\n",
      "working: 9\n",
      "shes: 6\n",
      "livin: 3\n",
      "mans: 3\n",
      "[110, 68, 0.6181818181818182, 558]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 138 tokens in the data.\n",
      "There are 79 unique tokens in the data.\n",
      "There are 605 characters in the data.\n",
      "The lexical diversity is 0.572 in the data.\n",
      "The 5 most common tokens are:\n",
      "kids: 13\n",
      "say: 5\n",
      "mother: 5\n",
      "ill: 4\n",
      "im: 4\n",
      "[138, 79, 0.572463768115942, 605]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 39 unique tokens in the data.\n",
      "There are 425 characters in the data.\n",
      "The lexical diversity is 0.448 in the data.\n",
      "The 5 most common tokens are:\n",
      "believe: 9\n",
      "dont: 8\n",
      "love: 7\n",
      "say: 4\n",
      "stay: 4\n",
      "[87, 39, 0.4482758620689655, 425]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 596 characters in the data.\n",
      "The lexical diversity is 0.448 in the data.\n",
      "The 5 most common tokens are:\n",
      "havent: 8\n",
      "seen: 8\n",
      "last: 8\n",
      "im: 7\n",
      "ive: 6\n",
      "[134, 60, 0.44776119402985076, 596]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 59 tokens in the data.\n",
      "There are 38 unique tokens in the data.\n",
      "There are 272 characters in the data.\n",
      "The lexical diversity is 0.644 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 9\n",
      "baby: 4\n",
      "well: 3\n",
      "love: 3\n",
      "youre: 2\n",
      "[59, 38, 0.6440677966101694, 272]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 96 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 479 characters in the data.\n",
      "The lexical diversity is 0.562 in the data.\n",
      "The 5 most common tokens are:\n",
      "young: 6\n",
      "pretty: 6\n",
      "say: 5\n",
      "make: 5\n",
      "youre: 5\n",
      "[96, 54, 0.5625, 479]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 87 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 445 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "The 5 most common tokens are:\n",
      "tomorrow: 10\n",
      "let: 8\n",
      "tonight: 3\n",
      "one: 3\n",
      "night: 3\n",
      "[87, 58, 0.6666666666666666, 445]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 74 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 332 characters in the data.\n",
      "The lexical diversity is 0.473 in the data.\n",
      "The 5 most common tokens are:\n",
      "every: 6\n",
      "ever: 6\n",
      "take: 5\n",
      "sometimes: 4\n",
      "ooh: 4\n",
      "[74, 35, 0.47297297297297297, 332]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 83 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 358 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "The 5 most common tokens are:\n",
      "made: 6\n",
      "happy: 6\n",
      "im: 6\n",
      "came: 6\n",
      "life: 5\n",
      "[83, 46, 0.5542168674698795, 358]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 132 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 569 characters in the data.\n",
      "The lexical diversity is 0.265 in the data.\n",
      "The 5 most common tokens are:\n",
      "hold: 25\n",
      "really: 17\n",
      "got: 17\n",
      "youve: 9\n",
      "want: 8\n",
      "[132, 35, 0.26515151515151514, 569]\n",
      "\n",
      "Descriptive statistics for cher lyrics:\n",
      "There are 172 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 858 characters in the data.\n",
      "The lexical diversity is 0.302 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 29\n",
      "wouldnt: 27\n",
      "love: 23\n",
      "knocked: 5\n",
      "door: 5\n",
      "[172, 52, 0.3023255813953488, 858]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 205 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 887 characters in the data.\n",
      "The lexical diversity is 0.390 in the data.\n",
      "The 5 most common tokens are:\n",
      "got: 24\n",
      "work: 16\n",
      "88: 14\n",
      "days: 14\n",
      "ive: 11\n",
      "[205, 80, 0.3902439024390244, 887]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 66 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 305 characters in the data.\n",
      "The lexical diversity is 0.606 in the data.\n",
      "The 5 most common tokens are:\n",
      "really: 6\n",
      "thing: 5\n",
      "want: 4\n",
      "baby: 4\n",
      "aint: 3\n",
      "[66, 40, 0.6060606060606061, 305]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 119 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 578 characters in the data.\n",
      "The lexical diversity is 0.471 in the data.\n",
      "The 5 most common tokens are:\n",
      "pressure: 13\n",
      "tell: 10\n",
      "like: 9\n",
      "boy: 8\n",
      "anytime: 5\n",
      "[119, 56, 0.47058823529411764, 578]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 77 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 343 characters in the data.\n",
      "The lexical diversity is 0.442 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 19\n",
      "forgive: 13\n",
      "wont: 3\n",
      "give: 3\n",
      "chance: 3\n",
      "[77, 34, 0.44155844155844154, 343]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 174 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 713 characters in the data.\n",
      "The lexical diversity is 0.190 in the data.\n",
      "The 5 most common tokens are:\n",
      "party: 19\n",
      "go: 15\n",
      "beach: 14\n",
      "ok: 14\n",
      "lets: 10\n",
      "[174, 33, 0.1896551724137931, 713]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 129 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 639 characters in the data.\n",
      "The lexical diversity is 0.457 in the data.\n",
      "The 5 most common tokens are:\n",
      "music: 7\n",
      "anyway: 7\n",
      "yeah: 6\n",
      "im: 6\n",
      "right: 6\n",
      "[129, 59, 0.4573643410852713, 639]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 175 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 857 characters in the data.\n",
      "The lexical diversity is 0.474 in the data.\n",
      "The 5 most common tokens are:\n",
      "never: 29\n",
      "mine: 14\n",
      "theres: 5\n",
      "every: 5\n",
      "cause: 5\n",
      "[175, 83, 0.4742857142857143, 857]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 166 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 785 characters in the data.\n",
      "The lexical diversity is 0.307 in the data.\n",
      "The 5 most common tokens are:\n",
      "lines: 20\n",
      "reading: 19\n",
      "like: 15\n",
      "baby: 13\n",
      "im: 8\n",
      "[166, 51, 0.3072289156626506, 785]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 181 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 856 characters in the data.\n",
      "The lexical diversity is 0.420 in the data.\n",
      "The 5 most common tokens are:\n",
      "wont: 8\n",
      "dont: 7\n",
      "really: 7\n",
      "city: 6\n",
      "make: 6\n",
      "[181, 76, 0.4198895027624309, 856]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 10 tokens in the data.\n",
      "There are 10 unique tokens in the data.\n",
      "There are 67 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "The 5 most common tokens are:\n",
      "bionic: 1\n",
      "woman: 1\n",
      "good: 1\n",
      "evening: 1\n",
      "ladies: 1\n",
      "[10, 10, 1.0, 67]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 91 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 436 characters in the data.\n",
      "The lexical diversity is 0.582 in the data.\n",
      "The 5 most common tokens are:\n",
      "youre: 10\n",
      "blow: 7\n",
      "mind: 7\n",
      "baby: 4\n",
      "ill: 4\n",
      "[91, 53, 0.5824175824175825, 436]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 64 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 342 characters in the data.\n",
      "The lexical diversity is 0.703 in the data.\n",
      "The 5 most common tokens are:\n",
      "break: 3\n",
      "suckers: 3\n",
      "nobody: 2\n",
      "knows: 2\n",
      "whats: 2\n",
      "[64, 45, 0.703125, 342]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 277 tokens in the data.\n",
      "There are 132 unique tokens in the data.\n",
      "There are 1384 characters in the data.\n",
      "The lexical diversity is 0.477 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 13\n",
      "looking: 11\n",
      "moneyman: 11\n",
      "win: 10\n",
      "good: 8\n",
      "[277, 132, 0.47653429602888087, 1384]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 169 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 823 characters in the data.\n",
      "The lexical diversity is 0.373 in the data.\n",
      "The 5 most common tokens are:\n",
      "like: 12\n",
      "wasting: 12\n",
      "time: 12\n",
      "bum: 11\n",
      "new: 11\n",
      "[169, 63, 0.3727810650887574, 823]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 138 tokens in the data.\n",
      "There are 97 unique tokens in the data.\n",
      "There are 690 characters in the data.\n",
      "The lexical diversity is 0.703 in the data.\n",
      "The 5 most common tokens are:\n",
      "bumpy: 4\n",
      "ride: 4\n",
      "whos: 4\n",
      "hold: 4\n",
      "youve: 4\n",
      "[138, 97, 0.7028985507246377, 690]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 130 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 640 characters in the data.\n",
      "The lexical diversity is 0.362 in the data.\n",
      "The 5 most common tokens are:\n",
      "call: 7\n",
      "girlfriend: 7\n",
      "give: 6\n",
      "tell: 6\n",
      "time: 5\n",
      "[130, 47, 0.36153846153846153, 640]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 351 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 1542 characters in the data.\n",
      "The lexical diversity is 0.177 in the data.\n",
      "The 5 most common tokens are:\n",
      "deng: 32\n",
      "digi: 32\n",
      "bomb: 16\n",
      "di: 16\n",
      "gi: 16\n",
      "[351, 62, 0.17663817663817663, 1542]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 152 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 729 characters in the data.\n",
      "The lexical diversity is 0.553 in the data.\n",
      "The 5 most common tokens are:\n",
      "girl: 10\n",
      "crash: 7\n",
      "burn: 7\n",
      "dont: 6\n",
      "mind: 5\n",
      "[152, 84, 0.5526315789473685, 729]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 283 tokens in the data.\n",
      "There are 89 unique tokens in the data.\n",
      "There are 1638 characters in the data.\n",
      "The lexical diversity is 0.314 in the data.\n",
      "The 5 most common tokens are:\n",
      "criminal: 17\n",
      "intent: 17\n",
      "somebody: 16\n",
      "alert: 16\n",
      "authorities: 16\n",
      "[283, 89, 0.31448763250883394, 1638]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 158 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 735 characters in the data.\n",
      "The lexical diversity is 0.468 in the data.\n",
      "The 5 most common tokens are:\n",
      "get: 11\n",
      "cry: 7\n",
      "older: 7\n",
      "never: 7\n",
      "told: 7\n",
      "[158, 74, 0.46835443037974683, 735]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 170 tokens in the data.\n",
      "There are 162 unique tokens in the data.\n",
      "There are 1042 characters in the data.\n",
      "The lexical diversity is 0.953 in the data.\n",
      "The 5 most common tokens are:\n",
      "konichiwa: 2\n",
      "records: 2\n",
      "get: 2\n",
      "listen: 2\n",
      "turn: 2\n",
      "[170, 162, 0.9529411764705882, 1042]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 187 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 879 characters in the data.\n",
      "The lexical diversity is 0.332 in the data.\n",
      "The 5 most common tokens are:\n",
      "wow: 16\n",
      "like: 12\n",
      "queen: 9\n",
      "dancehall: 8\n",
      "thing: 8\n",
      "[187, 62, 0.3315508021390374, 879]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 187 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 879 characters in the data.\n",
      "The lexical diversity is 0.332 in the data.\n",
      "The 5 most common tokens are:\n",
      "wow: 16\n",
      "like: 12\n",
      "queen: 9\n",
      "dancehall: 8\n",
      "thing: 8\n",
      "[187, 62, 0.3315508021390374, 879]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 603 characters in the data.\n",
      "The lexical diversity is 0.416 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 19\n",
      "oh: 11\n",
      "dancing: 10\n",
      "keep: 9\n",
      "youre: 5\n",
      "[137, 57, 0.41605839416058393, 603]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 614 characters in the data.\n",
      "The lexical diversity is 0.423 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 19\n",
      "dancing: 10\n",
      "keep: 9\n",
      "ohh: 7\n",
      "youre: 5\n",
      "[137, 58, 0.4233576642335766, 614]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 81 tokens in the data.\n",
      "There are 29 unique tokens in the data.\n",
      "There are 375 characters in the data.\n",
      "The lexical diversity is 0.358 in the data.\n",
      "The 5 most common tokens are:\n",
      "lets: 9\n",
      "dont: 6\n",
      "know: 5\n",
      "wait: 4\n",
      "hurts: 4\n",
      "[81, 29, 0.35802469135802467, 375]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 177 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 1078 characters in the data.\n",
      "The lexical diversity is 0.226 in the data.\n",
      "The 5 most common tokens are:\n",
      "killing: 68\n",
      "drinking: 16\n",
      "dont: 10\n",
      "fucking: 10\n",
      "tell: 10\n",
      "[177, 40, 0.22598870056497175, 1078]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 177 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 1078 characters in the data.\n",
      "The lexical diversity is 0.226 in the data.\n",
      "The 5 most common tokens are:\n",
      "killing: 68\n",
      "drinking: 16\n",
      "dont: 10\n",
      "fucking: 10\n",
      "tell: 10\n",
      "[177, 40, 0.22598870056497175, 1078]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 151 tokens in the data.\n",
      "There are 87 unique tokens in the data.\n",
      "There are 731 characters in the data.\n",
      "The lexical diversity is 0.576 in the data.\n",
      "The 5 most common tokens are:\n",
      "come: 10\n",
      "stop: 9\n",
      "music: 8\n",
      "baby: 8\n",
      "dont: 6\n",
      "[151, 87, 0.5761589403973509, 731]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 67 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 297 characters in the data.\n",
      "The lexical diversity is 0.522 in the data.\n",
      "The 5 most common tokens are:\n",
      "dont: 7\n",
      "wanna: 7\n",
      "back: 5\n",
      "want: 3\n",
      "even: 3\n",
      "[67, 35, 0.5223880597014925, 297]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 95 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 447 characters in the data.\n",
      "The lexical diversity is 0.600 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 9\n",
      "takes: 6\n",
      "around: 4\n",
      "got: 4\n",
      "love: 4\n",
      "[95, 57, 0.6, 447]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 111 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 520 characters in the data.\n",
      "The lexical diversity is 0.631 in the data.\n",
      "The 5 most common tokens are:\n",
      "really: 4\n",
      "want: 4\n",
      "right: 4\n",
      "show: 3\n",
      "respect: 3\n",
      "[111, 70, 0.6306306306306306, 520]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 103 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 550 characters in the data.\n",
      "The lexical diversity is 0.621 in the data.\n",
      "The 5 most common tokens are:\n",
      "right: 9\n",
      "youre: 4\n",
      "words: 4\n",
      "unspoken: 4\n",
      "falls: 4\n",
      "[103, 64, 0.6213592233009708, 550]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 153 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 818 characters in the data.\n",
      "The lexical diversity is 0.412 in the data.\n",
      "The 5 most common tokens are:\n",
      "electric: 28\n",
      "cant: 6\n",
      "deny: 6\n",
      "natural: 5\n",
      "high: 5\n",
      "[153, 63, 0.4117647058823529, 818]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 199 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 993 characters in the data.\n",
      "The lexical diversity is 0.302 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 23\n",
      "never: 21\n",
      "ever: 18\n",
      "brokenhearted: 11\n",
      "come: 8\n",
      "[199, 60, 0.3015075376884422, 993]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 96 tokens in the data.\n",
      "There are 29 unique tokens in the data.\n",
      "There are 459 characters in the data.\n",
      "The lexical diversity is 0.302 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 12\n",
      "waiting: 10\n",
      "every: 9\n",
      "little: 9\n",
      "thing: 9\n",
      "[96, 29, 0.3020833333333333, 459]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 246 tokens in the data.\n",
      "There are 113 unique tokens in the data.\n",
      "There are 1352 characters in the data.\n",
      "The lexical diversity is 0.459 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 8\n",
      "got: 7\n",
      "gone: 7\n",
      "tech: 7\n",
      "never: 7\n",
      "[246, 113, 0.45934959349593496, 1352]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 246 tokens in the data.\n",
      "There are 113 unique tokens in the data.\n",
      "There are 1352 characters in the data.\n",
      "The lexical diversity is 0.459 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 8\n",
      "got: 7\n",
      "gone: 7\n",
      "tech: 7\n",
      "never: 7\n",
      "[246, 113, 0.45934959349593496, 1352]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 224 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 999 characters in the data.\n",
      "The lexical diversity is 0.357 in the data.\n",
      "The 5 most common tokens are:\n",
      "got: 35\n",
      "get: 21\n",
      "together: 11\n",
      "gone: 10\n",
      "cant: 8\n",
      "[224, 80, 0.35714285714285715, 999]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 112 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 530 characters in the data.\n",
      "The lexical diversity is 0.616 in the data.\n",
      "The 5 most common tokens are:\n",
      "right: 7\n",
      "back: 6\n",
      "im: 6\n",
      "giving: 4\n",
      "nothing: 4\n",
      "[112, 69, 0.6160714285714286, 530]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 216 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 961 characters in the data.\n",
      "The lexical diversity is 0.236 in the data.\n",
      "The 5 most common tokens are:\n",
      "work: 43\n",
      "got: 21\n",
      "shake: 16\n",
      "make: 12\n",
      "fit: 12\n",
      "[216, 51, 0.2361111111111111, 961]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 254 tokens in the data.\n",
      "There are 96 unique tokens in the data.\n",
      "There are 1240 characters in the data.\n",
      "The lexical diversity is 0.378 in the data.\n",
      "The 5 most common tokens are:\n",
      "handle: 18\n",
      "cant: 17\n",
      "youre: 11\n",
      "sure: 10\n",
      "yeah: 8\n",
      "[254, 96, 0.3779527559055118, 1240]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 713 characters in the data.\n",
      "The lexical diversity is 0.313 in the data.\n",
      "The 5 most common tokens are:\n",
      "hang: 12\n",
      "gonna: 12\n",
      "im: 7\n",
      "right: 6\n",
      "guess: 4\n",
      "[134, 42, 0.31343283582089554, 713]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 134 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 713 characters in the data.\n",
      "The lexical diversity is 0.313 in the data.\n",
      "The 5 most common tokens are:\n",
      "hang: 12\n",
      "gonna: 12\n",
      "im: 7\n",
      "right: 6\n",
      "guess: 4\n",
      "[134, 42, 0.31343283582089554, 713]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 547 characters in the data.\n",
      "The lexical diversity is 0.431 in the data.\n",
      "The 5 most common tokens are:\n",
      "hang: 11\n",
      "gonna: 8\n",
      "im: 5\n",
      "right: 4\n",
      "guess: 3\n",
      "[102, 44, 0.43137254901960786, 547]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 150 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 748 characters in the data.\n",
      "The lexical diversity is 0.493 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 12\n",
      "healthy: 11\n",
      "ever: 9\n",
      "strange: 7\n",
      "feeling: 7\n",
      "[150, 74, 0.49333333333333335, 748]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 48 tokens in the data.\n",
      "There are 32 unique tokens in the data.\n",
      "There are 246 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "The 5 most common tokens are:\n",
      "go: 5\n",
      "thought: 3\n",
      "makin: 3\n",
      "another: 2\n",
      "baby: 2\n",
      "[48, 32, 0.6666666666666666, 246]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 221 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 1028 characters in the data.\n",
      "The lexical diversity is 0.271 in the data.\n",
      "The 5 most common tokens are:\n",
      "get: 19\n",
      "baby: 18\n",
      "honey: 14\n",
      "want: 13\n",
      "need: 10\n",
      "[221, 60, 0.27149321266968324, 1028]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 92 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 455 characters in the data.\n",
      "The lexical diversity is 0.696 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 5\n",
      "time: 5\n",
      "right: 4\n",
      "cause: 3\n",
      "long: 3\n",
      "[92, 64, 0.6956521739130435, 455]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 113 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 479 characters in the data.\n",
      "The lexical diversity is 0.389 in the data.\n",
      "The 5 most common tokens are:\n",
      "move: 15\n",
      "human: 13\n",
      "im: 12\n",
      "dont: 8\n",
      "body: 8\n",
      "[113, 44, 0.3893805309734513, 479]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 234 tokens in the data.\n",
      "There are 89 unique tokens in the data.\n",
      "There are 1186 characters in the data.\n",
      "The lexical diversity is 0.380 in the data.\n",
      "The 5 most common tokens are:\n",
      "include: 19\n",
      "dont: 16\n",
      "world: 8\n",
      "fall: 8\n",
      "apart: 8\n",
      "[234, 89, 0.3803418803418803, 1186]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 182 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 894 characters in the data.\n",
      "The lexical diversity is 0.313 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 22\n",
      "love: 20\n",
      "like: 13\n",
      "gonna: 12\n",
      "indestructible: 9\n",
      "[182, 57, 0.3131868131868132, 894]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 182 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 887 characters in the data.\n",
      "The lexical diversity is 0.330 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 20\n",
      "love: 18\n",
      "like: 13\n",
      "gonna: 10\n",
      "indestructible: 9\n",
      "[182, 60, 0.32967032967032966, 887]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 670 characters in the data.\n",
      "The lexical diversity is 0.452 in the data.\n",
      "The 5 most common tokens are:\n",
      "eyes: 9\n",
      "look: 8\n",
      "ok: 7\n",
      "like: 6\n",
      "think: 6\n",
      "[146, 66, 0.4520547945205479, 670]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 670 characters in the data.\n",
      "The lexical diversity is 0.452 in the data.\n",
      "The 5 most common tokens are:\n",
      "eyes: 9\n",
      "look: 8\n",
      "ok: 7\n",
      "like: 6\n",
      "think: 6\n",
      "[146, 66, 0.4520547945205479, 670]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 59 tokens in the data.\n",
      "There are 32 unique tokens in the data.\n",
      "There are 279 characters in the data.\n",
      "The lexical diversity is 0.542 in the data.\n",
      "The 5 most common tokens are:\n",
      "gonna: 7\n",
      "heart: 6\n",
      "im: 4\n",
      "never: 4\n",
      "think: 3\n",
      "[59, 32, 0.5423728813559322, 279]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 109 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 478 characters in the data.\n",
      "The lexical diversity is 0.495 in the data.\n",
      "The 5 most common tokens are:\n",
      "wish: 11\n",
      "baby: 6\n",
      "know: 4\n",
      "could: 4\n",
      "day: 4\n",
      "[109, 54, 0.4954128440366973, 478]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 146 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 554 characters in the data.\n",
      "The lexical diversity is 0.418 in the data.\n",
      "The 5 most common tokens are:\n",
      "u: 31\n",
      "jack: 25\n",
      "ill: 16\n",
      "youre: 5\n",
      "go: 3\n",
      "[146, 61, 0.4178082191780822, 554]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 101 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 467 characters in the data.\n",
      "The lexical diversity is 0.752 in the data.\n",
      "The 5 most common tokens are:\n",
      "jag: 4\n",
      "och: 4\n",
      "som: 4\n",
      "en: 3\n",
      "nr: 3\n",
      "[101, 76, 0.7524752475247525, 467]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 83 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 400 characters in the data.\n",
      "The lexical diversity is 0.687 in the data.\n",
      "The 5 most common tokens are:\n",
      "another: 5\n",
      "baby: 5\n",
      "girlfriend: 4\n",
      "say: 4\n",
      "stay: 4\n",
      "[83, 57, 0.6867469879518072, 400]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 180 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 812 characters in the data.\n",
      "The lexical diversity is 0.317 in the data.\n",
      "The 5 most common tokens are:\n",
      "ill: 17\n",
      "keep: 16\n",
      "fire: 8\n",
      "burning: 8\n",
      "even: 8\n",
      "[180, 57, 0.31666666666666665, 812]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 195 tokens in the data.\n",
      "There are 151 unique tokens in the data.\n",
      "There are 994 characters in the data.\n",
      "The lexical diversity is 0.774 in the data.\n",
      "The 5 most common tokens are:\n",
      "like: 10\n",
      "im: 7\n",
      "konichiwa: 4\n",
      "bitches: 4\n",
      "wanna: 4\n",
      "[195, 151, 0.7743589743589744, 994]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 164 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 731 characters in the data.\n",
      "The lexical diversity is 0.488 in the data.\n",
      "The 5 most common tokens are:\n",
      "gone: 26\n",
      "long: 23\n",
      "im: 18\n",
      "today: 5\n",
      "coming: 4\n",
      "[164, 80, 0.4878048780487805, 731]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 121 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 530 characters in the data.\n",
      "The lexical diversity is 0.289 in the data.\n",
      "The 5 most common tokens are:\n",
      "cant: 23\n",
      "control: 16\n",
      "dont: 16\n",
      "like: 15\n",
      "hey: 4\n",
      "[121, 35, 0.2892561983471074, 530]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 315 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 1440 characters in the data.\n",
      "The lexical diversity is 0.152 in the data.\n",
      "The 5 most common tokens are:\n",
      "boom: 46\n",
      "free: 32\n",
      "baby: 24\n",
      "love: 19\n",
      "give: 18\n",
      "[315, 48, 0.1523809523809524, 1440]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 246 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 1162 characters in the data.\n",
      "The lexical diversity is 0.171 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 25\n",
      "know: 16\n",
      "kills: 15\n",
      "cus: 14\n",
      "dont: 11\n",
      "[246, 42, 0.17073170731707318, 1162]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 247 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 1167 characters in the data.\n",
      "The lexical diversity is 0.170 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 25\n",
      "know: 16\n",
      "kills: 15\n",
      "cus: 14\n",
      "dont: 11\n",
      "[247, 42, 0.1700404858299595, 1167]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 147 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 659 characters in the data.\n",
      "The lexical diversity is 0.463 in the data.\n",
      "The 5 most common tokens are:\n",
      "work: 13\n",
      "lets: 12\n",
      "thing: 8\n",
      "weve: 6\n",
      "got: 6\n",
      "[147, 68, 0.46258503401360546, 659]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 188 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 1003 characters in the data.\n",
      "The lexical diversity is 0.404 in the data.\n",
      "The 5 most common tokens are:\n",
      "space: 10\n",
      "left: 10\n",
      "theres: 10\n",
      "empty: 9\n",
      "behind: 9\n",
      "[188, 76, 0.40425531914893614, 1003]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 98 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 531 characters in the data.\n",
      "The lexical diversity is 0.643 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 7\n",
      "morning: 4\n",
      "friday: 4\n",
      "saturday: 4\n",
      "sunday: 4\n",
      "[98, 63, 0.6428571428571429, 531]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 82 tokens in the data.\n",
      "There are 30 unique tokens in the data.\n",
      "There are 350 characters in the data.\n",
      "The lexical diversity is 0.366 in the data.\n",
      "The 5 most common tokens are:\n",
      "life: 14\n",
      "gone: 7\n",
      "love: 7\n",
      "let: 6\n",
      "monument: 4\n",
      "[82, 30, 0.36585365853658536, 350]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 74 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 319 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 8\n",
      "dont: 8\n",
      "go: 5\n",
      "moonlight: 3\n",
      "oh: 3\n",
      "[74, 41, 0.5540540540540541, 319]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 100 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 510 characters in the data.\n",
      "The lexical diversity is 0.680 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 5\n",
      "chorus: 4\n",
      "thats: 4\n",
      "im: 4\n",
      "dont: 4\n",
      "[100, 68, 0.68, 510]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 102 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 524 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "The 5 most common tokens are:\n",
      "truth: 12\n",
      "dont: 6\n",
      "cause: 4\n",
      "chorus: 4\n",
      "cant: 3\n",
      "[102, 68, 0.6666666666666666, 524]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 126 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 555 characters in the data.\n",
      "The lexical diversity is 0.468 in the data.\n",
      "The 5 most common tokens are:\n",
      "none: 14\n",
      "take: 6\n",
      "away: 6\n",
      "ive: 4\n",
      "im: 4\n",
      "[126, 59, 0.46825396825396826, 555]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 126 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 555 characters in the data.\n",
      "The lexical diversity is 0.468 in the data.\n",
      "The 5 most common tokens are:\n",
      "none: 14\n",
      "take: 6\n",
      "away: 6\n",
      "ive: 4\n",
      "im: 4\n",
      "[126, 59, 0.46825396825396826, 555]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 94 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 486 characters in the data.\n",
      "The lexical diversity is 0.745 in the data.\n",
      "The 5 most common tokens are:\n",
      "never: 4\n",
      "hes: 4\n",
      "isnt: 3\n",
      "chorus: 3\n",
      "loveless: 3\n",
      "[94, 70, 0.7446808510638298, 486]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 90 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 417 characters in the data.\n",
      "The lexical diversity is 0.689 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 6\n",
      "dont: 6\n",
      "chorus: 4\n",
      "youre: 4\n",
      "say: 4\n",
      "[90, 62, 0.6888888888888889, 417]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 96 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 448 characters in the data.\n",
      "The lexical diversity is 0.573 in the data.\n",
      "The 5 most common tokens are:\n",
      "yeah: 14\n",
      "say: 7\n",
      "people: 6\n",
      "never: 5\n",
      "play: 3\n",
      "[96, 55, 0.5729166666666666, 448]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 194 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 954 characters in the data.\n",
      "The lexical diversity is 0.376 in the data.\n",
      "The 5 most common tokens are:\n",
      "baby: 20\n",
      "psycho: 19\n",
      "youre: 15\n",
      "know: 11\n",
      "dont: 9\n",
      "[194, 73, 0.37628865979381443, 954]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 52 tokens in the data.\n",
      "There are 39 unique tokens in the data.\n",
      "There are 257 characters in the data.\n",
      "The lexical diversity is 0.750 in the data.\n",
      "The 5 most common tokens are:\n",
      "boy: 5\n",
      "hey: 4\n",
      "little: 3\n",
      "lost: 2\n",
      "robot: 2\n",
      "[52, 39, 0.75, 257]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 137 tokens in the data.\n",
      "There are 94 unique tokens in the data.\n",
      "There are 701 characters in the data.\n",
      "The lexical diversity is 0.686 in the data.\n",
      "The 5 most common tokens are:\n",
      "im: 8\n",
      "robyn: 7\n",
      "make: 4\n",
      "let: 3\n",
      "know: 3\n",
      "[137, 94, 0.6861313868613139, 701]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 52 tokens in the data.\n",
      "There are 14 unique tokens in the data.\n",
      "There are 222 characters in the data.\n",
      "The lexical diversity is 0.269 in the data.\n",
      "The 5 most common tokens are:\n",
      "want: 28\n",
      "say: 9\n",
      "woman: 3\n",
      "ready: 2\n",
      "sayit: 1\n",
      "[52, 14, 0.2692307692307692, 222]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 104 tokens in the data.\n",
      "There are 38 unique tokens in the data.\n",
      "There are 483 characters in the data.\n",
      "The lexical diversity is 0.365 in the data.\n",
      "The 5 most common tokens are:\n",
      "got: 11\n",
      "say: 11\n",
      "baby: 9\n",
      "something: 6\n",
      "tonight: 5\n",
      "[104, 38, 0.36538461538461536, 483]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 138 tokens in the data.\n",
      "There are 25 unique tokens in the data.\n",
      "There are 510 characters in the data.\n",
      "The lexical diversity is 0.181 in the data.\n",
      "The 5 most common tokens are:\n",
      "set: 44\n",
      "got: 34\n",
      "free: 18\n",
      "know: 15\n",
      "body: 4\n",
      "[138, 25, 0.18115942028985507, 510]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 97 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 480 characters in the data.\n",
      "The lexical diversity is 0.680 in the data.\n",
      "The 5 most common tokens are:\n",
      "known: 9\n",
      "let: 3\n",
      "even: 3\n",
      "know: 3\n",
      "believe: 3\n",
      "[97, 66, 0.6804123711340206, 480]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 97 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 480 characters in the data.\n",
      "The lexical diversity is 0.680 in the data.\n",
      "The 5 most common tokens are:\n",
      "known: 9\n",
      "let: 3\n",
      "even: 3\n",
      "know: 3\n",
      "believe: 3\n",
      "[97, 66, 0.6804123711340206, 480]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 181 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 815 characters in the data.\n",
      "The lexical diversity is 0.315 in the data.\n",
      "The 5 most common tokens are:\n",
      "show: 34\n",
      "love: 24\n",
      "alright: 10\n",
      "baby: 8\n",
      "one: 7\n",
      "[181, 57, 0.3149171270718232, 815]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 85 tokens in the data.\n",
      "There are 32 unique tokens in the data.\n",
      "There are 450 characters in the data.\n",
      "The lexical diversity is 0.376 in the data.\n",
      "The 5 most common tokens are:\n",
      "stars: 12\n",
      "forever: 10\n",
      "together: 6\n",
      "4x: 6\n",
      "right: 6\n",
      "[85, 32, 0.3764705882352941, 450]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 180 tokens in the data.\n",
      "There are 89 unique tokens in the data.\n",
      "There are 829 characters in the data.\n",
      "The lexical diversity is 0.494 in the data.\n",
      "The 5 most common tokens are:\n",
      "still: 12\n",
      "im: 9\n",
      "know: 7\n",
      "let: 6\n",
      "girl: 5\n",
      "[180, 89, 0.49444444444444446, 829]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 74 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 338 characters in the data.\n",
      "The lexical diversity is 0.378 in the data.\n",
      "The 5 most common tokens are:\n",
      "tell: 21\n",
      "today: 11\n",
      "want: 8\n",
      "chance: 2\n",
      "dance: 2\n",
      "[74, 28, 0.3783783783783784, 338]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 171 tokens in the data.\n",
      "There are 96 unique tokens in the data.\n",
      "There are 779 characters in the data.\n",
      "The lexical diversity is 0.561 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 8\n",
      "always: 7\n",
      "time: 6\n",
      "love: 6\n",
      "cause: 6\n",
      "[171, 96, 0.5614035087719298, 779]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 129 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 624 characters in the data.\n",
      "The lexical diversity is 0.411 in the data.\n",
      "The 5 most common tokens are:\n",
      "back: 14\n",
      "taking: 12\n",
      "time: 6\n",
      "could: 5\n",
      "one: 5\n",
      "[129, 53, 0.4108527131782946, 624]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 29 tokens in the data.\n",
      "There are 16 unique tokens in the data.\n",
      "There are 127 characters in the data.\n",
      "The lexical diversity is 0.552 in the data.\n",
      "The 5 most common tokens are:\n",
      "uh: 6\n",
      "like: 4\n",
      "dont: 2\n",
      "gimme: 2\n",
      "somethin: 2\n",
      "[29, 16, 0.5517241379310345, 127]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 108 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 521 characters in the data.\n",
      "The lexical diversity is 0.769 in the data.\n",
      "The 5 most common tokens are:\n",
      "see: 4\n",
      "love: 4\n",
      "underneath: 3\n",
      "heart: 3\n",
      "chorus: 3\n",
      "[108, 83, 0.7685185185185185, 521]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 83 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 435 characters in the data.\n",
      "The lexical diversity is 0.711 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 6\n",
      "shes: 5\n",
      "universal: 3\n",
      "woman: 3\n",
      "chorus: 3\n",
      "[83, 59, 0.7108433734939759, 435]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 323 tokens in the data.\n",
      "There are 183 unique tokens in the data.\n",
      "There are 1600 characters in the data.\n",
      "The lexical diversity is 0.567 in the data.\n",
      "The 5 most common tokens are:\n",
      "better: 42\n",
      "know: 33\n",
      "fuck: 15\n",
      "im: 8\n",
      "yyou: 7\n",
      "[323, 183, 0.56656346749226, 1600]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 323 tokens in the data.\n",
      "There are 183 unique tokens in the data.\n",
      "There are 1600 characters in the data.\n",
      "The lexical diversity is 0.567 in the data.\n",
      "The 5 most common tokens are:\n",
      "better: 42\n",
      "know: 33\n",
      "fuck: 15\n",
      "im: 8\n",
      "yyou: 7\n",
      "[323, 183, 0.56656346749226, 1600]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 222 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 1129 characters in the data.\n",
      "The lexical diversity is 0.324 in the data.\n",
      "The 5 most common tokens are:\n",
      "dance: 68\n",
      "beat: 67\n",
      "dont: 7\n",
      "stop: 7\n",
      "loud: 3\n",
      "[222, 72, 0.32432432432432434, 1129]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 222 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 1129 characters in the data.\n",
      "The lexical diversity is 0.324 in the data.\n",
      "The 5 most common tokens are:\n",
      "dance: 68\n",
      "beat: 67\n",
      "dont: 7\n",
      "stop: 7\n",
      "loud: 3\n",
      "[222, 72, 0.32432432432432434, 1129]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 55 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 266 characters in the data.\n",
      "The lexical diversity is 0.764 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 5\n",
      "thinkin: 3\n",
      "go: 2\n",
      "thoughts: 2\n",
      "used: 2\n",
      "[55, 42, 0.7636363636363637, 266]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 170 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 762 characters in the data.\n",
      "The lexical diversity is 0.318 in the data.\n",
      "The 5 most common tokens are:\n",
      "girl: 24\n",
      "whos: 19\n",
      "cant: 10\n",
      "take: 7\n",
      "pressure: 7\n",
      "[170, 54, 0.3176470588235294, 762]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 106 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 537 characters in the data.\n",
      "The lexical diversity is 0.311 in the data.\n",
      "The 5 most common tokens are:\n",
      "every: 12\n",
      "heartbeat: 9\n",
      "hurts: 8\n",
      "could: 6\n",
      "dont: 6\n",
      "[106, 33, 0.3113207547169811, 537]\n",
      "\n",
      "Descriptive statistics for robyn lyrics:\n",
      "There are 81 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 366 characters in the data.\n",
      "The lexical diversity is 0.691 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 5\n",
      "youve: 4\n",
      "got: 4\n",
      "ive: 3\n",
      "something: 2\n",
      "[81, 56, 0.691358024691358, 366]\n",
      "\n",
      "Overall descriptive statistics for cher lyrics:\n",
      "There are 35916 tokens in the data.\n",
      "There are 3703 unique tokens in the data.\n",
      "There are 172634 characters in the data.\n",
      "The lexical diversity is 0.103 in the data.\n",
      "The 5 most common tokens are:\n",
      "love: 1004\n",
      "im: 513\n",
      "know: 486\n",
      "dont: 440\n",
      "youre: 333\n",
      "[35916, 3703, 0.10310168170174852, 172634]\n",
      "\n",
      "Overall descriptive statistics for robyn lyrics:\n",
      "There are 15227 tokens in the data.\n",
      "There are 2156 unique tokens in the data.\n",
      "There are 73787 characters in the data.\n",
      "The lexical diversity is 0.142 in the data.\n",
      "The 5 most common tokens are:\n",
      "know: 308\n",
      "dont: 301\n",
      "im: 299\n",
      "love: 275\n",
      "got: 251\n",
      "[15227, 2156, 0.14159059565245943, 73787]\n"
     ]
    }
   ],
   "source": [
    "# Finding the lexical diversity of Cher and Robyn\n",
    "\n",
    "# Reading lyrics data\n",
    "lyrics_path = os.path.join(data_location, lyrics_folder)\n",
    "if os.path.exists(lyrics_path):\n",
    "    lyrics_dirs = os.listdir(lyrics_path)\n",
    "    all_lyrics = []\n",
    "    for lyrics_dir in lyrics_dirs:\n",
    "        dir_path = os.path.join(lyrics_path, lyrics_dir)\n",
    "        if os.path.isdir(dir_path):\n",
    "            files = os.listdir(dir_path)\n",
    "            for file in files:\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        lyrics_data = f.read()\n",
    "                        cleaned_data = clean_and_tokenize(lyrics_data)\n",
    "                        all_lyrics.append({\n",
    "                            'artist': lyrics_dir,\n",
    "                            'lyrics': lyrics_data,\n",
    "                            'cleaned_lyrics': cleaned_data\n",
    "                        })\n",
    "                except FileNotFoundError as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                except PermissionError as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "    # Create a DataFrame for the lyrics data\n",
    "    lyrics_df = pd.DataFrame(all_lyrics)\n",
    "    print(\"Lyrics DataFrame:\")\n",
    "    print(lyrics_df.head())\n",
    "\n",
    "    # Perform descriptive statistics on cleaned lyrics data\n",
    "    for index, row in lyrics_df.iterrows():\n",
    "        print(f\"\\nDescriptive statistics for {row['artist']} lyrics:\")\n",
    "        stats = descriptive_stats(row['cleaned_lyrics'], verbose=True)\n",
    "        print(stats)\n",
    "else:\n",
    "    print(f\"Lyrics directory does not exist: {lyrics_path}\")\n",
    "\n",
    "# Calculate average lexical diversity for each artist\n",
    "artists = lyrics_df['artist'].unique()\n",
    "for artist in artists:\n",
    "    artist_tokens = []\n",
    "    for _, row in lyrics_df[lyrics_df['artist'] == artist].iterrows():\n",
    "        artist_tokens.extend(row['cleaned_lyrics'])\n",
    "    print(f\"\\nOverall descriptive statistics for {artist} lyrics:\")\n",
    "    stats = descriptive_stats(artist_tokens, verbose=True)\n",
    "    print(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46294409",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "A: If we left stopwords in the data the top 5 words would more than likely find frequently occurring english words such as \"the\", \"is\", \"in\", \"and\", and \"to\".\n",
    "\n",
    "---\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: My prior beliefs about the lexical diversity between the artists are that the different musical genres might be an influence. Since, lexical diversity is a measure of different words appear in text, it would make sense that the musical genre's of Hip Hop or Folk music would have a higher lexical diversity than Pop which tends to use more repetitive and simpler language. Both Cher and Robyn are primarily pop artists and therefore might have lower lexical diversity. The difference or lack there of in lexical diversity between the artists do conform to my prior beliefs. Since they are both pop singers there would be little difference in their lexical diversity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e1ac1",
   "metadata": {},
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "753a5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(emoji.is_emoji(\"\"))\n",
    "assert(not emoji.is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fc4c0",
   "metadata": {},
   "source": [
    "### Emojis \n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "269cd433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten most common emojis used:\n",
      ": 100141\n",
      ": 72377\n",
      ": 52308\n",
      ": 51815\n",
      ": 49063\n",
      ": 32250\n",
      ": 31591\n",
      ": 26946\n",
      ": 23458\n",
      ": 22548\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "from collections import Counter\n",
    "\n",
    "# Define the directory path\n",
    "twitter_directory = r\"C:\\Users\\keevi\\OneDrive\\Documents\\SDU\\ADS-509\\Week 2\\M1 Results\\twitter\"\n",
    "\n",
    "# Helper function to extract emojis from text\n",
    "def extract_emojis(text):\n",
    "    return [char for char in text if emoji.is_emoji(char)]\n",
    "\n",
    "# Dictionary to store emoji counts\n",
    "emoji_counts = Counter()\n",
    "\n",
    "# Traverse the directory\n",
    "for root, dirs, files in os.walk(twitter_directory):\n",
    "    for file in files:\n",
    "        # Read the file content\n",
    "        file_path = os.path.join(root, file)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            tweets = f.readlines()\n",
    "        \n",
    "        # Extract emojis from each tweet and update the counts\n",
    "        for tweet in tweets:\n",
    "            emojis = extract_emojis(tweet)\n",
    "            emoji_counts.update(emojis)\n",
    "\n",
    "# Print the ten most common emojis\n",
    "print(\"Ten most common emojis used:\")\n",
    "for emoji_char, count in emoji_counts.most_common(10):\n",
    "    print(f\"{emoji_char}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9b770",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07c396f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ten most common hashtags for .DS_Store:\n",
      "\n",
      "Ten most common hashtags for cher_followers:\n",
      "\n",
      "Ten most common hashtags for cher_followers_data:\n",
      "#BLM: 10100\n",
      "#Resist: 6161\n",
      "#BlackLivesMatter: 4888\n",
      "#resist: 3860\n",
      "#FBR: 3330\n",
      "#1: 3111\n",
      "#TheResistance: 3044\n",
      "#blacklivesmatter: 2738\n",
      "#Resistance: 1953\n",
      "#RESIST: 1878\n",
      "\n",
      "Ten most common hashtags for robynkonichiwa_followers:\n",
      "\n",
      "Ten most common hashtags for robynkonichiwa_followers_data:\n",
      "#BlackLivesMatter: 356\n",
      "#BLM: 345\n",
      "#1: 228\n",
      "#blacklivesmatter: 222\n",
      "#music: 175\n",
      "#Music: 114\n",
      "#EDM: 87\n",
      "#LGBTQ: 76\n",
      "#blm: 60\n",
      "#TeamFollowBack: 59\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Define the directory path\n",
    "twitter_directory = r\"C:\\Users\\keevi\\OneDrive\\Documents\\SDU\\ADS-509\\Week 2\\M1 Results\\twitter\"\n",
    "\n",
    "# Helper function to extract hashtags from text\n",
    "def extract_hashtags(text):\n",
    "    return re.findall(r'#\\w+', text)\n",
    "\n",
    "# Dictionary to store hashtag counts by artist\n",
    "hashtag_counts_by_artist = {}\n",
    "\n",
    "# Traverse the directory\n",
    "for root, dirs, files in os.walk(twitter_directory):\n",
    "    for file in files:\n",
    "        # Read the file content\n",
    "        file_path = os.path.join(root, file)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            tweets = f.readlines()\n",
    "        \n",
    "        # Extract hashtags from each tweet and update the counts for the artist\n",
    "        artist = os.path.splitext(file)[0]\n",
    "        hashtag_counts = Counter()\n",
    "        for tweet in tweets:\n",
    "            hashtags = extract_hashtags(tweet)\n",
    "            hashtag_counts.update(hashtags)\n",
    "        \n",
    "        # Store the hashtag counts for the artist\n",
    "        hashtag_counts_by_artist[artist] = hashtag_counts\n",
    "\n",
    "# Print the ten most common hashtags by artist\n",
    "for artist, hashtag_counts in hashtag_counts_by_artist.items():\n",
    "    print(f\"\\nTen most common hashtags for {artist}:\")\n",
    "    for hashtag, count in hashtag_counts.most_common(10):\n",
    "        print(f\"{hashtag}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f21d5",
   "metadata": {},
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb69b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Five most common words in song titles for cher_88degrees:\n",
      "the: 19\n",
      "so: 16\n",
      "to: 11\n",
      "is: 8\n",
      "I'm: 8\n",
      "\n",
      "Five most common words in song titles for cher_adifferentkindoflovesong:\n",
      "of: 18\n",
      "kind: 15\n",
      "love: 15\n",
      "song: 14\n",
      "is: 10\n",
      "\n",
      "Five most common words in song titles for cher_afterall:\n",
      "to: 15\n",
      "all: 15\n",
      "and: 13\n",
      "After: 12\n",
      "you: 10\n",
      "\n",
      "Five most common words in song titles for cher_again:\n",
      "you: 6\n",
      "me: 4\n",
      "If: 3\n",
      "again: 3\n",
      "I: 3\n",
      "\n",
      "Five most common words in song titles for cher_alfie:\n",
      "it: 5\n",
      "we: 5\n",
      "Alfie.: 5\n",
      "the: 4\n",
      "to: 4\n",
      "\n",
      "Five most common words in song titles for cher_aliveagain:\n",
      "I: 22\n",
      "the: 10\n",
      "to: 8\n",
      "a: 7\n",
      "need: 7\n",
      "\n",
      "Five most common words in song titles for cher_allbecauseofyou:\n",
      "of: 19\n",
      "because: 17\n",
      "you: 15\n",
      "I: 11\n",
      "All: 10\n",
      "\n",
      "Five most common words in song titles for cher_allireallywanttodo:\n",
      "you: 37\n",
      "or: 14\n",
      "with: 12\n",
      "I: 11\n",
      "be: 10\n",
      "\n",
      "Five most common words in song titles for cher_allornothing:\n",
      "you: 17\n",
      "Baby: 10\n",
      "it's: 10\n",
      "all: 10\n",
      "or: 10\n",
      "\n",
      "Five most common words in song titles for cher_amiblue:\n",
      "I: 16\n",
      "was: 7\n",
      "I'm: 7\n",
      "Am: 6\n",
      "blue: 6\n",
      "\n",
      "Five most common words in song titles for cher_angelsrunning:\n",
      "a: 12\n",
      "I: 11\n",
      "And: 7\n",
      "thing: 7\n",
      "know: 5\n",
      "\n",
      "Five most common words in song titles for cher_applesdontfallfarfromthetree:\n",
      "the: 11\n",
      "I: 9\n",
      "And: 8\n",
      "on: 7\n",
      "Apples: 6\n",
      "\n",
      "Five most common words in song titles for cher_awomansstory:\n",
      "I: 16\n",
      "love: 12\n",
      "me: 8\n",
      "it: 8\n",
      "can't: 7\n",
      "\n",
      "Five most common words in song titles for cher_aworldwithoutheroes:\n",
      "a: 12\n",
      "without: 9\n",
      "you: 8\n",
      "world: 7\n",
      "heroes: 6\n",
      "\n",
      "Five most common words in song titles for cher_ayounggirluneenfante:\n",
      "her: 10\n",
      "She: 8\n",
      "of: 7\n",
      "she: 7\n",
      "the: 7\n",
      "\n",
      "Five most common words in song titles for cher_backonthestreetagain:\n",
      "I: 30\n",
      "Here: 12\n",
      "am,: 12\n",
      "I'm: 12\n",
      "back: 12\n",
      "\n",
      "Five most common words in song titles for cher_bangbang:\n",
      "bang: 33\n",
      "Bang: 29\n",
      "me: 12\n",
      "shot: 10\n",
      "I: 10\n",
      "\n",
      "Five most common words in song titles for cher_bangbangmybabyshotmedown:\n",
      "Bang: 13\n",
      "bang,: 12\n",
      "I: 10\n",
      "the: 7\n",
      "down: 6\n",
      "\n",
      "Five most common words in song titles for cher_behindthedoor:\n",
      "the: 9\n",
      "of: 9\n",
      "every: 9\n",
      "The: 8\n",
      "a: 6\n",
      "\n",
      "Five most common words in song titles for cher_believe:\n",
      "I: 21\n",
      "you: 14\n",
      "don't: 12\n",
      "after: 10\n",
      "strong: 10\n",
      "\n",
      "Five most common words in song titles for cher_bellbottomblues:\n",
      "to: 23\n",
      "you: 21\n",
      "I: 16\n",
      "want: 16\n",
      "me: 15\n",
      "\n",
      "Five most common words in song titles for cher_blowininthewind:\n",
      "many: 10\n",
      "the: 10\n",
      "The: 7\n",
      "Before: 7\n",
      "in: 7\n",
      "\n",
      "Five most common words in song titles for cher_bodytobodyhearttoheart:\n",
      "to: 23\n",
      "heart: 13\n",
      "you: 11\n",
      "body: 10\n",
      "I: 9\n",
      "\n",
      "Five most common words in song titles for cher_bornwiththehunger:\n",
      "the: 12\n",
      "hunger: 10\n",
      "The: 6\n",
      "born: 6\n",
      "with: 6\n",
      "\n",
      "Five most common words in song titles for cher_borrowedtime:\n",
      "on: 19\n",
      "the: 17\n",
      "borrowed: 9\n",
      "time: 9\n",
      "Living: 8\n",
      "\n",
      "Five most common words in song titles for cher_boysandgirls:\n",
      "your: 22\n",
      "you: 16\n",
      "and: 12\n",
      "a: 9\n",
      "up: 8\n",
      "\n",
      "Five most common words in song titles for cher_buticantloveyoumore:\n",
      "I: 16\n",
      "you: 7\n",
      "the: 6\n",
      "love: 5\n",
      "More-I: 4\n",
      "\n",
      "Five most common words in song titles for cher_bymyself:\n",
      "I: 17\n",
      "gotta: 13\n",
      "myself: 12\n",
      "my: 11\n",
      "go: 10\n",
      "\n",
      "Five most common words in song titles for cher_canyoufool:\n",
      "you: 20\n",
      "the: 11\n",
      "can: 9\n",
      "of: 7\n",
      "that: 7\n",
      "\n",
      "Five most common words in song titles for cher_carnival:\n",
      "my: 6\n",
      "I'll: 4\n",
      "the: 4\n",
      "sing: 3\n",
      "Carnival: 3\n",
      "\n",
      "Five most common words in song titles for cher_carouselman:\n",
      "man: 14\n",
      "me: 10\n",
      "The: 10\n",
      "around: 10\n",
      "carousel: 9\n",
      "\n",
      "Five most common words in song titles for cher_catchthewind:\n",
      "the: 10\n",
      "I: 9\n",
      "And: 7\n",
      "to: 5\n",
      "be: 4\n",
      "\n",
      "Five most common words in song titles for cher_chastityssongbandofthieves:\n",
      "about: 16\n",
      "What: 14\n",
      "the: 14\n",
      "good: 14\n",
      "I: 13\n",
      "\n",
      "Five most common words in song titles for cher_chastitysun:\n",
      "the: 10\n",
      "to: 8\n",
      "You: 7\n",
      "you: 4\n",
      "are: 4\n",
      "\n",
      "Five most common words in song titles for cher_chiquitita:\n",
      "you: 18\n",
      "the: 14\n",
      "and: 11\n",
      "I: 9\n",
      "a: 8\n",
      "\n",
      "Five most common words in song titles for cher_chiquititaspanishversion:\n",
      "Chiquitita,: 7\n",
      "Tu: 6\n",
      "que: 6\n",
      "compartir: 6\n",
      "Chiquitita: 6\n",
      "\n",
      "Five most common words in song titles for cher_classified1a:\n",
      "I: 15\n",
      "you: 10\n",
      "love: 6\n",
      "time: 6\n",
      "my: 4\n",
      "\n",
      "Five most common words in song titles for cher_clicksong:\n",
      "nguqo: 4\n",
      "ngqothwane: 4\n",
      "Igqira: 2\n",
      "lendlela: 2\n",
      "Sebeqabele: 2\n",
      "\n",
      "Five most common words in song titles for cher_comeandstaywithme:\n",
      "I'll: 8\n",
      "and: 6\n",
      "stay: 6\n",
      "with: 6\n",
      "me: 6\n",
      "\n",
      "Five most common words in song titles for cher_cometoyourwindow:\n",
      "to: 11\n",
      "you: 11\n",
      "the: 9\n",
      "me: 8\n",
      "your: 7\n",
      "\n",
      "Five most common words in song titles for cher_couldvebeenyou:\n",
      "you: 25\n",
      "been: 21\n",
      "baby: 11\n",
      "When: 11\n",
      "I: 10\n",
      "\n",
      "Five most common words in song titles for cher_crylikeababy:\n",
      "a: 26\n",
      "I: 15\n",
      "cry: 10\n",
      "like: 9\n",
      "baby: 9\n",
      "\n",
      "Five most common words in song titles for cher_crymyselftosleep:\n",
      "cry: 9\n",
      "to: 9\n",
      "I: 8\n",
      "myself: 7\n",
      "sleep: 7\n",
      "\n",
      "Five most common words in song titles for cher_dancingqueen:\n",
      "the: 23\n",
      "that: 7\n",
      "queen: 7\n",
      "You: 6\n",
      "can: 6\n",
      "\n",
      "Five most common words in song titles for cher_dangeroustimes:\n",
      "I: 13\n",
      "you: 9\n",
      "me: 8\n",
      "my: 5\n",
      "the: 5\n",
      "\n",
      "Five most common words in song titles for cher_dannyboy:\n",
      "the: 9\n",
      "and: 9\n",
      "I: 7\n",
      "you: 5\n",
      "And: 5\n",
      "\n",
      "Five most common words in song titles for cher_darklady:\n",
      "the: 11\n",
      "her: 8\n",
      "and: 8\n",
      "I: 8\n",
      "my: 6\n",
      "\n",
      "Five most common words in song titles for cher_davidssong:\n",
      "I: 17\n",
      "you: 15\n",
      "could: 12\n",
      "to: 9\n",
      "start: 6\n",
      "\n",
      "Five most common words in song titles for cher_disastercake:\n",
      "you: 15\n",
      "you're: 13\n",
      "to: 9\n",
      "my: 8\n",
      "a: 7\n",
      "\n",
      "Five most common words in song titles for cher_dixie:\n",
      "I: 13\n",
      "the: 7\n",
      "a: 6\n",
      "be: 5\n",
      "was: 4\n",
      "\n",
      "Five most common words in song titles for cher_dixiegirl:\n",
      "I: 16\n",
      "a: 11\n",
      "in: 9\n",
      "with: 7\n",
      "the: 6\n",
      "\n",
      "Five most common words in song titles for cher_doesanybodyreallyfallinloveanymore:\n",
      "I: 19\n",
      "to: 16\n",
      "Does: 15\n",
      "anybody: 15\n",
      "really: 15\n",
      "\n",
      "Five most common words in song titles for cher_doievercrossyourmind:\n",
      "ever: 12\n",
      "I: 8\n",
      "your: 8\n",
      "cross: 7\n",
      "mind: 7\n",
      "\n",
      "Five most common words in song titles for cher_dontcomearoundtonight:\n",
      "I: 12\n",
      "the: 9\n",
      "to: 8\n",
      "you: 8\n",
      "my: 5\n",
      "\n",
      "Five most common words in song titles for cher_donthideyourlove:\n",
      "your: 13\n",
      "love: 12\n",
      "me: 10\n",
      "and: 10\n",
      "hide: 10\n",
      "\n",
      "Five most common words in song titles for cher_dontthinktwice:\n",
      "I: 9\n",
      "ain't: 6\n",
      "no: 6\n",
      "use: 6\n",
      "and: 6\n",
      "\n",
      "Five most common words in song titles for cher_donttrytoclosearose:\n",
      "the: 13\n",
      "it: 12\n",
      "to: 7\n",
      "a: 7\n",
      "me: 5\n",
      "\n",
      "Five most common words in song titles for cher_dorightwomandorightman:\n",
      "a: 13\n",
      "do: 11\n",
      "right: 10\n",
      "all's: 10\n",
      "you: 7\n",
      "\n",
      "Five most common words in song titles for cher_dovelamore:\n",
      "love: 14\n",
      "my: 13\n",
      "you: 12\n",
      "is: 10\n",
      "other: 10\n",
      "\n",
      "Five most common words in song titles for cher_dowhatyougottado:\n",
      "you: 16\n",
      "to: 8\n",
      "me: 8\n",
      "I: 6\n",
      "see: 6\n",
      "\n",
      "Five most common words in song titles for cher_downdowndown:\n",
      "I: 15\n",
      "the: 15\n",
      "Down,: 7\n",
      "to: 7\n",
      "rock: 6\n",
      "\n",
      "Five most common words in song titles for cher_doyoubelieveinmagic:\n",
      "you: 16\n",
      "believe: 12\n",
      "the: 10\n",
      "in: 9\n",
      "magic: 9\n",
      "\n",
      "Five most common words in song titles for cher_dreambaby:\n",
      "I: 14\n",
      "the: 6\n",
      "for: 5\n",
      "dream: 5\n",
      "that: 5\n",
      "\n",
      "Five most common words in song titles for cher_dressedtokill:\n",
      "I: 10\n",
      "the: 10\n",
      "you: 9\n",
      "to: 9\n",
      "will: 9\n",
      "\n",
      "Five most common words in song titles for cher_earlymorningstrangers:\n",
      "to: 8\n",
      "mornin': 7\n",
      "love: 7\n",
      "I: 6\n",
      "strangers: 5\n",
      "\n",
      "Five most common words in song titles for cher_easytobehard:\n",
      "Easy: 13\n",
      "to: 13\n",
      "be: 12\n",
      "How: 9\n",
      "can: 8\n",
      "\n",
      "Five most common words in song titles for cher_elusivebutterfly:\n",
      "the: 10\n",
      "of: 6\n",
      "You: 5\n",
      "might: 5\n",
      "something: 5\n",
      "\n",
      "Five most common words in song titles for cher_emotionalfire:\n",
      "I: 12\n",
      "you: 12\n",
      "Emotional: 9\n",
      "fire,: 8\n",
      "fire: 7\n",
      "\n",
      "Five most common words in song titles for cher_fastcompany:\n",
      "the: 13\n",
      "I: 10\n",
      "You: 7\n",
      "you're: 6\n",
      "to: 6\n",
      "\n",
      "Five most common words in song titles for cher_favouritescars:\n",
      "you: 17\n",
      "Love: 15\n",
      "of: 15\n",
      "a: 13\n",
      "my: 12\n",
      "\n",
      "Five most common words in song titles for cher_fernando:\n",
      "I: 17\n",
      "the: 15\n",
      "Fernando: 12\n",
      "were: 11\n",
      "to: 10\n",
      "\n",
      "Five most common words in song titles for cher_fernando710922:\n",
      "I: 17\n",
      "the: 15\n",
      "Fernando: 12\n",
      "were: 11\n",
      "to: 10\n",
      "\n",
      "Five most common words in song titles for cher_fireandrain:\n",
      "I: 13\n",
      "I've: 12\n",
      "seen: 12\n",
      "to: 8\n",
      "you: 7\n",
      "\n",
      "Five most common words in song titles for cher_firesofeden:\n",
      "of: 15\n",
      "was: 12\n",
      "a: 9\n",
      "you: 9\n",
      "in: 8\n",
      "\n",
      "Five most common words in song titles for cher_fittofly:\n",
      "the: 12\n",
      "I: 9\n",
      "I'm: 8\n",
      "to: 7\n",
      "your: 6\n",
      "\n",
      "Five most common words in song titles for cher_flashback:\n",
      "you: 15\n",
      "your: 13\n",
      "to: 11\n",
      "a: 9\n",
      "I: 9\n",
      "\n",
      "Five most common words in song titles for cher_forwhatitsworth:\n",
      "what's: 14\n",
      "that: 7\n",
      "sound: 7\n",
      "Everybody: 7\n",
      "look: 7\n",
      "\n",
      "Five most common words in song titles for cher_games:\n",
      "a: 9\n",
      "you: 9\n",
      "the: 6\n",
      "it: 6\n",
      "Whatever: 4\n",
      "\n",
      "Five most common words in song titles for cher_geronimoscadillac:\n",
      "in: 9\n",
      "me: 7\n",
      "back: 7\n",
      "I: 7\n",
      "cadillac: 7\n",
      "\n",
      "Five most common words in song titles for cher_gimmegimmegimmeamanaftermidnight:\n",
      "the: 26\n",
      "a: 14\n",
      "to: 11\n",
      "Gimme,: 10\n",
      "gimme,: 10\n",
      "\n",
      "Five most common words in song titles for cher_girldontcome:\n",
      "you: 15\n",
      "wanna: 11\n",
      "don't: 10\n",
      "You: 9\n",
      "see: 8\n",
      "\n",
      "Five most common words in song titles for cher_gitdownguitargroupie:\n",
      "Away,: 20\n",
      "wanna: 12\n",
      "out: 10\n",
      "and: 10\n",
      "I: 9\n",
      "\n",
      "Five most common words in song titles for cher_giveourloveafightinchance:\n",
      "a: 11\n",
      "you: 8\n",
      "love: 7\n",
      "our: 6\n",
      "to: 5\n",
      "\n",
      "Five most common words in song titles for cher_gonow:\n",
      "you: 19\n",
      "now.: 14\n",
      "to: 9\n",
      "go: 7\n",
      "I: 7\n",
      "\n",
      "Five most common words in song titles for cher_gypsiestrampsandthieves:\n",
      "a: 12\n",
      "the: 7\n",
      "of: 6\n",
      "I: 5\n",
      "he: 5\n",
      "\n",
      "Five most common words in song titles for cher_halfbreed:\n",
      "I: 8\n",
      "me: 5\n",
      "to: 4\n",
      "My: 3\n",
      "a: 3\n",
      "\n",
      "Five most common words in song titles for cher_happinessisjustathingcalledjoe:\n",
      "a: 7\n",
      "is: 7\n",
      "Joe: 7\n",
      "the: 4\n",
      "President: 4\n",
      "\n",
      "Five most common words in song titles for cher_happywasthedaywemet:\n",
      "to: 10\n",
      "the: 10\n",
      "we: 10\n",
      "I: 9\n",
      "of: 7\n",
      "\n",
      "Five most common words in song titles for cher_hardenoughgettingoveryou:\n",
      "I: 16\n",
      "you: 11\n",
      "the: 9\n",
      "been: 8\n",
      "it's: 7\n",
      "\n",
      "Five most common words in song titles for cher_heaintheavyhesmybrother:\n",
      "my: 7\n",
      "he's: 6\n",
      "is: 4\n",
      "to: 4\n",
      "He: 4\n",
      "\n",
      "Five most common words in song titles for cher_heartofstone:\n",
      "the: 15\n",
      "heart: 13\n",
      "of: 12\n",
      "and: 10\n",
      "a: 9\n",
      "\n",
      "Five most common words in song titles for cher_hellneverknow:\n",
      "I: 13\n",
      "the: 10\n",
      "to: 8\n",
      "never: 8\n",
      "know: 8\n",
      "\n",
      "Five most common words in song titles for cher_hellonwheels:\n",
      "you: 22\n",
      "on: 21\n",
      "I: 19\n",
      "something: 16\n",
      "it: 13\n",
      "\n",
      "Five most common words in song titles for cher_hewasbeautiful:\n",
      "the: 10\n",
      "I: 9\n",
      "was: 7\n",
      "And: 5\n",
      "his: 5\n",
      "\n",
      "Five most common words in song titles for cher_heyjoe:\n",
      "I: 18\n",
      "down: 12\n",
      "her: 11\n",
      "shot: 9\n",
      "you: 7\n",
      "\n",
      "Five most common words in song titles for cher_holdinoutforlove:\n",
      "holdin': 20\n",
      "I'm: 15\n",
      "out: 15\n",
      "for: 15\n",
      "love: 15\n",
      "\n",
      "Five most common words in song titles for cher_holysmoke:\n",
      "smoke: 15\n",
      "say: 11\n",
      "a: 10\n",
      "to: 10\n",
      "the: 9\n",
      "\n",
      "Five most common words in song titles for cher_homewardbound:\n",
      "my: 13\n",
      "I: 9\n",
      "Home: 9\n",
      "where: 9\n",
      "Homeward: 6\n",
      "\n",
      "Five most common words in song titles for cher_houseisnotahome:\n",
      "a: 14\n",
      "is: 6\n",
      "house: 6\n",
      "And: 6\n",
      "one: 5\n",
      "\n",
      "Five most common words in song titles for cher_howcanyoumendabrokenheart:\n",
      "can: 12\n",
      "the: 10\n",
      "you: 8\n",
      "How: 8\n",
      "a: 6\n",
      "\n",
      "Five most common words in song titles for cher_howlonghasthisbeengoingon:\n",
      "I: 11\n",
      "been: 9\n",
      "long: 8\n",
      "has: 8\n",
      "this: 8\n",
      "\n",
      "Five most common words in song titles for cher_ibelieve:\n",
      "I: 34\n",
      "believe: 29\n",
      "the: 29\n",
      "in: 23\n",
      "man: 21\n",
      "\n",
      "Five most common words in song titles for cher_idonthavetosleeptodream:\n",
      "I: 32\n",
      "to: 21\n",
      "dream: 14\n",
      "You're: 10\n",
      "me: 9\n",
      "\n",
      "Five most common words in song titles for cher_idratherbelieveinyou:\n",
      "you've: 8\n",
      "loved: 8\n",
      "I: 7\n",
      "somebody: 7\n",
      "you: 6\n",
      "\n",
      "Five most common words in song titles for cher_ifeelsomethingintheairmagicintheair:\n",
      "I: 13\n",
      "to: 10\n",
      "you: 7\n",
      "me: 6\n",
      "a: 6\n",
      "\n",
      "Five most common words in song titles for cher_ificouldturnbacktime:\n",
      "I: 41\n",
      "If: 18\n",
      "could: 18\n",
      "you: 18\n",
      "back: 14\n",
      "\n",
      "Five most common words in song titles for cher_ifiknewthen:\n",
      "I: 20\n",
      "was: 6\n",
      "know: 6\n",
      "what: 5\n",
      "now: 5\n",
      "\n",
      "Five most common words in song titles for cher_ifoundsomeone:\n",
      "the: 14\n",
      "been: 11\n",
      "you: 10\n",
      "I: 10\n",
      "away: 9\n",
      "\n",
      "Five most common words in song titles for cher_ifoundyoulove:\n",
      "I: 21\n",
      "love: 19\n",
      "gonna: 16\n",
      "found: 10\n",
      "was: 8\n",
      "\n",
      "Five most common words in song titles for cher_igotitbadandthataintgood:\n",
      "I: 9\n",
      "it: 8\n",
      "bad,: 7\n",
      "got: 6\n",
      "bad: 5\n",
      "\n",
      "Five most common words in song titles for cher_igotosleep:\n",
      "I: 15\n",
      "me: 14\n",
      "you: 8\n",
      "to: 8\n",
      "there: 7\n",
      "\n",
      "Five most common words in song titles for cher_igotyoubabe:\n",
      "I: 28\n",
      "got: 24\n",
      "you: 22\n",
      "[Him:]: 11\n",
      "babe: 11\n",
      "\n",
      "Five most common words in song titles for cher_ihatetosleepalone:\n",
      "I: 10\n",
      "you: 6\n",
      "that: 6\n",
      "You: 5\n",
      "alone: 5\n",
      "\n",
      "Five most common words in song titles for cher_ihopeyoufindit:\n",
      "you: 27\n",
      "I: 23\n",
      "that: 17\n",
      "hope: 14\n",
      "And: 12\n",
      "\n",
      "Five most common words in song titles for cher_iknowyoudontloveme:\n",
      "you: 7\n",
      "love: 6\n",
      "I: 6\n",
      "me: 5\n",
      "Yes: 5\n",
      "\n",
      "Five most common words in song titles for cher_illneverstoplovingyou:\n",
      "I: 11\n",
      "you: 10\n",
      "to: 7\n",
      "stop: 6\n",
      "I'll: 5\n",
      "\n",
      "Five most common words in song titles for cher_ilovemakinlovetoyou:\n",
      "love: 14\n",
      "I: 11\n",
      "to: 9\n",
      "you: 7\n",
      "me: 7\n",
      "\n",
      "Five most common words in song titles for cher_imblowinaway:\n",
      "and: 5\n",
      "And: 4\n",
      "love: 4\n",
      "me: 3\n",
      "I've: 2\n",
      "\n",
      "Five most common words in song titles for cher_iminthemiddle:\n",
      "I: 16\n",
      "you: 10\n",
      "in: 9\n",
      "I'm: 9\n",
      "the: 9\n",
      "\n",
      "Five most common words in song titles for cher_impossibledream:\n",
      "To: 11\n",
      "the: 8\n",
      "to: 4\n",
      "with: 3\n",
      "and: 3\n",
      "\n",
      "Five most common words in song titles for cher_inforthenight:\n",
      "to: 6\n",
      "a: 6\n",
      "like: 4\n",
      "you: 4\n",
      "your: 4\n",
      "\n",
      "Five most common words in song titles for cher_iparalyze:\n",
      "I: 23\n",
      "a: 19\n",
      "of: 12\n",
      "you: 9\n",
      "Got: 8\n",
      "\n",
      "Five most common words in song titles for cher_isawamanandhedancedwithhiswife:\n",
      "I: 16\n",
      "he: 9\n",
      "on: 8\n",
      "me: 7\n",
      "with: 6\n",
      "\n",
      "Five most common words in song titles for cher_island:\n",
      "I: 11\n",
      "And: 6\n",
      "to: 5\n",
      "can't: 4\n",
      "get: 4\n",
      "\n",
      "Five most common words in song titles for cher_italladdsupnow:\n",
      "you: 7\n",
      "me: 5\n",
      "the: 3\n",
      "to: 3\n",
      "down: 3\n",
      "\n",
      "Five most common words in song titles for cher_itgetsmewhereiwanttogo:\n",
      "the: 6\n",
      "eyes: 6\n",
      "I: 5\n",
      "In: 5\n",
      "me: 4\n",
      "\n",
      "Five most common words in song titles for cher_ithrewitallaway:\n",
      "I: 10\n",
      "it: 9\n",
      "all: 7\n",
      "you: 6\n",
      "away: 5\n",
      "\n",
      "Five most common words in song titles for cher_itmightaswellstaymondayfromnowon:\n",
      "it: 9\n",
      "Monday: 8\n",
      "I: 7\n",
      "you: 7\n",
      "as: 6\n",
      "\n",
      "Five most common words in song titles for cher_itsacryinshame:\n",
      "a: 14\n",
      "the: 13\n",
      "Love: 11\n",
      "cryin': 10\n",
      "shame: 10\n",
      "\n",
      "Five most common words in song titles for cher_itsamansmansmansworld:\n",
      "a: 13\n",
      "the: 11\n",
      "He's: 7\n",
      "lost: 7\n",
      "man: 5\n",
      "\n",
      "Five most common words in song titles for cher_itsnotunusual:\n",
      "to: 9\n",
      "It's: 8\n",
      "not: 8\n",
      "unusual: 8\n",
      "you: 7\n",
      "\n",
      "Five most common words in song titles for cher_itstoolatetolovemenow:\n",
      "you: 16\n",
      "too: 14\n",
      "It's: 10\n",
      "late: 10\n",
      "me: 10\n",
      "\n",
      "Five most common words in song titles for cher_iwalkalone:\n",
      "to: 34\n",
      "Time: 24\n",
      "I: 18\n",
      "a: 15\n",
      "walk: 13\n",
      "\n",
      "Five most common words in song titles for cher_iwalkonguildedsplinters:\n",
      "I: 24\n",
      "Till: 16\n",
      "burn: 16\n",
      "up: 16\n",
      "Walk: 11\n",
      "\n",
      "Five most common words in song titles for cher_iwantyou:\n",
      "I: 26\n",
      "you: 18\n",
      "want: 16\n",
      "to: 10\n",
      "the: 6\n",
      "\n",
      "Five most common words in song titles for cher_iwasntready:\n",
      "I: 16\n",
      "he: 9\n",
      "was: 8\n",
      "in: 6\n",
      "walked: 5\n",
      "\n",
      "Five most common words in song titles for cher_iwillwaitforyou:\n",
      "you: 14\n",
      "I: 10\n",
      "wait: 7\n",
      "for: 7\n",
      "will: 6\n",
      "\n",
      "Five most common words in song titles for cher_iwouldnttreatadogthewayyoutreatedme:\n",
      "no: 14\n",
      "you: 14\n",
      "I: 10\n",
      "me: 10\n",
      "a: 9\n",
      "\n",
      "Five most common words in song titles for cher_jolsonmedley:\n",
      "me: 10\n",
      "you: 8\n",
      "my: 7\n",
      "I: 7\n",
      "boy: 6\n",
      "\n",
      "Five most common words in song titles for cher_julie:\n",
      "Julie: 18\n",
      "Julie,: 12\n",
      "you: 11\n",
      "the: 7\n",
      "do: 7\n",
      "\n",
      "Five most common words in song titles for cher_justenoughtokeepmehanginon:\n",
      "me: 14\n",
      "just: 12\n",
      "to: 10\n",
      "on: 9\n",
      "enough: 8\n",
      "\n",
      "Five most common words in song titles for cher_justlikejessejames:\n",
      "on: 11\n",
      "the: 10\n",
      "gonna: 10\n",
      "you: 8\n",
      "I'm: 8\n",
      "\n",
      "Five most common words in song titles for cher_justthisonetime:\n",
      "I: 9\n",
      "this: 8\n",
      "to: 7\n",
      "one: 7\n",
      "time: 7\n",
      "\n",
      "Five most common words in song titles for cher_justwhativebeenlookinfor:\n",
      "I: 10\n",
      "what: 8\n",
      "I've: 6\n",
      "been: 6\n",
      "for: 6\n",
      "\n",
      "Five most common words in song titles for cher_kisstokiss:\n",
      "to: 20\n",
      "kiss: 18\n",
      "the: 11\n",
      "we: 8\n",
      "from: 7\n",
      "\n",
      "Five most common words in song titles for cher_knockonwood:\n",
      "I: 23\n",
      "better: 12\n",
      "knock: 11\n",
      "on: 10\n",
      "wood: 10\n",
      "\n",
      "Five most common words in song titles for cher_laplane:\n",
      "me: 20\n",
      "I'm: 12\n",
      "Get: 11\n",
      "to: 6\n",
      "of: 6\n",
      "\n",
      "Five most common words in song titles for cher_laybabylay:\n",
      "Lay: 11\n",
      "baby: 10\n",
      "the: 8\n",
      "lay: 7\n",
      "you: 7\n",
      "\n",
      "Five most common words in song titles for cher_letmedowneasy:\n",
      "me: 20\n",
      "down: 16\n",
      "let: 13\n",
      "you're: 6\n",
      "gonna: 5\n",
      "\n",
      "Five most common words in song titles for cher_letthisbealessontoyou:\n",
      "up: 11\n",
      "She's: 9\n",
      "pretty: 9\n",
      "tied: 9\n",
      "you: 9\n",
      "\n",
      "Five most common words in song titles for cher_lietome:\n",
      "me: 13\n",
      "to: 6\n",
      "the: 6\n",
      "you: 6\n",
      "I: 5\n",
      "\n",
      "Five most common words in song titles for cher_likearollingstone:\n",
      "a: 15\n",
      "you: 15\n",
      "to: 10\n",
      "it: 10\n",
      "the: 8\n",
      "\n",
      "Five most common words in song titles for cher_livinginahousedivided:\n",
      "of: 4\n",
      "a: 4\n",
      "at: 3\n",
      "so: 3\n",
      "The: 3\n",
      "\n",
      "Five most common words in song titles for cher_longdistanceloveaffair:\n",
      "love: 13\n",
      "a: 10\n",
      "distant: 8\n",
      "affair: 8\n",
      "station: 8\n",
      "\n",
      "Five most common words in song titles for cher_lookatme:\n",
      "me: 12\n",
      "Look: 6\n",
      "at: 6\n",
      "Tell: 6\n",
      "what: 6\n",
      "\n",
      "Five most common words in song titles for cher_loveandunderstanding:\n",
      "love: 17\n",
      "enough: 16\n",
      "to: 14\n",
      "We: 10\n",
      "and: 9\n",
      "\n",
      "Five most common words in song titles for cher_loveenough:\n",
      "you: 9\n",
      "love: 9\n",
      "it: 7\n",
      "to: 6\n",
      "we: 6\n",
      "\n",
      "Five most common words in song titles for cher_lovehurts:\n",
      "a: 10\n",
      "Love: 9\n",
      "love: 9\n",
      "hurts,: 7\n",
      "I: 7\n",
      "\n",
      "Five most common words in song titles for cher_lovehurts312103:\n",
      "Love: 10\n",
      "a: 9\n",
      "hurts: 6\n",
      "lot: 5\n",
      "of: 5\n",
      "\n",
      "Five most common words in song titles for cher_loveisalonelyplacewithoutyou:\n",
      "I: 16\n",
      "you: 13\n",
      "a: 9\n",
      "place: 9\n",
      "Love: 8\n",
      "\n",
      "Five most common words in song titles for cher_loveisthegroove:\n",
      "the: 31\n",
      "in: 20\n",
      "is: 19\n",
      "we: 17\n",
      "Love: 15\n",
      "\n",
      "Five most common words in song titles for cher_loveme:\n",
      "and: 5\n",
      "I'll: 5\n",
      "be: 5\n",
      "to: 4\n",
      "me: 3\n",
      "\n",
      "Five most common words in song titles for cher_loveonarooftop:\n",
      "We: 13\n",
      "all: 13\n",
      "on: 10\n",
      "a: 8\n",
      "the: 8\n",
      "\n",
      "Five most common words in song titles for cher_loveoneanother:\n",
      "Love: 12\n",
      "one: 12\n",
      "another: 12\n",
      "Everybody: 9\n",
      "a: 7\n",
      "\n",
      "Five most common words in song titles for cher_lovepaintheresapaininmyheart:\n",
      "the: 11\n",
      "I: 10\n",
      "and: 10\n",
      "to: 8\n",
      "you: 8\n",
      "\n",
      "Five most common words in song titles for cher_loversforever:\n",
      "I: 5\n",
      "a: 4\n",
      "to: 4\n",
      "you: 4\n",
      "can: 4\n",
      "\n",
      "Five most common words in song titles for cher_lovesohigh:\n",
      "I: 15\n",
      "the: 7\n",
      "love: 6\n",
      "me: 5\n",
      "And: 4\n",
      "\n",
      "Five most common words in song titles for cher_lovethedeviloutofya:\n",
      "a: 13\n",
      "lid: 11\n",
      "on: 11\n",
      "it: 10\n",
      "Put: 9\n",
      "\n",
      "Five most common words in song titles for cher_mainman:\n",
      "my: 16\n",
      "main: 14\n",
      "man: 14\n",
      "you're: 10\n",
      "your: 8\n",
      "\n",
      "Five most common words in song titles for cher_makethemanloveme:\n",
      "the: 11\n",
      "man: 8\n",
      "me: 8\n",
      "him: 8\n",
      "I: 6\n",
      "\n",
      "Five most common words in song titles for cher_mamawhenmydollieshavebabies:\n",
      "I: 10\n",
      "a: 10\n",
      "Mama: 8\n",
      "my: 6\n",
      "and: 6\n",
      "\n",
      "Five most common words in song titles for cher_mammamia:\n",
      "I: 25\n",
      "you: 15\n",
      "Mamma: 10\n",
      "mia,: 10\n",
      "I've: 9\n",
      "\n",
      "Five most common words in song titles for cher_mastersofwar:\n",
      "You: 15\n",
      "the: 15\n",
      "you: 13\n",
      "your: 13\n",
      "that: 11\n",
      "\n",
      "Five most common words in song titles for cher_melody:\n",
      "in: 5\n",
      "Melody: 4\n",
      "I: 3\n",
      "you: 3\n",
      "a: 3\n",
      "\n",
      "Five most common words in song titles for cher_milord:\n",
      "Milord: 11\n",
      "the: 7\n",
      "you: 5\n",
      "And: 5\n",
      "be: 4\n",
      "\n",
      "Five most common words in song titles for cher_mirrorimage:\n",
      "I: 22\n",
      "my: 10\n",
      "the: 10\n",
      "mirror: 9\n",
      "to: 8\n",
      "\n",
      "Five most common words in song titles for cher_misssubwayof1952:\n",
      "a: 16\n",
      "She: 11\n",
      "little: 10\n",
      "of: 10\n",
      "her: 9\n",
      "\n",
      "Five most common words in song titles for cher_mommalooksharp:\n",
      "hey: 5\n",
      "the: 5\n",
      "sharp: 5\n",
      "Hey,: 4\n",
      "momma,: 4\n",
      "\n",
      "Five most common words in song titles for cher_morethanyouknow:\n",
      "I: 14\n",
      "you: 12\n",
      "than: 8\n",
      "More: 6\n",
      "Loving: 6\n",
      "\n",
      "Five most common words in song titles for cher_moveme:\n",
      "me: 15\n",
      "I: 15\n",
      "you: 13\n",
      "love: 11\n",
      "the: 9\n",
      "\n",
      "Five most common words in song titles for cher_mrsoul:\n",
      "I: 13\n",
      "the: 13\n",
      "don't: 8\n",
      "a: 6\n",
      "change: 6\n",
      "\n",
      "Five most common words in song titles for cher_mylove:\n",
      "love: 24\n",
      "my: 23\n",
      "does: 10\n",
      "it: 10\n",
      "My: 9\n",
      "\n",
      "Five most common words in song titles for cher_mylove318663:\n",
      "you: 26\n",
      "my: 21\n",
      "can: 19\n",
      "love: 19\n",
      "be: 16\n",
      "\n",
      "Five most common words in song titles for cher_mysongtoofargone:\n",
      "to: 10\n",
      "know: 9\n",
      "I: 8\n",
      "he: 8\n",
      "far: 8\n",
      "\n",
      "Five most common words in song titles for cher_needlesandpins:\n",
      "I: 19\n",
      "and: 9\n",
      "him: 6\n",
      "pins: 6\n",
      "now: 6\n",
      "\n",
      "Five most common words in song titles for cher_neverbeentospain:\n",
      "I: 17\n",
      "it: 15\n",
      "to: 10\n",
      "Well: 7\n",
      "been: 7\n",
      "\n",
      "Five most common words in song titles for cher_nevershouldvestarted:\n",
      "I: 13\n",
      "can't: 7\n",
      "Holy: 5\n",
      "my: 5\n",
      "the: 4\n",
      "\n",
      "Five most common words in song titles for cher_notenoughloveintheworld:\n",
      "I: 15\n",
      "not: 8\n",
      "the: 8\n",
      "in: 7\n",
      "your: 6\n",
      "\n",
      "Five most common words in song titles for cher_olmanriver:\n",
      "the: 9\n",
      "and: 9\n",
      "that: 6\n",
      "Man: 5\n",
      "don't: 5\n",
      "\n",
      "Five most common words in song titles for cher_onebyone:\n",
      "one: 13\n",
      "love: 6\n",
      "for: 6\n",
      "by: 6\n",
      "you: 5\n",
      "\n",
      "Five most common words in song titles for cher_onehonestman:\n",
      "I: 16\n",
      "can't: 13\n",
      "find: 12\n",
      "man: 12\n",
      "one: 10\n",
      "\n",
      "Five most common words in song titles for cher_oneofus:\n",
      "of: 14\n",
      "us: 12\n",
      "is: 10\n",
      "I: 7\n",
      "the: 7\n",
      "\n",
      "Five most common words in song titles for cher_onesmallstep:\n",
      "the: 17\n",
      "small: 15\n",
      "in: 11\n",
      "One: 9\n",
      "step: 9\n",
      "\n",
      "Five most common words in song titles for cher_oogaboo:\n",
      "ooga,: 23\n",
      "boo: 12\n",
      "I: 10\n",
      "ooga: 9\n",
      "you: 8\n",
      "\n",
      "Five most common words in song titles for cher_ourdaywillcome:\n",
      "Our: 6\n",
      "come: 6\n",
      "love: 6\n",
      "day: 4\n",
      "will: 4\n",
      "\n",
      "Five most common words in song titles for cher_ourladyofsanfrancisco:\n",
      "I: 9\n",
      "in: 8\n",
      "San: 4\n",
      "a: 4\n",
      "her: 4\n",
      "\n",
      "Five most common words in song titles for cher_outrageous:\n",
      "I'm: 12\n",
      "outrageous: 11\n",
      "I: 9\n",
      "the: 8\n",
      "rage: 7\n",
      "\n",
      "Five most common words in song titles for cher_paradiseishere:\n",
      "your: 12\n",
      "I: 10\n",
      "need: 8\n",
      "Right: 8\n",
      "now: 8\n",
      "\n",
      "Five most common words in song titles for cher_perfection:\n",
      "perfection: 16\n",
      "I: 16\n",
      "the: 15\n",
      "to: 14\n",
      "it: 14\n",
      "\n",
      "Five most common words in song titles for cher_piedpiper:\n",
      "you: 13\n",
      "I'm: 8\n",
      "the: 8\n",
      "pied: 8\n",
      "piper: 8\n",
      "\n",
      "Five most common words in song titles for cher_pirate:\n",
      "I: 16\n",
      "the: 14\n",
      "you: 13\n",
      "love: 11\n",
      "And: 9\n",
      "\n",
      "Five most common words in song titles for cher_pleasedonttellme:\n",
      "the: 3\n",
      "I: 3\n",
      "this: 3\n",
      "and: 3\n",
      "far: 2\n",
      "\n",
      "Five most common words in song titles for cher_pride:\n",
      "we: 22\n",
      "We: 20\n",
      "the: 19\n",
      "oh: 18\n",
      "it: 12\n",
      "\n",
      "Five most common words in song titles for cher_prisoner:\n",
      "your: 25\n",
      "I'm: 18\n",
      "me: 12\n",
      "I: 11\n",
      "prisoner: 10\n",
      "\n",
      "Five most common words in song titles for cher_rainrain:\n",
      "you: 8\n",
      "I: 6\n",
      "the: 6\n",
      "The: 5\n",
      "my: 4\n",
      "\n",
      "Five most common words in song titles for cher_reallove:\n",
      "I: 20\n",
      "you: 15\n",
      "time: 11\n",
      "after: 10\n",
      "love: 9\n",
      "\n",
      "Five most common words in song titles for cher_reasontobelieve:\n",
      "to: 12\n",
      "I: 9\n",
      "you: 8\n",
      "find: 6\n",
      "believe: 5\n",
      "\n",
      "Five most common words in song titles for cher_red:\n",
      "my: 15\n",
      "I: 11\n",
      "now: 10\n",
      "you: 10\n",
      "All: 9\n",
      "\n",
      "Five most common words in song titles for cher_rescueme:\n",
      "me: 14\n",
      "and: 14\n",
      "you: 13\n",
      "on: 10\n",
      "I'm: 9\n",
      "\n",
      "Five most common words in song titles for cher_rockandrolldoctor:\n",
      "the: 13\n",
      "you: 12\n",
      "feel: 8\n",
      "a: 7\n",
      "so: 7\n",
      "\n",
      "Five most common words in song titles for cher_rudy:\n",
      "Rudy: 18\n",
      "you: 16\n",
      "you're: 14\n",
      "still: 8\n",
      "always: 8\n",
      "\n",
      "Five most common words in song titles for cher_runaway:\n",
      "I: 19\n",
      "Runaway: 18\n",
      "can't: 12\n",
      "find: 10\n",
      "gotta: 9\n",
      "\n",
      "Five most common words in song titles for cher_runnin:\n",
      "runnin': 11\n",
      "I: 7\n",
      "-: 7\n",
      "to: 6\n",
      "it: 6\n",
      "\n",
      "Five most common words in song titles for cher_savethechildren:\n",
      "and: 6\n",
      "your: 5\n",
      "the: 4\n",
      "For: 4\n",
      "eyes: 4\n",
      "\n",
      "Five most common words in song titles for cher_saveupallyourtears:\n",
      "don't: 17\n",
      "the: 16\n",
      "it: 16\n",
      "be: 14\n",
      "you: 13\n",
      "\n",
      "Five most common words in song titles for cher_saytheword:\n",
      "I: 15\n",
      "that: 12\n",
      "the: 8\n",
      "And: 8\n",
      "blade: 7\n",
      "\n",
      "Five most common words in song titles for cher_saywhatsonyourmind:\n",
      "me: 18\n",
      "you: 17\n",
      "to: 10\n",
      "not: 10\n",
      "or: 10\n",
      "\n",
      "Five most common words in song titles for cher_sendthemanover:\n",
      "a: 14\n",
      "the: 11\n",
      "I: 11\n",
      "to: 8\n",
      "my: 6\n",
      "\n",
      "Five most common words in song titles for cher_shadowdreamsong:\n",
      "the: 11\n",
      "I: 10\n",
      "her: 6\n",
      "and: 6\n",
      "to: 4\n",
      "\n",
      "Five most common words in song titles for cher_shapeofthingstocome:\n",
      "The: 17\n",
      "of: 16\n",
      "things: 16\n",
      "shape: 15\n",
      "to: 15\n",
      "\n",
      "Five most common words in song titles for cher_shelovestohearthemusic:\n",
      "to: 12\n",
      "the: 10\n",
      "she: 9\n",
      "She: 9\n",
      "She's: 8\n",
      "\n",
      "Five most common words in song titles for cher_shoppin:\n",
      "Shoppin',: 18\n",
      "I'm: 14\n",
      "I: 13\n",
      "my: 12\n",
      "to: 9\n",
      "\n",
      "Five most common words in song titles for cher_silverwingsgoldenrings:\n",
      "you: 9\n",
      "to: 6\n",
      "I: 6\n",
      "the: 6\n",
      "me: 5\n",
      "\n",
      "Five most common words in song titles for cher_singforyoursupper:\n",
      "you'll: 8\n",
      "a: 6\n",
      "I: 5\n",
      "sing: 5\n",
      "for: 4\n",
      "\n",
      "Five most common words in song titles for cher_sirens:\n",
      "the: 25\n",
      "will: 9\n",
      "of: 7\n",
      "in: 6\n",
      "From: 6\n",
      "\n",
      "Five most common words in song titles for cher_sistersofmercy:\n",
      "of: 21\n",
      "no: 14\n",
      "mercy: 11\n",
      "Your: 10\n",
      "a: 10\n",
      "\n",
      "Five most common words in song titles for cher_sittinonthedockofthebay:\n",
      "the: 21\n",
      "dock: 7\n",
      "on: 6\n",
      "of: 6\n",
      "roll: 5\n",
      "\n",
      "Five most common words in song titles for cher_skindeep:\n",
      "the: 20\n",
      "I: 18\n",
      "to: 15\n",
      "Skin: 14\n",
      "deep,: 14\n",
      "\n",
      "Five most common words in song titles for cher_songcalledchildren:\n",
      "they: 8\n",
      "still: 5\n",
      "a: 4\n",
      "the: 4\n",
      "can: 4\n",
      "\n",
      "Five most common words in song titles for cher_songforyou:\n",
      "you: 10\n",
      "I: 7\n",
      "my: 6\n",
      "this: 6\n",
      "in: 5\n",
      "\n",
      "Five most common words in song titles for cher_sos:\n",
      "I: 19\n",
      "to: 12\n",
      "me,: 12\n",
      "you're: 11\n",
      "can: 11\n",
      "\n",
      "Five most common words in song titles for cher_spring:\n",
      "a: 15\n",
      "you: 10\n",
      "Spring: 9\n",
      "long: 9\n",
      "the: 7\n",
      "\n",
      "Five most common words in song titles for cher_stars:\n",
      "They: 11\n",
      "the: 11\n",
      "come: 9\n",
      "you: 9\n",
      "never: 6\n",
      "\n",
      "Five most common words in song titles for cher_startingover:\n",
      "the: 11\n",
      "Startin': 11\n",
      "over: 11\n",
      "again: 9\n",
      "back: 6\n",
      "\n",
      "Five most common words in song titles for cher_still:\n",
      "I: 23\n",
      "love: 15\n",
      "you: 12\n",
      "still: 8\n",
      "for: 7\n",
      "\n",
      "Five most common words in song titles for cher_stillinlovewithyou:\n",
      "I: 16\n",
      "you: 15\n",
      "know: 11\n",
      "in: 9\n",
      "it's: 8\n",
      "\n",
      "Five most common words in song titles for cher_strongenough:\n",
      "enough: 19\n",
      "you: 14\n",
      "I'm: 13\n",
      "I: 12\n",
      "And: 11\n",
      "\n",
      "Five most common words in song titles for cher_sunny:\n",
      "you: 18\n",
      "Sunny: 11\n",
      "I: 8\n",
      "love: 8\n",
      "the: 7\n",
      "\n",
      "Five most common words in song titles for cher_superstar:\n",
      "you: 9\n",
      "baby: 9\n",
      "Ah: 7\n",
      "I: 7\n",
      "Oh: 6\n",
      "\n",
      "Five most common words in song titles for cher_takeitfromtheboys:\n",
      "the: 43\n",
      "it: 32\n",
      "from: 30\n",
      "boys: 30\n",
      "Take: 21\n",
      "\n",
      "Five most common words in song titles for cher_takeitlikeaman:\n",
      "it: 27\n",
      "you: 20\n",
      "the: 14\n",
      "You: 12\n",
      "gotta: 11\n",
      "\n",
      "Five most common words in song titles for cher_takemeforalittlewhile:\n",
      "me: 12\n",
      "you: 11\n",
      "I: 6\n",
      "love: 5\n",
      "And: 4\n",
      "\n",
      "Five most common words in song titles for cher_takemehome:\n",
      "me: 46\n",
      "you: 26\n",
      "home: 20\n",
      "I: 16\n",
      "Take: 13\n",
      "\n",
      "Five most common words in song titles for cher_takinbackmyheart:\n",
      "my: 34\n",
      "back: 22\n",
      "baby,: 17\n",
      "heart: 17\n",
      "I'm: 11\n",
      "\n",
      "Five most common words in song titles for cher_taxitaxi:\n",
      "me: 19\n",
      "you: 18\n",
      "ride: 18\n",
      "I'm: 17\n",
      "gonna: 17\n",
      "\n",
      "Five most common words in song titles for cher_thebellsofrhymney:\n",
      "the: 18\n",
      "Say: 12\n",
      "bells: 12\n",
      "of: 12\n",
      "what: 4\n",
      "\n",
      "Five most common words in song titles for cher_thebiggertheycomethehardertheyfall:\n",
      "they: 14\n",
      "And: 9\n",
      "the: 8\n",
      "The: 7\n",
      "as: 6\n",
      "\n",
      "Five most common words in song titles for cher_thebookoflove:\n",
      "of: 18\n",
      "the: 12\n",
      "book: 12\n",
      "love: 12\n",
      "a: 11\n",
      "\n",
      "Five most common words in song titles for cher_thecruelwar:\n",
      "you: 13\n",
      "my: 7\n",
      "with: 6\n",
      "love: 6\n",
      "I: 5\n",
      "\n",
      "Five most common words in song titles for cher_thefallkurtsblues:\n",
      "the: 10\n",
      "you: 8\n",
      "your: 8\n",
      "I: 7\n",
      "But: 6\n",
      "\n",
      "Five most common words in song titles for cher_thefirsttime:\n",
      "I: 17\n",
      "a: 5\n",
      "you: 5\n",
      "think: 3\n",
      "been: 3\n",
      "\n",
      "Five most common words in song titles for cher_thegirlfromipanema:\n",
      "she: 11\n",
      "and: 10\n",
      "I: 10\n",
      "when: 6\n",
      "passes: 6\n",
      "\n",
      "Five most common words in song titles for cher_thegreatestsongieverheard:\n",
      "the: 23\n",
      "And: 9\n",
      "I: 7\n",
      "ever: 7\n",
      "Was: 6\n",
      "\n",
      "Five most common words in song titles for cher_thegreatestthing:\n",
      "you: 29\n",
      "I: 21\n",
      "to: 16\n",
      "greatest: 16\n",
      "the: 10\n",
      "\n",
      "Five most common words in song titles for cher_thegunman:\n",
      "is: 10\n",
      "a: 9\n",
      "gunman: 8\n",
      "and: 8\n",
      "you: 8\n",
      "\n",
      "Five most common words in song titles for cher_thelongandwindingroad:\n",
      "me: 12\n",
      "long: 8\n",
      "And: 5\n",
      "road: 5\n",
      "here: 5\n",
      "\n",
      "Five most common words in song titles for cher_themanilove:\n",
      "I: 9\n",
      "And: 7\n",
      "gonna: 7\n",
      "a: 5\n",
      "my: 4\n",
      "\n",
      "Five most common words in song titles for cher_themanthatgotaway:\n",
      "The: 8\n",
      "the: 6\n",
      "you: 5\n",
      "man: 4\n",
      "that: 4\n",
      "\n",
      "Five most common words in song titles for cher_themusicsnogoodwithoutyou:\n",
      "the: 7\n",
      "to: 7\n",
      "I: 7\n",
      "you: 6\n",
      "me: 6\n",
      "\n",
      "Five most common words in song titles for cher_thenameofthegame:\n",
      "the: 29\n",
      "I: 27\n",
      "you: 24\n",
      "me: 17\n",
      "to: 14\n",
      "\n",
      "Five most common words in song titles for cher_thepower:\n",
      "The: 13\n",
      "power: 12\n",
      "it: 8\n",
      "I: 7\n",
      "Every: 6\n",
      "\n",
      "Five most common words in song titles for cher_therebutforfortune:\n",
      "the: 19\n",
      "Show: 10\n",
      "me: 10\n",
      "you: 8\n",
      "I: 6\n",
      "\n",
      "Five most common words in song titles for cher_thesamemistake:\n",
      "I: 23\n",
      "the: 19\n",
      "is: 7\n",
      "And: 6\n",
      "to: 6\n",
      "\n",
      "Five most common words in song titles for cher_thesedays:\n",
      "I: 10\n",
      "days: 8\n",
      "to: 7\n",
      "I've: 5\n",
      "These: 5\n",
      "\n",
      "Five most common words in song titles for cher_theshoopshoopsongitsinhiskiss:\n",
      "his: 18\n",
      "it: 15\n",
      "in: 15\n",
      "That's: 14\n",
      "It's: 12\n",
      "\n",
      "Five most common words in song titles for cher_thesunaintgonnashineanymore:\n",
      "The: 16\n",
      "ain't: 10\n",
      "gonna: 10\n",
      "always: 7\n",
      "in: 6\n",
      "\n",
      "Five most common words in song titles for cher_thethoughtoflovingyou:\n",
      "The: 7\n",
      "you: 6\n",
      "to: 5\n",
      "I: 5\n",
      "now: 5\n",
      "\n",
      "Five most common words in song titles for cher_thetimestheyareachangin:\n",
      "the: 16\n",
      "And: 9\n",
      "your: 8\n",
      "For: 8\n",
      "you: 6\n",
      "\n",
      "Five most common words in song titles for cher_thetwelfthofnever:\n",
      "you: 8\n",
      "the: 7\n",
      "I: 6\n",
      "of: 5\n",
      "long: 4\n",
      "\n",
      "Five most common words in song titles for cher_thewayoflove:\n",
      "you: 14\n",
      "a: 8\n",
      "of: 8\n",
      "way: 8\n",
      "the: 7\n",
      "\n",
      "Five most common words in song titles for cher_thewinnertakesitall:\n",
      "I: 12\n",
      "it: 12\n",
      "The: 10\n",
      "the: 9\n",
      "winner: 6\n",
      "\n",
      "Five most common words in song titles for cher_thisgodforsakenday:\n",
      "the: 13\n",
      "I: 9\n",
      "gone: 5\n",
      "This: 4\n",
      "god-forsaken: 4\n",
      "\n",
      "Five most common words in song titles for cher_thisisasongforthelonely:\n",
      "the: 13\n",
      "you: 12\n",
      "a: 8\n",
      "song: 6\n",
      "is: 5\n",
      "\n",
      "Five most common words in song titles for cher_thunderstorm:\n",
      "I: 12\n",
      "the: 12\n",
      "you: 12\n",
      "your: 6\n",
      "here: 4\n",
      "\n",
      "Five most common words in song titles for cher_time:\n",
      "Some: 12\n",
      "people: 5\n",
      "go: 5\n",
      "Time: 4\n",
      "oh: 4\n",
      "\n",
      "Five most common words in song titles for cher_tonightillbestayingherewithyou:\n",
      "I: 8\n",
      "my: 7\n",
      "Throw: 6\n",
      "out: 6\n",
      "I'll: 5\n",
      "\n",
      "Five most common words in song titles for cher_touchandgo:\n",
      "and: 16\n",
      "we: 10\n",
      "I: 6\n",
      "know: 6\n",
      "you: 6\n",
      "\n",
      "Five most common words in song titles for cher_trainofthought:\n",
      "the: 12\n",
      "get: 10\n",
      "And: 9\n",
      "off: 7\n",
      "me: 6\n",
      "\n",
      "Five most common words in song titles for cher_twopeopleclingingtoathread:\n",
      "we: 10\n",
      "the: 9\n",
      "And: 5\n",
      "in: 4\n",
      "To: 3\n",
      "\n",
      "Five most common words in song titles for cher_untilitstimeforyoutogo:\n",
      "a: 7\n",
      "you: 5\n",
      "not: 4\n",
      "in: 4\n",
      "I'm: 3\n",
      "\n",
      "Five most common words in song titles for cher_walkinginmemphis:\n",
      "I: 23\n",
      "in: 20\n",
      "the: 17\n",
      "Memphis: 11\n",
      "feet: 10\n",
      "\n",
      "Five most common words in song titles for cher_walkwithme:\n",
      "me: 23\n",
      "with: 16\n",
      "you: 9\n",
      "for: 9\n",
      "Walk: 8\n",
      "\n",
      "Five most common words in song titles for cher_walls:\n",
      "the: 17\n",
      "I: 13\n",
      "them: 10\n",
      "see: 9\n",
      "to: 8\n",
      "\n",
      "Five most common words in song titles for cher_warpaintandsoftfeathers:\n",
      "was: 15\n",
      "the: 15\n",
      "and: 10\n",
      "a: 9\n",
      "War: 8\n",
      "\n",
      "Five most common words in song titles for cher_wasntitgood:\n",
      "you: 22\n",
      "it: 20\n",
      "good: 14\n",
      "I: 8\n",
      "Wasn't: 6\n",
      "\n",
      "Five most common words in song titles for cher_waterloo:\n",
      "Waterloo,: 16\n",
      "I: 15\n",
      "my: 11\n",
      "you: 10\n",
      "to: 10\n",
      "\n",
      "Five most common words in song titles for cher_weallflyhome:\n",
      "all: 7\n",
      "fly: 6\n",
      "home: 6\n",
      "a: 5\n",
      "to: 4\n",
      "\n",
      "Five most common words in song titles for cher_weallsleepalone:\n",
      "all: 9\n",
      "the: 8\n",
      "we: 7\n",
      "sleep: 7\n",
      "alone: 6\n",
      "\n",
      "Five most common words in song titles for cher_welcometoburlesque:\n",
      "a: 9\n",
      "little: 8\n",
      "you: 7\n",
      "to: 6\n",
      "Welcome: 5\n",
      "\n",
      "Five most common words in song titles for cher_weregonnamakeit:\n",
      "we: 18\n",
      "gonna: 15\n",
      "make: 15\n",
      "it: 12\n",
      "I: 10\n",
      "\n",
      "Five most common words in song titles for cher_whataboutthemoonlight:\n",
      "about: 26\n",
      "What: 20\n",
      "the: 19\n",
      "your: 14\n",
      "you: 11\n",
      "\n",
      "Five most common words in song titles for cher_whatllido:\n",
      "I: 12\n",
      "do: 7\n",
      "What'll: 5\n",
      "you: 4\n",
      "when: 3\n",
      "\n",
      "Five most common words in song titles for cher_whenlovecallsyourname:\n",
      "your: 20\n",
      "the: 13\n",
      "it: 11\n",
      "love: 10\n",
      "calls: 10\n",
      "\n",
      "Five most common words in song titles for cher_whenloversbecomestrangers:\n",
      "you: 16\n",
      "the: 14\n",
      "when: 13\n",
      "a: 13\n",
      "shame: 12\n",
      "\n",
      "Five most common words in song titles for cher_whentheloveisgone:\n",
      "the: 18\n",
      "When: 14\n",
      "you: 14\n",
      "love: 11\n",
      "is: 10\n",
      "\n",
      "Five most common words in song titles for cher_whenthemoneysgone:\n",
      "the: 18\n",
      "you: 16\n",
      "Will: 10\n",
      "me: 10\n",
      "When: 8\n",
      "\n",
      "Five most common words in song titles for cher_whenyoufindoutwhereyouregoinletmeknow:\n",
      "you: 15\n",
      "where: 8\n",
      "know: 7\n",
      "I: 7\n",
      "When: 6\n",
      "\n",
      "Five most common words in song titles for cher_whenyouwalkaway:\n",
      "you: 30\n",
      "walk: 20\n",
      "away: 16\n",
      "no: 16\n",
      "to: 14\n",
      "\n",
      "Five most common words in song titles for cher_wheredoyougo:\n",
      "you: 9\n",
      "do: 6\n",
      "your: 5\n",
      "don't: 4\n",
      "You: 3\n",
      "\n",
      "Five most common words in song titles for cher_whoyougonnabelieve:\n",
      "you: 29\n",
      "gonna: 12\n",
      "I: 8\n",
      "Who: 5\n",
      "the: 5\n",
      "\n",
      "Five most common words in song titles for cher_whywasiborn:\n",
      "I: 19\n",
      "do: 8\n",
      "me: 7\n",
      "Why: 5\n",
      "can: 4\n",
      "\n",
      "Five most common words in song titles for cher_willyoulovemetomorrow:\n",
      "love: 10\n",
      "me: 8\n",
      "you: 6\n",
      "tomorrow: 6\n",
      "the: 5\n",
      "\n",
      "Five most common words in song titles for cher_willyouwaitforme:\n",
      "for: 13\n",
      "me: 12\n",
      "you: 11\n",
      "I: 10\n",
      "the: 10\n",
      "\n",
      "Five most common words in song titles for cher_withorwithoutyou:\n",
      "I: 10\n",
      "to: 7\n",
      "it: 7\n",
      "you: 6\n",
      "my: 5\n",
      "\n",
      "Five most common words in song titles for cher_womansworld:\n",
      "a: 38\n",
      "is: 34\n",
      "world: 34\n",
      "This: 32\n",
      "woman's: 32\n",
      "\n",
      "Five most common words in song titles for cher_workinggirl:\n",
      "a: 12\n",
      "the: 10\n",
      "in: 7\n",
      "Working: 6\n",
      "girl,: 6\n",
      "\n",
      "Five most common words in song titles for cher_youbettersitdownkids:\n",
      "to: 13\n",
      "kids: 12\n",
      "I: 10\n",
      "you: 8\n",
      "not: 5\n",
      "\n",
      "Five most common words in song titles for cher_youdonthavetosayyouloveme:\n",
      "you: 15\n",
      "I: 12\n",
      "me: 10\n",
      "to: 9\n",
      "You: 8\n",
      "\n",
      "Five most common words in song titles for cher_youhaventseenthelastofme:\n",
      "me: 14\n",
      "the: 12\n",
      "of: 11\n",
      "You: 10\n",
      "I: 8\n",
      "\n",
      "Five most common words in song titles for cher_youknowit:\n",
      "you: 12\n",
      "it: 9\n",
      "know: 8\n",
      "You: 4\n",
      "to: 4\n",
      "\n",
      "Five most common words in song titles for cher_youngandpretty:\n",
      "I: 11\n",
      "the: 9\n",
      "it: 8\n",
      "say: 5\n",
      "you: 5\n",
      "\n",
      "Five most common words in song titles for cher_yoursuntiltomorrow:\n",
      "me: 11\n",
      "be: 10\n",
      "I: 9\n",
      "Let: 8\n",
      "yours: 8\n",
      "\n",
      "Five most common words in song titles for cher_youtakeitall:\n",
      "the: 11\n",
      "we: 9\n",
      "Every: 6\n",
      "that: 6\n",
      "ever: 6\n",
      "\n",
      "Five most common words in song titles for cher_youvemademesoveryhappy:\n",
      "you: 18\n",
      "so: 13\n",
      "You: 8\n",
      "me: 8\n",
      "my: 8\n",
      "\n",
      "Five most common words in song titles for cher_youvereallygotaholdonme:\n",
      "me: 26\n",
      "really: 16\n",
      "got: 16\n",
      "a: 16\n",
      "hold: 16\n",
      "\n",
      "Five most common words in song titles for cher_youwouldntknowlove:\n",
      "know: 28\n",
      "wouldn't: 26\n",
      "it: 24\n",
      "you: 20\n",
      "You: 20\n",
      "\n",
      "Five most common words in song titles for robyn_88days:\n",
      "got: 23\n",
      "the: 17\n",
      "you: 15\n",
      "to: 13\n",
      "88: 11\n",
      "\n",
      "Five most common words in song titles for robyn_aintnothing:\n",
      "you: 8\n",
      "really: 6\n",
      "for: 5\n",
      "want: 4\n",
      "me: 4\n",
      "\n",
      "Five most common words in song titles for robyn_anytimeyoulike:\n",
      "you: 22\n",
      "Under: 13\n",
      "pressure,: 13\n",
      "me: 10\n",
      "I: 10\n",
      "\n",
      "Five most common words in song titles for robyn_babyforgiveme:\n",
      "me: 13\n",
      "Baby: 12\n",
      "forgive: 12\n",
      "you: 8\n",
      "the: 4\n",
      "\n",
      "Five most common words in song titles for robyn_beach2k20:\n",
      "go: 14\n",
      "on: 13\n",
      "the: 13\n",
      "beach: 12\n",
      "you: 9\n",
      "\n",
      "Five most common words in song titles for robyn_becauseitsinthemusic:\n",
      "it: 17\n",
      "in: 13\n",
      "to: 9\n",
      "And: 8\n",
      "that: 8\n",
      "\n",
      "Five most common words in song titles for robyn_bemine:\n",
      "you: 37\n",
      "never: 29\n",
      "and: 15\n",
      "be: 14\n",
      "were: 13\n",
      "\n",
      "Five most common words in song titles for robyn_betweenthelines:\n",
      "the: 21\n",
      "in: 20\n",
      "between: 20\n",
      "reading: 19\n",
      "I: 19\n",
      "\n",
      "Five most common words in song titles for robyn_bigcity:\n",
      "you: 18\n",
      "me: 13\n",
      "the: 10\n",
      "too: 9\n",
      "I: 9\n",
      "\n",
      "Five most common words in song titles for robyn_bionicwoman:\n",
      "We're: 2\n",
      "\"Bionic: 1\n",
      "Woman\": 1\n",
      "Good: 1\n",
      "evening: 1\n",
      "\n",
      "Five most common words in song titles for robyn_blowmymind:\n",
      "my: 11\n",
      "you're: 10\n",
      "you: 8\n",
      "And: 7\n",
      "the: 7\n",
      "\n",
      "Five most common words in song titles for robyn_breakdownintermission:\n",
      "you: 9\n",
      "and: 9\n",
      "on: 8\n",
      "to: 4\n",
      "what: 3\n",
      "\n",
      "Five most common words in song titles for robyn_buffalostance:\n",
      "you: 18\n",
      "the: 15\n",
      "my: 14\n",
      "a: 14\n",
      "No: 13\n",
      "\n",
      "Five most common words in song titles for robyn_bumlikeyou:\n",
      "my: 17\n",
      "you: 15\n",
      "do: 13\n",
      "on: 13\n",
      "a: 13\n",
      "\n",
      "Five most common words in song titles for robyn_bumpyride:\n",
      "you: 13\n",
      "your: 9\n",
      "the: 9\n",
      "to: 8\n",
      "in: 6\n",
      "\n",
      "Five most common words in song titles for robyn_callyourgirlfriend:\n",
      "you: 22\n",
      "her: 20\n",
      "your: 11\n",
      "And: 9\n",
      "the: 8\n",
      "\n",
      "Five most common words in song titles for robyn_cobrastyle:\n",
      "deng: 32\n",
      "digi: 32\n",
      "the: 24\n",
      "I: 21\n",
      "with: 16\n",
      "\n",
      "Five most common words in song titles for robyn_crashandburngirl:\n",
      "the: 18\n",
      "you: 13\n",
      "down: 11\n",
      "your: 10\n",
      "and: 8\n",
      "\n",
      "Five most common words in song titles for robyn_criminalintent:\n",
      "the: 22\n",
      "I: 18\n",
      "Somebody: 16\n",
      "alert: 16\n",
      "authorities,: 16\n",
      "\n",
      "Five most common words in song titles for robyn_crywhenyougetolder:\n",
      "you: 21\n",
      "when: 12\n",
      "the: 11\n",
      "get: 10\n",
      "your: 9\n",
      "\n",
      "Five most common words in song titles for robyn_curriculumvitae:\n",
      "the: 21\n",
      "in: 12\n",
      "and: 12\n",
      "of: 10\n",
      "to: 7\n",
      "\n",
      "Five most common words in song titles for robyn_dancehallqueen:\n",
      "I: 24\n",
      "the: 15\n",
      "like: 12\n",
      "you: 8\n",
      "thing: 8\n",
      "\n",
      "Five most common words in song titles for robyn_dancehallqueen114530:\n",
      "I: 24\n",
      "the: 15\n",
      "like: 12\n",
      "you: 8\n",
      "thing: 8\n",
      "\n",
      "Five most common words in song titles for robyn_dancingonmyown:\n",
      "I'm: 19\n",
      "I: 15\n",
      "my: 14\n",
      "oh: 11\n",
      "you: 10\n",
      "\n",
      "Five most common words in song titles for robyn_dancingonmyown114521:\n",
      "I'm: 19\n",
      "I: 15\n",
      "my: 14\n",
      "you: 10\n",
      "the: 9\n",
      "\n",
      "Five most common words in song titles for robyn_doitagain:\n",
      "it: 24\n",
      "again: 23\n",
      "do: 19\n",
      "I: 9\n",
      "We: 8\n",
      "\n",
      "Five most common words in song titles for robyn_dontfuckingtellmewhattodo:\n",
      "me: 77\n",
      "killing: 66\n",
      "My: 48\n",
      "is: 41\n",
      "drinking: 16\n",
      "\n",
      "Five most common words in song titles for robyn_dontfuckingtellmewhattodo114520:\n",
      "me: 77\n",
      "killing: 66\n",
      "My: 48\n",
      "is: 41\n",
      "drinking: 16\n",
      "\n",
      "Five most common words in song titles for robyn_dontstopthemusic:\n",
      "on: 13\n",
      "you: 11\n",
      "the: 10\n",
      "come: 10\n",
      "Baby: 8\n",
      "\n",
      "Five most common words in song titles for robyn_dontwantyouback:\n",
      "I: 13\n",
      "wanna: 7\n",
      "don't: 6\n",
      "you: 6\n",
      "to: 6\n",
      "\n",
      "Five most common words in song titles for robyn_doyouknowwhatittakes:\n",
      "you: 13\n",
      "what: 9\n",
      "know: 7\n",
      "I: 7\n",
      "to: 7\n",
      "\n",
      "Five most common words in song titles for robyn_doyoureallywantmeshowrespect:\n",
      "her: 10\n",
      "you: 8\n",
      "is: 6\n",
      "You: 5\n",
      "to: 5\n",
      "\n",
      "Five most common words in song titles for robyn_eclipse:\n",
      "the: 9\n",
      "right,: 8\n",
      "your: 7\n",
      "I: 7\n",
      "just: 5\n",
      "\n",
      "Five most common words in song titles for robyn_electric:\n",
      "It's: 15\n",
      "Electric: 14\n",
      "electric: 10\n",
      "the: 10\n",
      "your: 9\n",
      "\n",
      "Five most common words in song titles for robyn_everagain:\n",
      "gonna: 23\n",
      "it: 19\n",
      "be: 19\n",
      "out: 12\n",
      "again: 11\n",
      "\n",
      "Five most common words in song titles for robyn_everylittlething:\n",
      "you: 16\n",
      "know: 12\n",
      "I: 10\n",
      "waiting: 9\n",
      "Every: 8\n",
      "\n",
      "Five most common words in song titles for robyn_fembot:\n",
      "you: 21\n",
      "in: 17\n",
      "my: 11\n",
      "and: 9\n",
      "for: 8\n",
      "\n",
      "Five most common words in song titles for robyn_fembot114519:\n",
      "you: 21\n",
      "in: 17\n",
      "my: 11\n",
      "and: 9\n",
      "for: 8\n",
      "\n",
      "Five most common words in song titles for robyn_getmyselftogether:\n",
      "got: 35\n",
      "...: 34\n",
      "I: 30\n",
      "to: 19\n",
      "get: 17\n",
      "\n",
      "Five most common words in song titles for robyn_givingyouback:\n",
      "I: 15\n",
      "you: 15\n",
      "be: 12\n",
      "can: 7\n",
      "to: 6\n",
      "\n",
      "Five most common words in song titles for robyn_gottoworkitout:\n",
      "it: 39\n",
      "Work: 23\n",
      "work: 19\n",
      "out.: 18\n",
      "you: 17\n",
      "\n",
      "Five most common words in song titles for robyn_handleme:\n",
      "you: 38\n",
      "me: 26\n",
      "and: 21\n",
      "You: 20\n",
      "can't: 17\n",
      "\n",
      "Five most common words in song titles for robyn_hangwithme:\n",
      "you: 27\n",
      "me: 23\n",
      "with: 15\n",
      "gonna: 12\n",
      "hang: 11\n",
      "\n",
      "Five most common words in song titles for robyn_hangwithme114525:\n",
      "you: 27\n",
      "me: 23\n",
      "with: 15\n",
      "gonna: 12\n",
      "hang: 11\n",
      "\n",
      "Five most common words in song titles for robyn_hangwithmeacousticversion:\n",
      "you: 20\n",
      "me: 19\n",
      "with: 13\n",
      "gonna: 8\n",
      "hang: 8\n",
      "\n",
      "Five most common words in song titles for robyn_healthylove:\n",
      "you: 22\n",
      "a: 9\n",
      "I: 9\n",
      "ever: 8\n",
      "had: 7\n",
      "\n",
      "Five most common words in song titles for robyn_herewego:\n",
      "I: 8\n",
      "we: 6\n",
      "you: 4\n",
      "that: 4\n",
      "Here: 4\n",
      "\n",
      "Five most common words in song titles for robyn_honey:\n",
      "you: 28\n",
      "the: 26\n",
      "what: 20\n",
      "get: 17\n",
      "your: 17\n",
      "\n",
      "Five most common words in song titles for robyn_how:\n",
      "you: 12\n",
      "the: 7\n",
      "is: 7\n",
      "to: 5\n",
      "time: 5\n",
      "\n",
      "Five most common words in song titles for robyn_humanbeing:\n",
      "a: 14\n",
      "(Move: 13\n",
      "human: 12\n",
      "I'm: 9\n",
      "being: 9\n",
      "\n",
      "Five most common words in song titles for robyn_includemeout:\n",
      "the: 24\n",
      "me: 20\n",
      "include: 18\n",
      "for: 16\n",
      "out: 13\n",
      "\n",
      "Five most common words in song titles for robyn_indestructible:\n",
      "I'm: 22\n",
      "love: 20\n",
      "the: 14\n",
      "you: 13\n",
      "like: 13\n",
      "\n",
      "Five most common words in song titles for robyn_indestructibleacousticversion:\n",
      "I'm: 20\n",
      "love: 18\n",
      "the: 14\n",
      "you: 11\n",
      "like: 11\n",
      "\n",
      "Five most common words in song titles for robyn_inmyeyes:\n",
      "you: 22\n",
      "my: 9\n",
      "look: 8\n",
      "into: 8\n",
      "eyes: 8\n",
      "\n",
      "Five most common words in song titles for robyn_inmyeyes114532:\n",
      "you: 22\n",
      "my: 9\n",
      "look: 8\n",
      "into: 8\n",
      "eyes: 8\n",
      "\n",
      "Five most common words in song titles for robyn_inmyheart:\n",
      "I: 8\n",
      "it: 8\n",
      "gonna: 7\n",
      "my: 6\n",
      "In: 5\n",
      "\n",
      "Five most common words in song titles for robyn_iwish:\n",
      "I: 20\n",
      "you: 18\n",
      "to: 11\n",
      "wish: 10\n",
      "the: 10\n",
      "\n",
      "Five most common words in song titles for robyn_jackuoff:\n",
      "u: 30\n",
      "jack: 24\n",
      "I'll: 16\n",
      "off: 16\n",
      "a: 8\n",
      "\n",
      "Five most common words in song titles for robyn_jagvetendejligrosa:\n",
      "och: 4\n",
      "hjrtans: 3\n",
      "en: 2\n",
      "som: 2\n",
      "Nr: 2\n",
      "\n",
      "Five most common words in song titles for robyn_justanothergirlfriend:\n",
      "you: 15\n",
      "me: 9\n",
      "that: 7\n",
      "I: 7\n",
      "all: 6\n",
      "\n",
      "Five most common words in song titles for robyn_keepthisfireburning:\n",
      "be: 19\n",
      "I'll: 17\n",
      "your: 14\n",
      "keep: 13\n",
      "I: 13\n",
      "\n",
      "Five most common words in song titles for robyn_konichiwabitches:\n",
      "the: 16\n",
      "you: 15\n",
      "a: 12\n",
      "on: 10\n",
      "in: 8\n",
      "\n",
      "Five most common words in song titles for robyn_longgone:\n",
      "gone: 21\n",
      "I'm: 18\n",
      "Long: 14\n",
      "I: 10\n",
      "in: 7\n",
      "\n",
      "Five most common words in song titles for robyn_losecontrol:\n",
      "you: 33\n",
      "can't: 21\n",
      "it: 16\n",
      "don't: 16\n",
      "like: 15\n",
      "\n",
      "Five most common words in song titles for robyn_loveisfree:\n",
      "boom: 40\n",
      "baby: 24\n",
      "it: 22\n",
      "give: 18\n",
      "Love: 16\n",
      "\n",
      "Five most common words in song titles for robyn_lovekills:\n",
      "you: 26\n",
      "love: 24\n",
      "yourself: 20\n",
      "that: 18\n",
      "know: 16\n",
      "\n",
      "Five most common words in song titles for robyn_lovekills114524:\n",
      "you: 27\n",
      "love: 24\n",
      "yourself: 20\n",
      "that: 18\n",
      "know: 16\n",
      "\n",
      "Five most common words in song titles for robyn_mainthing:\n",
      "it: 14\n",
      "you: 13\n",
      "work: 13\n",
      "I: 12\n",
      "(Let's: 11\n",
      "\n",
      "Five most common words in song titles for robyn_missingu:\n",
      "you: 22\n",
      "I: 13\n",
      "of: 11\n",
      "me: 10\n",
      "space: 10\n",
      "\n",
      "Five most common words in song titles for robyn_mondaymorning:\n",
      "you: 9\n",
      "love: 7\n",
      "I: 6\n",
      "on: 6\n",
      "Will: 5\n",
      "\n",
      "Five most common words in song titles for robyn_monument:\n",
      "my: 10\n",
      "life: 10\n",
      "I: 9\n",
      "a: 8\n",
      "Of: 6\n",
      "\n",
      "Five most common words in song titles for robyn_moonlight:\n",
      "don't: 7\n",
      "you: 6\n",
      "baby: 5\n",
      "the: 4\n",
      "I: 4\n",
      "\n",
      "Five most common words in song titles for robyn_myonlyreason:\n",
      "I: 9\n",
      "you: 7\n",
      "my: 6\n",
      "and: 6\n",
      "why: 5\n",
      "\n",
      "Five most common words in song titles for robyn_mytruth:\n",
      "you: 11\n",
      "If: 9\n",
      "I: 9\n",
      "my: 9\n",
      "truth: 7\n",
      "\n",
      "Five most common words in song titles for robyn_noneofdem:\n",
      "of: 18\n",
      "None: 13\n",
      "me: 12\n",
      "them: 10\n",
      "a: 6\n",
      "\n",
      "Five most common words in song titles for robyn_noneofdem114527:\n",
      "of: 18\n",
      "None: 13\n",
      "me: 12\n",
      "them: 10\n",
      "a: 6\n",
      "\n",
      "Five most common words in song titles for robyn_notontheinside:\n",
      "the: 7\n",
      "to: 6\n",
      "a: 6\n",
      "that: 5\n",
      "he: 4\n",
      "\n",
      "Five most common words in song titles for robyn_obaby:\n",
      "you: 13\n",
      "I: 7\n",
      "again: 6\n",
      "me: 6\n",
      "baby: 5\n",
      "\n",
      "Five most common words in song titles for robyn_play:\n",
      "yeah,: 7\n",
      "people: 6\n",
      "to: 6\n",
      "Some: 5\n",
      "never: 5\n",
      "\n",
      "Five most common words in song titles for robyn_psycho:\n",
      "baby: 20\n",
      "me: 19\n",
      "You're: 14\n",
      "you: 13\n",
      "psycho: 13\n",
      "\n",
      "Five most common words in song titles for robyn_robotboy:\n",
      "you: 7\n",
      "boy,: 5\n",
      "Hey: 4\n",
      "your: 4\n",
      "Your: 3\n",
      "\n",
      "Five most common words in song titles for robyn_robynishere:\n",
      "is: 11\n",
      "here: 10\n",
      "you: 10\n",
      "my: 8\n",
      "I'm: 8\n",
      "\n",
      "Five most common words in song titles for robyn_sayit:\n",
      "I: 26\n",
      "want: 26\n",
      "you: 26\n",
      "too: 9\n",
      "Say: 5\n",
      "\n",
      "Five most common words in song titles for robyn_sendtorobinimmediately:\n",
      "you: 15\n",
      "to: 15\n",
      "it: 14\n",
      "If: 11\n",
      "got: 11\n",
      "\n",
      "Five most common words in song titles for robyn_setmefree:\n",
      "set: 35\n",
      "to: 33\n",
      "got: 20\n",
      "me: 19\n",
      "know: 15\n",
      "\n",
      "Five most common words in song titles for robyn_shouldhaveknown:\n",
      "I: 17\n",
      "you: 11\n",
      "should: 9\n",
      "have: 9\n",
      "known: 7\n",
      "\n",
      "Five most common words in song titles for robyn_shouldhaveknown106828:\n",
      "I: 17\n",
      "you: 11\n",
      "should: 9\n",
      "have: 9\n",
      "known: 7\n",
      "\n",
      "Five most common words in song titles for robyn_showmelove:\n",
      "me: 38\n",
      "Show: 17\n",
      "all: 15\n",
      "love: 15\n",
      "what: 15\n",
      "\n",
      "Five most common words in song titles for robyn_stars4ever:\n",
      "the: 10\n",
      "I: 10\n",
      "You: 9\n",
      "and: 9\n",
      "me: 9\n",
      "\n",
      "Five most common words in song titles for robyn_stillyourgirl:\n",
      "you: 21\n",
      "your: 18\n",
      "I: 17\n",
      "it: 12\n",
      "still: 11\n",
      "\n",
      "Five most common words in song titles for robyn_tellyoutoday:\n",
      "you: 20\n",
      "I: 15\n",
      "Tell: 12\n",
      "today: 10\n",
      "to: 9\n",
      "\n",
      "Five most common words in song titles for robyn_thelasttime:\n",
      "I: 28\n",
      "you: 12\n",
      "to: 12\n",
      "always: 7\n",
      "back: 7\n",
      "\n",
      "Five most common words in song titles for robyn_timemachine:\n",
      "I: 16\n",
      "it: 14\n",
      "taking: 12\n",
      "back: 8\n",
      "the: 7\n",
      "\n",
      "Five most common words in song titles for robyn_tomteverkstan:\n",
      "uh: 6\n",
      "like: 3\n",
      "you: 3\n",
      "I: 2\n",
      "don't: 2\n",
      "\n",
      "Five most common words in song titles for robyn_underneaththeheart:\n",
      "the: 13\n",
      "you: 8\n",
      "I: 4\n",
      "see: 4\n",
      "a: 4\n",
      "\n",
      "Five most common words in song titles for robyn_universalwoman:\n",
      "her: 7\n",
      "she: 7\n",
      "a: 4\n",
      "love: 4\n",
      "is: 4\n",
      "\n",
      "Five most common words in song titles for robyn_ushouldknowbetter:\n",
      "better: 41\n",
      "know: 32\n",
      "to: 24\n",
      "the: 22\n",
      "with: 22\n",
      "\n",
      "Five most common words in song titles for robyn_ushouldknowbetter114529:\n",
      "better: 41\n",
      "know: 32\n",
      "to: 24\n",
      "the: 22\n",
      "with: 22\n",
      "\n",
      "Five most common words in song titles for robyn_wedancetothebeat:\n",
      "We: 68\n",
      "the: 68\n",
      "dance: 66\n",
      "to: 66\n",
      "beat: 66\n",
      "\n",
      "Five most common words in song titles for robyn_wedancetothebeat114528:\n",
      "We: 68\n",
      "the: 68\n",
      "dance: 66\n",
      "to: 66\n",
      "beat: 66\n",
      "\n",
      "Five most common words in song titles for robyn_wheredidourlovego:\n",
      "about: 5\n",
      "you: 5\n",
      "and: 5\n",
      "to: 5\n",
      "I: 5\n",
      "\n",
      "Five most common words in song titles for robyn_whosthatgirl:\n",
      "that: 27\n",
      "I: 22\n",
      "Who's: 18\n",
      "you: 16\n",
      "the: 14\n",
      "\n",
      "Five most common words in song titles for robyn_witheveryheartbeat:\n",
      "it: 12\n",
      "with: 11\n",
      "every: 11\n",
      "I: 9\n",
      "And: 8\n",
      "\n",
      "Five most common words in song titles for robyn_youvegotthatsomething:\n",
      "you: 12\n",
      "I: 11\n",
      "that: 8\n",
      "me: 6\n",
      "to: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Define the directory path\n",
    "lyrics_directory = r\"C:\\Users\\keevi\\OneDrive\\Documents\\SDU\\ADS-509\\Week 2\\M1 Results\\lyrics\"\n",
    "\n",
    "# Helper function to extract song titles\n",
    "def extract_song_titles(lyrics):\n",
    "    return [line.strip() for line in lyrics.split('\\n') if line.strip()]\n",
    "\n",
    "# Dictionary to store word counts in song titles by artist\n",
    "word_counts_by_artist = {}\n",
    "\n",
    "# Traverse the directory\n",
    "for root, dirs, files in os.walk(lyrics_directory):\n",
    "    for file in files:\n",
    "        # Read the file content\n",
    "        file_path = os.path.join(root, file)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            lyrics = f.read()\n",
    "        \n",
    "        # Extract the artist name from the file name\n",
    "        artist = os.path.splitext(file)[0]\n",
    "        \n",
    "        # Extract song titles from the lyrics\n",
    "        song_titles = extract_song_titles(lyrics)\n",
    "        \n",
    "        # Count word occurrences in song titles\n",
    "        word_counts = Counter()\n",
    "        for title in song_titles:\n",
    "            words = title.split()\n",
    "            word_counts.update(words)\n",
    "        \n",
    "        # Store the word counts for the artist\n",
    "        word_counts_by_artist[artist] = word_counts\n",
    "\n",
    "# Print the five most common words in song titles by artist\n",
    "for artist, word_counts in word_counts_by_artist.items():\n",
    "    print(f\"\\nFive most common words in song titles for {artist}:\")\n",
    "    for word, count in word_counts.most_common(5):\n",
    "        print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4fd71",
   "metadata": {},
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3790646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\keevi\\miniconda3\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\keevi\\miniconda3\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\keevi\\miniconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\keevi\\miniconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\keevi\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\keevi\\miniconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\keevi\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\keevi\\miniconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\keevi\\miniconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\keevi\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\keevi\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd428bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "805a1e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Cher     Axes(0.125,0.11;0.775x0.77)\n",
       "Robyn    Axes(0.125,0.11;0.775x0.77)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_replicates = 1000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"artist\" : ['Cher'] * num_replicates + ['Robyn']*num_replicates,\n",
    "    \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "})\n",
    "\n",
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9ebb",
   "metadata": {},
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: The regular expression '\\s+' matches a whitespace and substituting with empty string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0e34516",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyric) : \n",
    "    \"\"\"strip and split on whitespace\"\"\"\n",
    "    return([item.lower() for item in collapse_whitespace.split(lyric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2294c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create histograms for each artist\n",
    "for artist, group in lyrics_df.groupby('artist'):\n",
    "    plt.hist(group['cleaned_lyrics'].apply(len), bins=20, alpha=0.5, label=artist)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Song Lengths by Artist')\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c3c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
